{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> Project 2\n",
    "\n",
    "Project Description:\n",
    "- Use same datasets as Project 1.\n",
    "- Preprocess data: Explore data and apply data scaling.\n",
    "\n",
    "Regression Task:\n",
    "- Apply any two models with bagging and any two models with pasting.\n",
    "- Apply any two models with adaboost boosting\n",
    "- Apply one model with gradient boosting\n",
    "- Apply PCA on data and then apply all the models in project 1 again on data you get from PCA. Compare your results with results in project 2. You don't need to apply all the models twice. Just copy the result table from project 1, prepare similar table for all the models after PCA and compare both tables. Does PCA help in getting better results?\n",
    "- Apply deep learning models covered in class\n",
    "\n",
    "Classification Task:\n",
    "- Apply two voting classifiers - one with hard voting and one with soft voting\n",
    "- Apply any two models with bagging and any two models with pasting.\n",
    "- Apply any two models with adaboost boosting\n",
    "- Apply one model with gradient boosting\n",
    "- Apply PCA on data and then apply all the models in project 1 again on data you get from PCA. Compare your results with results in project 1. You don't need to apply all the models twice. Just copy the result table from project 1, prepare similar table for all the models after PCA and compare both tables. Does PCA help in getting better results?\n",
    "- Apply deep learning models covered in class\n",
    "\n",
    "Deliverables:\n",
    "- Use markdown to provide inline comments for this project.\n",
    "- Your outputs should be clearly executed in the notebook i.e. we should not need to rerun the code to obtain the outputs.\n",
    "- Visualization encouraged.\n",
    "- If you are submitting two different files, then please only one group member submit both the files. If you submit two files separately from different accounts, it will be submitted as two different attempts.\n",
    "- If you are submitting two different files, then please follow below naming convetion:\n",
    "    Project2_Regression_GroupXX_Firstname1_Firstname2.ipynb\n",
    "    Project2_Classification_GroupXX_Firstname1_Firstname2.ipynb\n",
    "- If you are submitting single file, then please follow below naming convetion:\n",
    "    Project2_Both_GroupXX_Firstname1_Firstname2.ipynb\n",
    "\n",
    "Questions regarding the project:\n",
    "- We have created a discussion board under Projects folder on e-learning. Create threads over there and post your queries related to project there.\n",
    "- We will also answer queries there. We will not be answering any project related queries through the mail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading datasets\n",
    "audit_risk = pd.read_csv('audit_risk.csv')\n",
    "trial = pd.read_csv('trial.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(776, 27)\n",
      "(776, 18)\n"
     ]
    }
   ],
   "source": [
    "# Exploring datasets\n",
    "print(audit_risk.shape)\n",
    "print(trial.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 776 entries, 0 to 775\n",
      "Data columns (total 27 columns):\n",
      "Sector_score      776 non-null float64\n",
      "LOCATION_ID       776 non-null object\n",
      "PARA_A            776 non-null float64\n",
      "Score_A           776 non-null float64\n",
      "Risk_A            776 non-null float64\n",
      "PARA_B            776 non-null float64\n",
      "Score_B           776 non-null float64\n",
      "Risk_B            776 non-null float64\n",
      "TOTAL             776 non-null float64\n",
      "numbers           776 non-null float64\n",
      "Score_B.1         776 non-null float64\n",
      "Risk_C            776 non-null float64\n",
      "Money_Value       775 non-null float64\n",
      "Score_MV          776 non-null float64\n",
      "Risk_D            776 non-null float64\n",
      "District_Loss     776 non-null int64\n",
      "PROB              776 non-null float64\n",
      "RiSk_E            776 non-null float64\n",
      "History           776 non-null int64\n",
      "Prob              776 non-null float64\n",
      "Risk_F            776 non-null float64\n",
      "Score             776 non-null float64\n",
      "Inherent_Risk     776 non-null float64\n",
      "CONTROL_RISK      776 non-null float64\n",
      "Detection_Risk    776 non-null float64\n",
      "Audit_Risk        776 non-null float64\n",
      "Risk              776 non-null int64\n",
      "dtypes: float64(23), int64(3), object(1)\n",
      "memory usage: 163.8+ KB\n"
     ]
    }
   ],
   "source": [
    "audit_risk.info() \n",
    "#one missing values in Money_Value, and Location_ID dtype is object; need to be fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sector_score</th>\n",
       "      <th>PARA_A</th>\n",
       "      <th>Score_A</th>\n",
       "      <th>Risk_A</th>\n",
       "      <th>PARA_B</th>\n",
       "      <th>Score_B</th>\n",
       "      <th>Risk_B</th>\n",
       "      <th>TOTAL</th>\n",
       "      <th>numbers</th>\n",
       "      <th>Score_B.1</th>\n",
       "      <th>...</th>\n",
       "      <th>RiSk_E</th>\n",
       "      <th>History</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Risk_F</th>\n",
       "      <th>Score</th>\n",
       "      <th>Inherent_Risk</th>\n",
       "      <th>CONTROL_RISK</th>\n",
       "      <th>Detection_Risk</th>\n",
       "      <th>Audit_Risk</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.0</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20.184536</td>\n",
       "      <td>2.450194</td>\n",
       "      <td>0.351289</td>\n",
       "      <td>1.351029</td>\n",
       "      <td>10.799988</td>\n",
       "      <td>0.313144</td>\n",
       "      <td>6.334008</td>\n",
       "      <td>13.218481</td>\n",
       "      <td>5.067655</td>\n",
       "      <td>0.223711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519072</td>\n",
       "      <td>0.104381</td>\n",
       "      <td>0.216753</td>\n",
       "      <td>0.053608</td>\n",
       "      <td>2.702577</td>\n",
       "      <td>17.680612</td>\n",
       "      <td>0.572680</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.168158</td>\n",
       "      <td>0.393041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>24.319017</td>\n",
       "      <td>5.678870</td>\n",
       "      <td>0.174055</td>\n",
       "      <td>3.440447</td>\n",
       "      <td>50.083624</td>\n",
       "      <td>0.169804</td>\n",
       "      <td>30.072845</td>\n",
       "      <td>51.312829</td>\n",
       "      <td>0.264449</td>\n",
       "      <td>0.080352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.290312</td>\n",
       "      <td>0.531031</td>\n",
       "      <td>0.067987</td>\n",
       "      <td>0.305835</td>\n",
       "      <td>0.858923</td>\n",
       "      <td>54.740244</td>\n",
       "      <td>0.444581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.667494</td>\n",
       "      <td>0.488741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.850000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.370000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.583500</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.316700</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.890000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.081000</td>\n",
       "      <td>1.370000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>2.214000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.555600</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>55.570000</td>\n",
       "      <td>2.480000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.488000</td>\n",
       "      <td>4.160000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.840500</td>\n",
       "      <td>7.707500</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>10.663500</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.249900</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>59.850000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>1264.630000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>758.778000</td>\n",
       "      <td>1268.910000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>801.262000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>961.514400</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sector_score      PARA_A     Score_A      Risk_A       PARA_B  \\\n",
       "count    776.000000  776.000000  776.000000  776.000000   776.000000   \n",
       "mean      20.184536    2.450194    0.351289    1.351029    10.799988   \n",
       "std       24.319017    5.678870    0.174055    3.440447    50.083624   \n",
       "min        1.850000    0.000000    0.200000    0.000000     0.000000   \n",
       "25%        2.370000    0.210000    0.200000    0.042000     0.000000   \n",
       "50%        3.890000    0.875000    0.200000    0.175000     0.405000   \n",
       "75%       55.570000    2.480000    0.600000    1.488000     4.160000   \n",
       "max       59.850000   85.000000    0.600000   51.000000  1264.630000   \n",
       "\n",
       "          Score_B      Risk_B        TOTAL     numbers   Score_B.1  \\\n",
       "count  776.000000  776.000000   776.000000  776.000000  776.000000   \n",
       "mean     0.313144    6.334008    13.218481    5.067655    0.223711   \n",
       "std      0.169804   30.072845    51.312829    0.264449    0.080352   \n",
       "min      0.200000    0.000000     0.000000    5.000000    0.200000   \n",
       "25%      0.200000    0.000000     0.537500    5.000000    0.200000   \n",
       "50%      0.200000    0.081000     1.370000    5.000000    0.200000   \n",
       "75%      0.400000    1.840500     7.707500    5.000000    0.200000   \n",
       "max      0.600000  758.778000  1268.910000    9.000000    0.600000   \n",
       "\n",
       "          ...          RiSk_E     History        Prob      Risk_F       Score  \\\n",
       "count     ...      776.000000  776.000000  776.000000  776.000000  776.000000   \n",
       "mean      ...        0.519072    0.104381    0.216753    0.053608    2.702577   \n",
       "std       ...        0.290312    0.531031    0.067987    0.305835    0.858923   \n",
       "min       ...        0.400000    0.000000    0.200000    0.000000    2.000000   \n",
       "25%       ...        0.400000    0.000000    0.200000    0.000000    2.000000   \n",
       "50%       ...        0.400000    0.000000    0.200000    0.000000    2.400000   \n",
       "75%       ...        0.400000    0.000000    0.200000    0.000000    3.250000   \n",
       "max       ...        2.400000    9.000000    0.600000    5.400000    5.200000   \n",
       "\n",
       "       Inherent_Risk  CONTROL_RISK  Detection_Risk  Audit_Risk        Risk  \n",
       "count     776.000000    776.000000           776.0  776.000000  776.000000  \n",
       "mean       17.680612      0.572680             0.5    7.168158    0.393041  \n",
       "std        54.740244      0.444581             0.0   38.667494    0.488741  \n",
       "min         1.400000      0.400000             0.5    0.280000    0.000000  \n",
       "25%         1.583500      0.400000             0.5    0.316700    0.000000  \n",
       "50%         2.214000      0.400000             0.5    0.555600    0.000000  \n",
       "75%        10.663500      0.400000             0.5    3.249900    1.000000  \n",
       "max       801.262000      5.800000             0.5  961.514400    1.000000  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audit_risk.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 776 entries, 0 to 775\n",
      "Data columns (total 18 columns):\n",
      "Sector_score     776 non-null float64\n",
      "LOCATION_ID      776 non-null object\n",
      "PARA_A           776 non-null float64\n",
      "SCORE_A          776 non-null int64\n",
      "PARA_B           776 non-null float64\n",
      "SCORE_B          776 non-null int64\n",
      "TOTAL            776 non-null float64\n",
      "numbers          776 non-null float64\n",
      "Marks            776 non-null int64\n",
      "Money_Value      775 non-null float64\n",
      "MONEY_Marks      776 non-null int64\n",
      "District         776 non-null int64\n",
      "Loss             776 non-null int64\n",
      "LOSS_SCORE       776 non-null int64\n",
      "History          776 non-null int64\n",
      "History_score    776 non-null int64\n",
      "Score            776 non-null float64\n",
      "Risk             776 non-null int64\n",
      "dtypes: float64(7), int64(10), object(1)\n",
      "memory usage: 109.2+ KB\n"
     ]
    }
   ],
   "source": [
    "trial.info() #No missing values but Location_ID is object; need to be fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sector_score</th>\n",
       "      <th>PARA_A</th>\n",
       "      <th>SCORE_A</th>\n",
       "      <th>PARA_B</th>\n",
       "      <th>SCORE_B</th>\n",
       "      <th>TOTAL</th>\n",
       "      <th>numbers</th>\n",
       "      <th>Marks</th>\n",
       "      <th>Money_Value</th>\n",
       "      <th>MONEY_Marks</th>\n",
       "      <th>District</th>\n",
       "      <th>Loss</th>\n",
       "      <th>LOSS_SCORE</th>\n",
       "      <th>History</th>\n",
       "      <th>History_score</th>\n",
       "      <th>Score</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>775.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>776.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20.184536</td>\n",
       "      <td>2.450194</td>\n",
       "      <td>3.512887</td>\n",
       "      <td>10.799988</td>\n",
       "      <td>3.131443</td>\n",
       "      <td>13.218481</td>\n",
       "      <td>5.067655</td>\n",
       "      <td>2.237113</td>\n",
       "      <td>14.137631</td>\n",
       "      <td>2.909794</td>\n",
       "      <td>2.505155</td>\n",
       "      <td>0.029639</td>\n",
       "      <td>2.061856</td>\n",
       "      <td>0.104381</td>\n",
       "      <td>2.167526</td>\n",
       "      <td>2.702577</td>\n",
       "      <td>0.626289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>24.319017</td>\n",
       "      <td>5.678870</td>\n",
       "      <td>1.740549</td>\n",
       "      <td>50.083624</td>\n",
       "      <td>1.698042</td>\n",
       "      <td>51.312829</td>\n",
       "      <td>0.264449</td>\n",
       "      <td>0.803517</td>\n",
       "      <td>66.606519</td>\n",
       "      <td>1.597452</td>\n",
       "      <td>1.228678</td>\n",
       "      <td>0.184280</td>\n",
       "      <td>0.375080</td>\n",
       "      <td>0.531031</td>\n",
       "      <td>0.679869</td>\n",
       "      <td>0.858923</td>\n",
       "      <td>0.484100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.850000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.370000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.890000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.370000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>55.570000</td>\n",
       "      <td>2.480000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.160000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.707500</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.595000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>59.850000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1264.630000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1268.910000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>935.030000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sector_score      PARA_A     SCORE_A       PARA_B     SCORE_B  \\\n",
       "count    776.000000  776.000000  776.000000   776.000000  776.000000   \n",
       "mean      20.184536    2.450194    3.512887    10.799988    3.131443   \n",
       "std       24.319017    5.678870    1.740549    50.083624    1.698042   \n",
       "min        1.850000    0.000000    2.000000     0.000000    2.000000   \n",
       "25%        2.370000    0.210000    2.000000     0.000000    2.000000   \n",
       "50%        3.890000    0.875000    2.000000     0.405000    2.000000   \n",
       "75%       55.570000    2.480000    6.000000     4.160000    4.000000   \n",
       "max       59.850000   85.000000    6.000000  1264.630000    6.000000   \n",
       "\n",
       "             TOTAL     numbers       Marks  Money_Value  MONEY_Marks  \\\n",
       "count   776.000000  776.000000  776.000000   775.000000   776.000000   \n",
       "mean     13.218481    5.067655    2.237113    14.137631     2.909794   \n",
       "std      51.312829    0.264449    0.803517    66.606519     1.597452   \n",
       "min       0.000000    5.000000    2.000000     0.000000     2.000000   \n",
       "25%       0.537500    5.000000    2.000000     0.000000     2.000000   \n",
       "50%       1.370000    5.000000    2.000000     0.090000     2.000000   \n",
       "75%       7.707500    5.000000    2.000000     5.595000     4.000000   \n",
       "max    1268.910000    9.000000    6.000000   935.030000     6.000000   \n",
       "\n",
       "         District        Loss  LOSS_SCORE     History  History_score  \\\n",
       "count  776.000000  776.000000  776.000000  776.000000     776.000000   \n",
       "mean     2.505155    0.029639    2.061856    0.104381       2.167526   \n",
       "std      1.228678    0.184280    0.375080    0.531031       0.679869   \n",
       "min      2.000000    0.000000    2.000000    0.000000       2.000000   \n",
       "25%      2.000000    0.000000    2.000000    0.000000       2.000000   \n",
       "50%      2.000000    0.000000    2.000000    0.000000       2.000000   \n",
       "75%      2.000000    0.000000    2.000000    0.000000       2.000000   \n",
       "max      6.000000    2.000000    6.000000    9.000000       6.000000   \n",
       "\n",
       "            Score        Risk  \n",
       "count  776.000000  776.000000  \n",
       "mean     2.702577    0.626289  \n",
       "std      0.858923    0.484100  \n",
       "min      2.000000    0.000000  \n",
       "25%      2.000000    0.000000  \n",
       "50%      2.400000    1.000000  \n",
       "75%      3.250000    1.000000  \n",
       "max      5.200000    1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove categorical values in the column of LOCATION_ID\n",
    "# Did not assign new values because they could be already one of the LOCATION_ID\n",
    "audit_risk = audit_risk[audit_risk.LOCATION_ID != 'LOHARU']\n",
    "audit_risk = audit_risk[audit_risk.LOCATION_ID != 'NUH']\n",
    "audit_risk = audit_risk[audit_risk.LOCATION_ID != 'SAFIDON']\n",
    "\n",
    "trial = trial[trial.LOCATION_ID != 'LOHARU']\n",
    "trial = trial[trial.LOCATION_ID != 'NUH']\n",
    "trial = trial[trial.LOCATION_ID != 'SAFIDON']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing dtype(object to integer)\n",
    "audit_risk['LOCATION_ID'] = pd.to_numeric(audit_risk['LOCATION_ID'])\n",
    "trial['LOCATION_ID'] = pd.to_numeric(trial['LOCATION_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicated columns\n",
    "# We removed duplicated parameters with different scales in advance \n",
    "trial.drop(['Sector_score','LOCATION_ID','PARA_A','SCORE_A',\n",
    "            'PARA_B','SCORE_B','TOTAL','numbers','District','Money_Value','History','Score','Risk'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Money_Value       1\n",
      "Risk              0\n",
      "LOCATION_ID       0\n",
      "PARA_A            0\n",
      "Score_A           0\n",
      "Risk_A            0\n",
      "PARA_B            0\n",
      "Score_B           0\n",
      "Risk_B            0\n",
      "TOTAL             0\n",
      "numbers           0\n",
      "Score_B.1         0\n",
      "Risk_C            0\n",
      "Score_MV          0\n",
      "Audit_Risk        0\n",
      "Risk_D            0\n",
      "District_Loss     0\n",
      "PROB              0\n",
      "RiSk_E            0\n",
      "History           0\n",
      "Prob              0\n",
      "Risk_F            0\n",
      "Score             0\n",
      "Inherent_Risk     0\n",
      "CONTROL_RISK      0\n",
      "Detection_Risk    0\n",
      "Sector_score      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Dealing with missing values\n",
    "print(audit_risk.isnull().sum().sort_values(ascending = False))\n",
    "audit_risk['Money_Value'] = audit_risk.fillna(audit_risk['Money_Value'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "History_score    0\n",
       "LOSS_SCORE       0\n",
       "Loss             0\n",
       "MONEY_Marks      0\n",
       "Marks            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial.isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(773, 27)\n",
      "(773, 5)\n"
     ]
    }
   ],
   "source": [
    "# Checking the shape again \n",
    "print(audit_risk.shape)\n",
    "print(trial.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(773, 32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging datasets\n",
    "df = pd.concat([audit_risk, trial], axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 773 entries, 0 to 775\n",
      "Data columns (total 32 columns):\n",
      "Sector_score      773 non-null float64\n",
      "LOCATION_ID       773 non-null int64\n",
      "PARA_A            773 non-null float64\n",
      "Score_A           773 non-null float64\n",
      "Risk_A            773 non-null float64\n",
      "PARA_B            773 non-null float64\n",
      "Score_B           773 non-null float64\n",
      "Risk_B            773 non-null float64\n",
      "TOTAL             773 non-null float64\n",
      "numbers           773 non-null float64\n",
      "Score_B.1         773 non-null float64\n",
      "Risk_C            773 non-null float64\n",
      "Money_Value       773 non-null float64\n",
      "Score_MV          773 non-null float64\n",
      "Risk_D            773 non-null float64\n",
      "District_Loss     773 non-null int64\n",
      "PROB              773 non-null float64\n",
      "RiSk_E            773 non-null float64\n",
      "History           773 non-null int64\n",
      "Prob              773 non-null float64\n",
      "Risk_F            773 non-null float64\n",
      "Score             773 non-null float64\n",
      "Inherent_Risk     773 non-null float64\n",
      "CONTROL_RISK      773 non-null float64\n",
      "Detection_Risk    773 non-null float64\n",
      "Audit_Risk        773 non-null float64\n",
      "Risk              773 non-null int64\n",
      "Marks             773 non-null int64\n",
      "MONEY_Marks       773 non-null int64\n",
      "Loss              773 non-null int64\n",
      "LOSS_SCORE        773 non-null int64\n",
      "History_score     773 non-null int64\n",
      "dtypes: float64(23), int64(9)\n",
      "memory usage: 199.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring & Scaling dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x258102d9d68>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtUAAAIYCAYAAACixRABAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzs3Xu8lWWd///Xe282JwERRUNS0fJQIpLiMTwXOo2ZljOKOUnlUI1aU1NNk/Mtc36N1TRTakcqJXuMZlkZTiWYRnRABeWokppa4iFEFAK2wIbP74/72rVYrn281oK19n4/H4/7wVrXfd2f+7rXXmvx2de+7utSRGBmZmZmZr3XtLMbYGZmZmbW6JxUm5mZmZllclJtZmZmZpbJSbWZmZmZWSYn1WZmZmZmmZxUm5mZmZllclJtZmZmZg1H0nWSVkla3sF+SbpG0qOSlko6omTfRZIeSdtF1WiPk2ozMzMza0QzgTM62f83wIFpmw58FUDSKOCTwDHA0cAnJe2W2xgn1WZmZmbWcCJiHrCmkypvAW6Iwt3ASEljgNOBOyJiTUS8ANxB58l5tzipNjMzM7O+aCzwZMnzlamso/IsA3IDWPf8pOXg7PXgH/3hiux2rFixNjvGsnlLsmMAHHbi4dkxRu85NDvGc6s2ZsfYc69dsmMAbNmyrSpxcrXVSTsATrpsYnaMb73vJ9kxJh4zLjsGQHOzsmO0tOTH2LBha3aMAVVoB8CWzfnvt8GDm7NjzL/r4ewYAAdP3C87xoAB+X1eu+02MDvG7d9bkB0D4KhTJ2THePTBp7JjHHvSAdkxqmX9+raqxLnyooHV+SBmqEaOU8mZbQ+/h2LYRrsZETGjByEqvTbRSXkWJ9VmZmZmVndSAt2TJLrcSmCfkuevBJ5O5SeXlc/NOA/g4R9mZmZmlkEtqslWBbOAd6RZQI4F1kbEM8BsYIqk3dINilNSWRb3VJuZmZlZw5F0E0WP8x6SVlLM6NECEBFfA34KvAl4FNgIvDPtWyPpP4D28U1XRkRnNzx2S02SakmXAxcAW4FtwHsi4p4eHD8OOD4ibqxF+8zMzMysOpoG7Jxh3RExtYv9AVzSwb7rgOuq2Z6qJ9WSjgPOBI6IiE2S9gB6erfEOIqkvNtJtaQBEVGdUf91cB4zMzMzaxy1GFM9BlgdEZsAImJ1RDwt6UhJv5R0n6TZaZ5AJL1a0s8lLZF0v6RXAZ8BTpC0WNIHJQ2WdL2kZZIWSTolHTtN0vcl3QbMqdQYSWMkzUuxlks6IZWfkc63RNKdqWyUpFvTqjt3S5qQyq+QNEPSHOAGSc2S/kvSglT3PTV4Hc3MzMzqnlqaarI1mloM/5gDfELSw8DPgZuB3wLXAm+JiOcknQd8GngX8L/AZyLiR5IGUyT6HwM+HBFnAkj6F4CIOEzSIcAcSQel8x0HTOhkLMwFwOyI+LSkZmCopNHAN4ATI+LxtLIOwKeARRFxtqRTgRuA9vm8jgQmR0SrpOkUg92PkjQI+I2kORHxeOmJU73pAJc27ckZTSN783qamZmZ1a2dNfyj3lQ9qY6I9ZKOBE4ATqFIqv8/YDxwhySAZuAZScOBsRHxo3TsSwCpTqnJFEk5EbFC0h+A9qT6ji4Gly8ArpPUAtwaEYslnQzMa0+CS46fDLwtld0laXdJu6Z9syKiNT2eAkyQdG56vivFEpjbJdWlU8HUag5HMzMzM9v5anKjYkRspZjvb66kZRSDxB+IiONK60ka0c2Qnf0KtKGLtsyTdCLwt8B3JP0X8CKVJ/nubDLwDWX1LouI7OlXzMzMzBpZlaa/a3hVH7Ai6WBJB5YUTQQeAkanmxiR1CLp0IhYB6yUdHYqHyRpKPBnYHhJjHnA21Odg4B9gd91sz37Aasi4hvAt4AjgPnASZL2T3Xah3+UnudkirHh6yqEnQ28L/V+I+kgSdVZUs/MzMzMGk4teqqHAddKGgm0UcwNOJ1iGMQ1aTjFAOCLwAPAPwBfl3QlsAX4O2Ap0CZpCTAT+ArwtdTr3QZMSzOLdKc9JwMfkbQFWA+8I43rng78UFITsAp4I3AFcL2kpRTzGV7UQcxvUsxQcr+KRjwHnN2tV8fMzMysD/GY6kItxlTfBxxfYddq4MQK9R8BTq1Q/7Sy59MqHDuTIunurD3fBr5dofxnwM/KytYAb6lQ94qy59uAj6fNzMzMzPo5r6hoZmZmZr3mMdUFFYvNND5JhwHfKSveFBHH7Iz2lLv6tvwX+tVvPSS7HavmdGsoeqf2GFGdtW9Wr8v/na65CncFjB31UnaMp9YMzm9IHdm0pTpxujdCq3MbNuZ/R71m3/wLevAPLdkxADZs3JYdY++9mrNjPPvc1uwYLVX6k++gQflxWl/Kf5+M3z//NQF47Nn877bn1+R/zw4Zkv8+OXCf6uQIq9flt2W/0ZuzYzz7Yk/Xoqtsa/7HmPVV+G4DuOxvq/FNm+eXr5lYk2TypIcW7/Rr64k+01MdEcv465zSZmZmZmY7TJ9Jqs3MzMxsx1NzQ3Uo10zjrQFpZmZmZlZnqpJUS1rfQfl0SSvSdq+kySX7WiR9RtIjkpan/X9Tsv91kkLS6en57pIWp+1ZSU+VPB9Y2gZJh0q6S9LDKf7/S1PfIWmapG2SJpTUXy5pXCfX94SkPdLjremcD0haIulDaVo+MzMzs36nqVk12RpNzYZ/SDoTeA8wOSJWSzoCuFXS0RHxLPAfwBhgfJpzei/gpJIQU4Ffp39nR8TzpDHTkq4A1kfE50vO1/7vEGAW8L6ImJMWk/kB8E/Al1P1lcDlwHm9uLTWiGhvx57AjRTLlH+yF7HMzMzMGpqaGi8BroVa9rD+K/CRiFgNEBH3U8wXfUlKdP+RYqnvTWn/nyLiewCpV/lcirmpp0jqydQKFwC/iYg5Ke5G4FLgYyV1/g84VNLBGddHRKyiWNjm0vaecDMzMzPrf2qZVB8K3FdWtjCVvxr4YwdLgAO8Hng8In4PzAXelHPeFGeYpBGpaBvwOaqweEtEPEbxOu5Zvi8Nf1koaeFvb5+ReyozMzOzuqPmpppsjWZHt1hAd+YynAp8Nz3+bnpejXOUlt8IHCtp/x7E7uycLz9ZxIyImBQRk44/Y3oVTmNmZmZm9aiWU+o9CBwJ3FVSdkQqfxTYV9LwiPhz6UGSmoG3AWdJupwiYd29Ut0OPEDZcuiSDqAYg/3n9lEaEdEm6b8phqn0Woq9FViVE8fMzMysETXiTYW1UMue6s8Bn5W0O4CkiRRjpL+Sxjl/C7hG0sC0f4ykC4E3AEsiYp+IGBcR+1HcaHh2N8/7v8BkSW9IcYcA16T2lJuZzje6NxcoaTTwNeBL0VeWpjQzMzPrATWpJlujqVZSPVTSypLtQxExC7gO+K2kFcA3gAsj4pl0zL8DzwEPSloO3JqeTwV+VBb/BxQ3IHYpIlqBtwD/Lul3wDJgAfClCnU3UyTcLxsP3Ykh7VPqAT8H5gCf6sHxZmZmZtbHVGX4R0RUTM4j4qvAVzvYtxn4aNpKza5QdxbFNHntz6+oUGdYyeNlwMkdnHcmRQ91+/NrKBLrDkXEuJLHzZ3VNTMzM+tPPPyj0Hi3VpqZmZmZ1Zla3qjYcCTdAwwqK/6H1POdZcWKtbkhGDHnd9kx9pySNTU3AKfO+UR2DIC7plyZHWPkkvJZG3vuQFZkxxg8+pDsGACjB63JjvHUxl7dIrCdepp1/eafbcqOceah+a/r8Xsuz44BcM8uU7JjPL8+/wd01CFt2TGqdSfJsIH5P+O1m3qynEFlr2+7q+tK3XDyLi9mx1i435uzY4wcuCE7xthNj2bHAFg29HXZMfYZ+kzXlbrw4sZx2TGq5ZBXVFyMuhdGdF2lxuSeasBJ9XYi4pid3QYzMzMzazxOqs3MzMys19Tk0cTgpNrMzMzMMjTi9He10JC/Wkjamqa1Wy7p+5KGluw7R1JIOqSkbJyk1nTMg5JukNRSFvNqSU9J6tZrIunHkuZX76rMzMzMrFE1ZFINtEbExIgYD2wG3luybyrwa+D8smN+HxETgcOAVwJ/374jJdLnAE9SthpjJZJGUqwOObJKy5ybmZmZNaSmZtVkazSNmlSX+hXwagBJw4DXA+/m5Uk1ABGxFbgXGFtSfAqwnGJO7andOOfbgNuA73Z0HjMzMzPrPxo6qZY0APgbilUToVjK/PaIeBhYI+mICscMBo4Bbi8pngrcRLGS45nlQ0MqaK9/E50k4ZKmS1ooaeGDd8/s3kWZmZmZNRAvU15o1KR6iKTFwELgj8C3UvlUit5j0r+lCe+r0jHPA3+MiKUAkgYCbwJujYh1wD1AhxPJStqLomf81yl5b5M0vlLdiJgREZMiYtJrj53Wuys1MzMzq2NqaqrJ1mgadfaP1jQ++i8k7Q6cCoyXFEAzEJLal0H/fURMlDQGmCvprLT8+RnArsAyFSteDAU2Aj/p4NznAbsBj6f6IyiGgPx7NS/QzMzMzBpH4/0a0LFzgRsiYr+IGBcR+wCPA5NLK0XEM8DHgH9LRVOBi9Mx44D9gSmlM4qUmQqcUVL/SDyu2szMzPopD/8o9KWkeirFmOhSPwAuqFD3VmCopJOA0ynplY6IDRSzh7xsjVhJ44B9gbtL6j8OrJPk1RjNzMzM+qmGHP4REcMqlJ1coeyakqfjS8oDODw9HVXhuLd2cN4n2H7WkPbyl90QaWZmZtYfNOL0d7XQkEm1mZmZmdWHRhyqUQtOqjsg6Z3AB8qKfxMRl/Qm3rJ5S7Lb9KZTX58d49Q5n8iOcdeUK7NjAJx2++XZMR4ftDY7xojFv8qOMWrimOwYAAPjpewYew15ITtGi7ZkxwAI8r9ol817PDvGmGP+lB1jxStOy44B0Lo+/2t32KCt2THatuX/bEYObs2OATCqJf9zvGXb7vkx/q98BGHvrP37y7JjtGzN/xlvifz32pD7fp4dA2Ds5Jf9kbfHxqxcmB1j2LB9smNUy+4DX6xSpBFVimO5nFR3ICKuB67f2e0wMzMzq2eNOP1dLfhVMDMzMzPL5J5qMzMzM+s1j6kuNGRPtaTLJT0gaamkxTtjOjtJ50gKSYfs6HObmZmZWX1puJ5qSccBZwJHRMQmSXsAAzPiDYiItl4cOpViPuvzgSt6e34zMzOzRuae6kIj9lSPAVZHxCaAiFgdEU9LOkrSbyUtkXSvpOGSBku6XtIySYsknQIgaZqk70u6DZiTyj4iaUHq/f5UZw2QNAx4PfBuvJqimZmZ9WNeUbHQiEn1HGAfSQ9L+oqkkyQNBG4GPhARhwNvAFqBSwAi4jCKnuVvSxqc4hwHXBQRp0qaAhwIHA1MBI6UdGInbTgbuD0iHgbWSKq4+Iuk6ZIWSlr47B9uy75wMzMzM6tPDZdUR8R64EhgOvAcRTL9HuCZiFiQ6qxLQzomA99JZSuAPwAHpVB3RMSa9HhK2hYB9wOHUCTZHZkKfDc9/m56XqmtMyJiUkRMesV+L1v13MzMzKzhqampJlujabgx1QARsRWYC8yVtIyiRzoqVO3sbwcbyupdFRFf7+rcknYHTgXGSwqgGQhJH03Ln5uZmZlZP9NwvwZIOlhSaS/yROAhYG9JR6U6wyUNAOYBb09lBwH7Ar+rEHY28K40VhpJYyXt2UETzgVuiIj9ImJcROwDPE7RK25mZmbWrzQ1qyZbo2nEnuphwLWSRgJtwKMUQ0GuT+VDKMZTvwH4CvC11JvdBkxLM4ZsFzAi5kh6DTA/7VsPXAisqnD+qcBnysp+AFwA5K93bWZmZtZAGvGmwlpouKQ6Iu4Djq+wazVwbIXyaRVizARmlpVdDVzdjfOfXKHsmq6OMzMzM7O+q+GSajMzMzOrH414U2EtOKnuQLoh8c4Ku06LiOd7Gu+wEw/PbtPqdfk/rrumXJkd47TbL8+OAXDnGZ/OjrHb0nOyY+zxmtdnx3hh84jsGAADBvZmHaLtrWrdLTtGcQ9ufTjsxPzX9tmxPf7IvsxBz/0mOwbAC7tMyY7x/Pper3f1F7sN3ZIdY/3mwV1X2kE2bmnJjtFy+luq0BIY9czy7BiP7bF/doxdBryUHeOlI07NjgHw9Eujs2M0jz0yO8aG55qzYwBUY1qCNVt2zQ9idcVJdQdS4jxxZ7fDzMzMrJ55THXBSbWZmZmZ9ZqT6oIHwZiZmZmZZepTSbWkrZIWS1ou6bY07R6S9pZ0SyfHjZPUo0Fwkq6W9JSkPvUampmZmfWEV1QsNF6LO9caERMjYjywhmKlRSLi6Yg4t1onSYn0OcCTwInVimtmZmZmjamvJdWl5gNjYfueaEmHSro39WgvLVudEUkHSFrUvjpjB04BlgNfpVgMxszMzKxfUpNqsjWaPplUS2oGTgNmVdj9XuDqiJgITAJWlhx3MMXqiO+MiAWdnGIqcBPwI+BMSRXncpI0XdJCSQsfvHtmr67FzMzMzOpfX0uqh0haDDwPjALuqFBnPvBxSf8K7BcRral8NPBj4MKIWNzRCSQNBN4E3BoR64B7gIoTz0bEjIiYFBGTXnvstN5ek5mZmVnd8pjqQuO1uHOtqQd6P2AgaUx1qYi4ETgLaAVmS2qf2X4txRjprlYCOQPYFVgm6QlgMh4CYmZmZv2VVJutwfS1pBqAiFgLvB/4cPnQDEkHAI9FxDUUw0MmpF2bgbOBd0i6oJPwU4GLI2JcRIwD9gemSBpa5cswMzMzswbRJ5NqgIhYBCwBzi/bdR6wPA0TOQS4oeSYDcCZwAclvWy92pQ4nw78pOyYXwNvrvY1mJmZmdU736hY6FMrKkbEsLLnpYnu+FR2FXBV2aFrSva/CFSc+SMiNlKM1S4vf2vvW21mZmZmja5PJdVmZmZmtmM14k2FteCkugOSTgc+W1b8eESc05t4o/fMH3LdXIX37Mgl92XHeHzQ2vyGALst7dVLuZ0XJkzKjrFt6Y110Q6AF1vy/9w1Zsmvs2O0qC07BsC2yH/Tjt5zZHaMlm1PZ8e4Z5eKk/z02MbN9fG1+1Jbc3aMscOr810wWn/KjjFgyJjsGG3aJTsGgBbMy44x5LQzsmPEZflrnq36cv73I8DusS47Rsu2TdkxIrJDVM3Y5qeqFGnXKsXpvUYcqlEL9fHtXociYjYwe2e3w8zMzMzqn5NqMzMzM+u1nTX8Q9IZwNVAM/DNiPhM2f4vUKyCDTAU2DMiRqZ9W4Flad8fI+Ks3PY4qTYzMzOzhpJWz/4y8EaK1bEXSJoVEQ+214mID5bUvwx4XUmI9rVNqqYhR5ZL2ippsaTlkr5fOke0pHMkhaRDSsrGSWpNxzwo6YYK81dfLekpSZ2+JpKmSXouxXpA0i2eo9rMzMz6q500pd7RwKMR8VhEbAa+C7xsOuQSU4GbqnTJFTVkUk367SIixlMs2vLekn1TKeaNLp+f+vfpN5LDgFcCf9++IyXS51CsqHhiN85/czr/oen85/X6SszMzMwa2E5KqsdS5G3tVqayl7dP2o9isb67SooHS1oo6W5JZ+dcf7tGTapL/Qp4NYCkYRTLjL+blyfVAETEVuBetn/hTwGWA1+lB0uOSxoA7AK80JuGm5mZmVllkqanxLd9m166u8IhHc3vcj5wS8oB2+0bEZOAC4AvSnpVbnsbOqlOSe3f8NeB5mcDt0fEw8AaSUdUOGYwcAxwe0lx+58EfgScWT40pILz0oqMT1EsBnNbB+37y5vh/rnf7MGVmZmZmTWIpqaabBExIyImlWwzSs66Etin5PkrgY7mTz2fsqEfEfF0+vcxYC7bj7fu3cuQG2AnGZKS2oXAH4FvpfKpFGNqSP+W9jq/Kh3zPMVdnksBJA0E3gTcGhHrgHuAriakvTkNJXkFRUL/kUqVSt8MR5x8cU+v0czMzMwqWwAcKGn/lMudD8wqryTpYGA3YH5J2W6SBqXHe1CMcniw/NieatTZP152x6ak3YFTgfGSgmJ6lZD00VTl9xExUdIYYK6ksyJiFnAGxczpyyRBMeXKRuAnXTUiIkLSbcBlwGe6qm9mZmbW16T8aYeKiDZJl1KsKdIMXBcRD0i6EliYcjxIHa4R2y398xrg65K2UXQwf6Z01pDeatSkupJzgRsi4j3tBZJ+CUymZCB7RDwj6WPAv1H8RjMVuDgibkrH7AI8LmloRGzsxnknA7+v3mWYmZmZWVci4qfAT8vKPlH2/IoKx/2WYuKKqmrU4R+VTKUYE13qBxQD0MvdCgyVdBJwOiW90hGxgWL2kDd3cq7z0pR6SynG4PxHTsPNzMzMGpWammqyNZqG7KmOiGEVyk6uUHZNydPxJeUBHJ6ejqpw3Fs7OfdMYGa3G2tmZmbWh3Vj+rt+ofF+DTAzMzMzqzMN2VO9I0h6J/CBsuLfRMQlvYn33KruDM/u3ElHbMuOcSArsmOMWPyr7BgAe7zm9dkxti29MTvGwgmVRgj1zKQqtANgwNZN2TFeaPpzdoyB217KjgEQnS9Q2i3PrRqYHWP0sjuyY6wa/w/ZMQD+8NzL/jjWY68YuSU7xvPru5o5tGt7D69O71RUnG62Z7Zsa86O8dg/fzw7BsC+X/qf7BjrNg/OjjHq2h9mx9h37jVdV+qG1Sd2ewmIDlXjczx8/wOzYwBER7Mh9yRGFd73daMBh2rUgpPqDkTE9cD1O7sdZmZmZlb/nFSbmZmZWa95THXBSbWZmZmZ9ZqqMNSvL2jIV0HS5ZIekLQ0TW13zA4+/9Z03iWS7pd0/I48v5mZmZnVl4brqZZ0HHAmcEREbErLS/b6TiZJAyKirYeH/WVFR0mnA1cBJ/W2DWZmZmYNy8M/gMbsqR4DrI6ITQARsToinpZ0lKTfpt7jeyUNlzRY0vWSlklaJOkUAEnTJH0/LTE+J5V9RNKC1Pv9qR60ZwTwQrUv0szMzMwaR8P1VFMkwZ+Q9DDwc+BmYH7697yIWCBpBNBKmhIvIg6TdAgwR9JBKc5xwISIWCNpCnAgcDQgYJakEyNiXgdtGCJpMTCYIsk/tVIlSdOB6QAnvvULvPbYaZmXbmZmZlZfGnH1w1pouKQ6ItZLOhI4ATiFIpn+NPBMRCxIddYBSJoMXJvKVkj6A9CeVN8REWvS4ylpW5SeD6NIsjtKqkuHfxwH3CBpfFqpsbStM4AZAO/7rxerMKulmZmZWX3x7B+FhkuqASJiKzAXmCtpGXAJUClp7eynvKGs3lUR8fVetGV+Gtc9GljV0+PNzMzMrPE1XH+9pIMllS6JNBF4CNhb0lGpznBJAyh6mt+eyg4C9gV+VyHsbOBdkoalumMl7dnN9hwCNAPP9/KSzMzMzBqXmmqzNZhG7KkeBlwraSTQBjxKMW75+lQ+hGI89RuArwBfS73ZbcC0NGPIdgEjYo6k1wDz0771wIV03PPcPqYail7ui1LvuZmZmZn1Qw2XVEfEfUCleaFXA8dWKJ9WIcZMYGZZ2dXA1d1sQ3N36pmZmZn1dR5TXWi4pNrMzMzM6ohn/wCcVHdI0u7AnRV2nRYRPR4/vedeu2S36ak1LdkxBo8+JDvGqIljsmMAvLB5RH6MCZOyY0xaemN2jIUTLsiOAaCW/N/2xyz5dXaMFg3JjgGwLfK/aKvx2Vl12JTsGC++NDQ7BsDoXXu61tTLrd+U/8eykbvkt0MV7w/fOXFamvJH4B3wxf/MjgHQ8ssfZccYcdrB2TGaLntrdow/fjn/+xGgLaqQblThc/zn1fXzh2YN96RgfY2T6g6kxHnizm6HmZmZWT0rv1etv3J/vZmZmZlZJvdUm5mZmVnveUw10Md6qiVtlbRY0nJJt6Vp95C0t6RbOjlunKTl3TzHyZLWpvMslfTz7s5pbWZmZmZ9U59KqknLh0fEeGANxUqLRMTTEXFuFc/zq3SeCcCC9vOYmZmZ9TdqUk22RtPXkupS84GxsH1PtKRDJd1b0tNcujojkg6QtKh9dcbOqBiZPxx4oQbtNzMzM6t/XlER6KNJtaRm4DRgVoXd7wWujoiJwCRgZclxBwM/AN4ZEQs6OcUJaUXFP1Ks3HhdB+2YLmmhpIX3/eKbvbsYMzMzM6t7fS2pbl8+/HlgFHBHhTrzgY9L+ldgv4hoTeWjgR8DF0bE4grHlWof/rEPxfLon6tUKSJmRMSkiJh05CkX9+Z6zMzMzOpbk2qzNZi+llS3ph7o/YCBVBjrHBE3AmcBrcBsSaemXWuBJ4HX9/Ccs4ATe91iMzMzM2t4fXJKvYhYK+n9wI8lfbV0n6QDgMci4pr0eALwGLAZOJsi0V6fku/umAz8vorNNzMzM2sYasDxz7XQJ5NqgIhYJGkJcD7wq5Jd5wEXStoCPAtcCYxIx2yQdCZwh6QNEfHjDsK3j6kWRQ+3x3aYmZlZ/9SAQzVqoU8l1RExrOz5m0uejk9lVwFXlR26pmT/i0CHM39ExFxg1yo018zMzMz6iD6VVJuZmZnZjiWvqAg4qe6QpNOBz5YVPx4R5/Qm3pYt2/IbVQWjB63JjjEwXqpCS2DAwLbsGC+25P/JacDWTdkxVIV2AMSWyI4h6iMGQJPy3/fV+Oy0VOFnPGTAluwYAJu2NGfHUBXebtWJUaX3SWzNj1GF99qAzRuyYwBs3djadaUuVON6qmEQ1fm+38ou2TGq8Tmuxvu+Wqrxvrf64qS6AxExG5i9s9thZmZmVtfq6beVnchJtZmZmZn1nod/AH1snmpJu6flxxdLelbSUyXP95X0Y0mPSPq9pKslDZR0ekmd9ZJ+lx7fUBL36hSrqaRsmqQv7ZwrNTMzM7N60qd6qiPieWAigKQrgPUR8XlJAu4BvhoRb0nLmM8APh0RHyEN85A0F/hwRCxsj5kS6XMoFoY5EZi7wy7IzMzMrN55+AfQx3qqO3Eq8FJEXA8QEVuBDwLvkjS0i2NPAZYDXwWm1rSVZmZmZtaQ+lRPdScOBe4rLYiIdZL+CLwaWNrJsVOBm4AfA/8pqSUiqjMNgJmZmVmD85R6hf7yKggqzhHWUXmxUxoIvAm4NSLWUQwhmdLtk0rTJS2UtHDRL7/ZwyabmZmZWaPoLz3VDwBvKy2QNALYB/h9J8edQbF64rJiWDZDgY3AT7pz0oiYQTF2m49/a1N1JnQ1MzMzqyfqL31zvDyHAAAgAElEQVS0nesvr8KdwFBJ7wBINyr+NzAzIjZ2ctxU4OKIGBcR44D9gSndGIdtZmZm1j80qTZbg+kXSXVEBMUMHn8n6RHgYeAl4OMdHZMS59Mp6ZWOiA3Ar4E3p6JpklaWbK+s1TWYmZmZWf3qs8M/IuKKsudP8tdkuKNjTi55vBEYVaHOW0uezsxpo5mZmVmjk4d/AP2kp9rMzMzMrJb6bE+1mZmZme0ADTj+uRacVPczT20cnR1jryEvVKElsKp1t+wYY5b8OjvGC01/rot2AKjjGR677anXTs6OsdfxLxv51CsbVrXmB/nwPdkhhq99MjtGy8hx2TEABrVszY6x7qX8r+5hA/On24+ozn+kqzQmP0gV5lca8Ofn84MAK8/5UHaMgVVYDiGuvSU7RlNU5/u+9d1v7bpSF4Z/rsPboLptfevE7BgAQwblv+Gq8r4HxlYlSiYP/wA8/MPMzMzMLJt7qs3MzMys9+ThH9CPe6olzZU0aWe3w8zMzMwan3uqe0HSgIho29ntMDMzM9vpmvptH+126v5VkDRO0kOSviHpAUlzJA0p7WmWtIekJ9LjaZJulXSbpMclXSrpQ5IWSbpbUukdWBdK+q2k5ZKOTsfvIuk6SQvSMW8pift9SbcBcySNkTRP0uJ0/Ak7+KUxMzMz2/nUVJutwTRKiw8EvhwRhwIvAm/rov544ALgaODTwMaIeB0wH3hHSb1dIuJ44J+A61LZ5cBdEXEUcArwX5J2SfuOAy6KiFNT/NkRMRE4HFiceY1mZmZm1qAaJal+PCLak9b7gHFd1P9FRPw5Ip4D1gK3pfJlZcfeBBAR84ARkkYCU4CPSVoMzAUGA/um+ndExJr0eAHwTklXAIdFxMvmZZM0XdJCSQsX/fKb3b1WMzMzs8bRpNpsDaZRkupNJY+3UowFb+Ov7R/cSf1tJc+3sf048vKJJgMQ8LaImJi2fSPiobR/w18qFon4icBTwHckvYPyYBEzImJSREx63UkXd3WNZmZmZtagGiWpruQJ4Mj0+NxexjgPQNJkYG1ErAVmA5dJxfwwkl5X6UBJ+wGrIuIbwLeAI3rZBjMzM7PG5THVQGPP/vF54HuS/gG4q5cxXpD0W2AE8K5U9h/AF4GlKbF+AjizwrEnAx+RtAVYz/Zjtc3MzMysH6n7pDoinqC48bD9+edLdk8oefzvaf9MYGZJ/XElj/+yLyJO7uB8rcB7KpSXx/028O1uXYSZmZlZX+XFX4AGSKrNzMzMrI55nmqgscdUm5mZmZnVBfdU7yBtW7Zlx9i0Jb8d1fgLTYuq0BBAKp98pedalL+w5cBtL1WhHUOyYwDoZRPS9Nxex4/qulIX/vTbNV1X6ga15L/hqvHZGbD+hewYg0Ztzo4B0NLUUpU4uQY05b+uLU3VWVh2QBU+x1u25b+uerE67/tB+2zMjrG1qTk7RjW+Y4dsetlssb1Sje+U8VX4HCv/Za2awU2buq7UKDz8A3BPtZmZmZlZNvdUm5mZmVnvNeD0d7XgpNrMzMzMes83KgJ1NvxD0uWSHpC0VNJiScfs4PNvTeddIul+Scd3UO/Tkp6UtH5Hts/MzMzM6lPd9FRLOo5ikZUjImKTpD2AgRnxBkRET+9+aY2Iien404GrgJMq1LsN+BLwSG/bZ2ZmZtYn+EZFoL56qscAqyNiE0BErI6IpyUdJem3qff4XknDJQ2WdL2kZZIWSToFQNI0Sd+XdBswJ5V9RNKC1Pv9qR60ZwRQ8VbjiLg7Ip7Ju1wzMzMz6yvqpqeaIgn+hKSHgZ8DNwPz07/nRcQCSSOAVuADABFxmKRDgDmSDkpxjgMmRMQaSVOAA4GjAQGzJJ0YEfM6aMMQSYuBwRRJ/qk5FyRpOjAdYMoF13L4Ce/OCWdmZmZWf3yjIlBHPdURsR44kiIJfY4imX4P8ExELEh11qUhHZOB76SyFcAfgPak+o6IaJ8Qc0raFgH3A4dQJNkdaY2IiRFxCHAGcIPU+79pRMSMiJgUEZOcUJuZmVmfJNVm6/K0OkPS7yQ9KuljFfZPk/Rcul9usaSLS/ZdJOmRtF1UjZehnnqqiYitwFxgrqRlwCVQcTWMzl7pDWX1roqIr/eiLfPTuO7RwKqeHm9mZmZmtSGpGfgy8EZgJbBA0qyIeLCs6s0RcWnZsaOATwKTKPLM+9KxWSsM1U1PtaSDJZX2Ik8EHgL2lnRUqjNc0gBgHvD2VHYQsC/wuwphZwPvkjQs1R0rac9utucQoBl4vpeXZGZmZtb3NTXVZuvc0cCjEfFYRGwGvgu8pZstPp00siEl0ndQjFDIUjdJNTAM+LakByUtBV4LfAI4D7hW0hKKix4MfAVoTr3ZNwPT2m9wLBURc4Abgfmp7i3A8E7aMKT9TwQp7kWp95xURnr8OUkrgaGSVkq6IvfizczMzKzbxgJPljxfmcrKvS1NVnGLpH16eGyP1M3wj4i4D6g0L/Rq4NgK5dMqxJgJzCwruxq4upttaO5k38SSxx8FPtqdmGZmZmZ9WdRoSr3SCR+SGRExo313paaUPb8NuClN1fxe4NsUk1B059geq5uk2szMzMysXUqgZ3SweyWwT8nzVwJPlx1fOoT3G8BnS449uezYuRlNBfphUi1pd+DOCrtOK3vx6069zK0end4numNti/wRTFGFqYCq0Q6AJm3LjrFhVWt2DLVU52ccW7J/8a+KaOrwj1Ddtq1K7/t6+vzkiqjOtWyrl5GIA6rzX+I25b/fqvE+qUaMbVX47EB1vlOq8TmO+vhKAqr3/0Zd2DlT6i0ADpS0P/AUcD5wwXbNksaUrCtyFsW9elDcc/efknZLz6cA/5bboH6XVKfEeWKXFc3MzMysazshqY6INkmXUiTIzcB1EfGApCuBhRExC3i/pLOANmANaehwWsvkPygSc4ArS6Zj7rV+l1SbmZmZWeOLiJ8CPy0r+0TJ43+jgx7oiLgOuK6a7XFSbWZmZma9VqsbFRtNHxrQA5K2pinxlku6TdLIVL63pFs6OW6cpOU9OM/RkualVXxWSPqmpKHVuAYzMzMzazx9Kqnmr8uMj6cYO3MJQEQ8HRHnVuMEkvYCvg/8a0QcDLwGuJ3O5782MzMz65vUVJutwTRei7tvPmki79KeaEmHSro39WgvLVvFEUkHSFrUvopjBZcA346I+QBRuCUi/lTDazEzMzOrT1JttgbTJ5PqtB78acCsCrvfC1ydFnOZRDFXYftxBwM/AN4ZEQsqHAswHrivm+2YLmmhpIVLfvWtnlyCmZmZmTWQvnaj4pC0nPg4isT3jgp15gOXS3ol8MOIeETFb0OjgR8Db4uIB6rRmNJJyz/6tdY6mh3TzMzMrEqa+mQfbY/1tVehNfVA7wcMJI2pLhURN1JMAN4KzJZ0atq1lmId+Nd3cY4HgCOr1mIzMzMza3h9LakGICLWAu8HPiyppXSfpAOAxyLiGorhIRPSrs3A2cA7JG23Ik+ZLwEXSTqmJOaFkl5RzWswMzMzawQh1WRrNH0yqQaIiEXAEoplK0udByxPw0QOAW4oOWYDcCbwQUlv6SDun1LMz6cp9R4CTgDWVf8qzMzMzOqcZ/8A+tiY6ogYVvb8zSVPx6eyq4Cryg5dU7L/RaCjmT/a486nSKTNzMzMzPpWUm1mZmZmO1Y0YK9yLSjCk1JUIul04LNlxY9HxDm9ifeTloOzX+hHf7giNwQrVqzNjrFs3pLsGACHnXh4dozRe+YvZPncqo3ZMfbca5fsGABbtmyrSpxcbXXSDoCTLpuYHeNb7/tJdoyJx4zLjgHQ3Jw/TrClJT/Ghg1bs2MMqEI7ALZszn+/DR7cnB1j/l0PZ8cAOHjiftkxBgzIT1J2221gdozbv9fR7LI9c9SpE7qu1IVHH3wqO8axJx2QHaNa1q9vq0qcKy8auNMHH6+/e1ZNkslhx56106+tJ9xT3YGImA3M3tntMDMzM6trDXhTYS24v97MzMzMLJN7qs3MzMys1zymulC1V0FSSPpOyfMBkp6T9H/VOkcv2jQ3jY0uLftnSV/p4rj1tW2ZmZmZWR8h1WZrMNX81WIDMF7SkPT8jUD+XQV5buLl81Sfn8rNzMzMzKqi2v31PwP+Nj2eSknyKmmUpFslLZV0t6QJqfwKSdelXuXHJL2/5JgLJd0rabGkr0tqlvRuSV8oqfOPkv6ng/bcApwpaVCqOw7YG/i1pGGS7pR0v6RllRZ7kXRyaU+7pC9JmpYeHynpl5LukzRb0pjevGBmZmZmDc2LvwDVT6q/C5wvaTDF8t/3lOz7FLAoIiYAH6dkJUOKlQ1PB44GPimpRdJrKFY/fH1ETAS2Am9P5zirZPnxdwLXV2pMRDwP3AuckYrOB26OYh7Bl4BzIuII4BTgv6Xu/a0hnfta4NyIOBK4Dvh0d441MzMzs76nqjcqRsTS1Bs8Ffhp2e7JwNtSvbsk7S5p17TvJxGxCdgkaRWwF3AacCSwIOW6Q4BVEbFB0l0UPdAPAS0RsayTZrUPAflx+vddqVzAf0o6EdgGjE3nfbYbl3owxQqMd6S2NQPPlFeSNB2YDnBp056c0TSyG6HNzMzMGkc04PjnWqjF7B+zgM8DJwO7l5RXesXbJwvfVFK2NbVLwLcj4t8qHPdNit7uFXTQS13iVuB/JB0BDImI+1P524HRwJERsUXSE8DgsmPb2L43v32/gAci4rjOThwRM4AZUJ3FX8zMzMzqTgMO1aiFWrwK1wFXVug9nkeRyCLpZGB1RKzrJM6dwLmS9kzHjJK0H0BE3APsA1xAFzcdRsR6YG5qV2ndXSl6vrdIOgWotATWH4DXShqUetVPS+W/A0ZLOi61rUXSoZ21w8zMzMz6rqr3VEfESuDqCruuAK6XtBTYCFzURZwHJf07MEdSE7AFuIQi0QX4HjAxIl7oRrNuAn7I9jOB/C9wm6SFwGKKXu/yNjwp6XvAUuARYFEq3yzpXOCalGwPAL4IPNCNtpiZmZn1GVFxMEL/U7WkOiKGVSibS9FLTESsAV42w0ZEXFH2fHzJ45uBmzs45WTgCx3sKz/HjygbfhIRq4GKwzdKryUiPgp8tEKdxcCJ3Tm/mZmZmfVtDbeioqSRFDN6LImIO3d2e8zMzMz6M6+oWGi4pDoiXgQOKi2TtDvFGOxyp6Vp9Xa6b73vJ9kx3rvvluwYZx66JjvGmGP+lB0D4Nmx+T+alm1PZ8cYveyO7BirDpuSHQOgZeumrit1YfjaJ7NjDFjfnVFVXYum5uwYb6/CZ+fdX/3brit14biLv5kdA+A3Wzq9v7lbhg3cnB1j09b8n81+w1dlxwDYtS3/u2BVU/5SAe++/z+zYwAMf23+++3hvU/rulIXdm1amx3jvU/cmB0DYNCBv8uOcedl+TPXDrp4aXYMgGZty45x8MBHqtASKGYw3smcVAMNmFRXkhLniTu7HWZmZmbWP/WJpNrMzMzMdg7PU11wf72ZmZmZWaa6S6olXS7pAUlLJS2WdMwOPn9I+k7J8wGSnpP0f5LGSVqZpvgrPWaxpKN3ZDvNzMzM6kGoqSZbo6mr4R9pMZUzgSMiYpOkPYCBGfEGRERbDw/bAIyXNCQiWoE3Ak8BRMQTkp4ETgB+mc5xCDA8Iu7tbTvNzMzMrLHV268BYyhWWtwExVzSEfG0pKMk/VbSEkn3ShouabCk6yUtk7QorYqIpGmSvi/pNmBOKvuIpAWp9/tT3WjHz4D227ensv1KjDex/SIy59PFqo5mZmZmfZZUm63B1FtSPQfYR9LDkr4i6SRJAykWgPlARBwOvAFopVhdkYg4jCLx/bakwSnOccBFEXGqpCnAgcDRFDOEHCmpq0Vbvgucn+JNAO4p2fc94GxJ7b3856X6ZmZmZv2Oh38U6qrFEbEeOBKYDjxHkUy/B3gmIhakOuvSkI7JwHdS2QqK5cvb56++I63gCDAlbYuA+4FDKJLsztqxFBhHkaz/tGzfsxTLkZ8maSKwJSKWV4ojabqkhZIWPr7cebeZmZlZX1VXY6oBImIrxdLmcyUto+iRjgpVO/u7wIayeldFxNd72JRZwOeBk4Hdy/a1DwH5E50M/YiIGcAMgLe+/9FK12BmZmbW0KLTlKz/qKueakkHSyrtRZ4IPATsLemoVGd4GnoxD3h7KjsI2BeotGTTbOBdkoalumMl7dmN5lwHXBkRyyrs+wHwJjz0w8zMzMyov57qYcC1kkYCbcCjFENBrk/lQyjGU78B+ArwtdSb3QZMSzOGbBcwIuZIeg0wP+1bD1wIdLq+bkSsBK7uYN+Lku4G9oqIx3t7sWZmZmaNrhHHP9dCXSXVEXEfcHyFXauBYyuUT6sQYyYws6zsajpIkCscP6xC2VyKISmlZW/pTjwzMzOzPq0BZ+qoBf9qYWZmZmaWSRH97/45SbsDd1bYdVpEPF+Lc175v23ZL/SI4c3Z7bh4z9uyYzw86vXZMQAOWvOb7Bj37DIlO8bIQRuzY7y4aWh2DIAhA7Zkx2hp2podY1DT5uwYANuqcPPKrHt3y45x6WHzs2PMP/Li7BgAa3+xIjtGvXQKDRuc/14DGDRgW3aMjZvzvx8njHoiOwZAfOr92TGWXTYrO8bRIx7IjrFuwKjsGACbt/V6Hbe/eGVrpdumeub2dZOzY0B1PoO7D8v/vgeYcvjAnf6NsOrBhTVJJvd87aSdfm09UVfDP3aUlDhP3NntMDMzM7O+oV8m1WZmZmZWHVEvfz7byZxUm5mZmVmvefaPgl8FMzMzM7NMfSaplrRV0mJJyyXdlua6RtLekm7p5LhxkiouM16h7smS1kpaJOl3kuZJOrNa12BmZmbWaALVZGs0fSapBlojYmJEjAfWUCxvTkQ8HRHnVvE8v4qI10XEwcD7gS9JOq2K8c3MzMyswfSlpLrUfGAsbN8TLelQSfemHu2lZUuiI+mA1At9VHdOEhGLgSuBS6vcfjMzM7OGEGqqydZoGq/FXZDUDJwGVJrk873A1RExEZgErCw57mDgB8A7I2JBD055P3BIB22ZLmmhpIUL7/pGD0KamZmZWSPpS7N/DJG0GBgH3AfcUaHOfOBySa8EfhgRj6iYBmY08GPgbRHR09nyOxz0ExEzgBlQncVfzMzMzOqNp9Qr9KWe6tbUA70fMJA0prpURNwInAW0ArMlnZp2rQWeBHqzVODrgId61WIzMzOzBucbFQt9KakGICLWUtxA+GFJLaX7JB0APBYR11AMD5mQdm0GzgbeIemC7p5L0gTg/wFfrkbbzczMzKwx9aXhH38REYskLQHOB35Vsus84EJJW4BnKW4yHJGO2ZCmx7tD0oaI+HEH4U+QtAgYCqwC3h8Rd9bqWszMzMzqWSPeVFgLfSapjohhZc/fXPJ0fCq7Criq7NA1JftfBDqc+SMi5gK7VqG5ZmZmZtaH9Jmkut41N+ePDdqwcVt2jHt2mZIdo3V9dd42L1ShLRs357flD8+Nyo4xete27BgAm7Y0Z8cY1LI1O0ZLU0vXlbqhGmPiqvHZ+c2W47Jj/PkXK7JjAOx6SsXJgnqk9df5t3Hs9y/HZ8d46gu/yY4BsKmtPnq51m6rTp/Jyg909IfO7nvjwk9kx1hxyr9kx3jVusXZMQCWDjwmO8YfqvA5bqrSW21Ac/7cA/Xyvq+GRhz/XAtOqiuQdDrw2bLixyPinJ3RHjMzM7N65eEfBSfVFUTEbGD2zm6HmZmZmTUGJ9VmZmZm1mse/lFwf72ZmZmZWaaaJNWStkpaLOkBSUskfUgqBtxImiTpmk6OHdfZXNGS9pZ0Sxfn/2dJQ7uo84SkPbq6FjMzMzPrWKipJlujqVWLWyNiYkQcCrwReBPwSYCIWBgR7+/k2HFAxaRa0oCIeDoizu3i/P9MMY+0mZmZmdWQV1Qs1PzXgIhYBUwHLlXhZEn/ByDppNSjvVjSIknDgc9QLLCyWNIHJU2T9H1JtwFzUk/28nR8s6TPS1omaamkyyS9H9gb+IWkX/SkrZJGSbo1xbo7rZhYsZ2Sxkial8qWSzqhii+bmZmZmTWQHdK3HhGPpXPtWbbrw8AlETEROAFoBT4G/Cr1dH8h1TsOuCgiTi07fjqwP/C6iJgA/G9agvxp4JSIOKWHTf0UsCjF+jhwQyftvACYncoOB142maek6ZIWSlq44M5v9LApZmZmZvUvpJpsjWZHDlip9Or8Bvif1Ls8MiI6WkHjjohYU6H8DcDX2o/roE5PTAa+k2LdBewuadcO2rkAeKekK4DDIuLP5cEiYkZETIqISUed9o+ZTTMzMzOzerVDkmpJBwBbgVWl5RHxGeBiYAhwt6SOlhrb0FFoIH9Zo+3jlYtK7YyIecCJwFPAdyS9o4rtMDMzM2sIEarJ1mhqnlRLGg18DfhSRETZvldFxLKI+CywEDgE+DMwvJvh5wDvlTQgxWtfb7onMUrNA96eYp0MrI6IdZXaKWk/YFVEfAP4FnBEL85nZmZmZn1ArRZ/GSJpMdACtFEMqfifCvX+WdIpFL3YDwI/A7YBbZKWADOBFzo5zzeBg4ClkrYA3wC+BMwAfibpmS7GVS+VtC09/h5wBXC9pKXARuCiTtp5PvCRdN71gHuqzczMrN8JL3sC1CipjojmTvbNBeamx5d1UO20suczS45/AhifHrcBH0pb6TmuBa7too3jOtj1lgp1K7Xz22kzMzMz67cacfq7WvAy5TtIS0v+G270qPzfBJ9fn9+OYYO2ZscAeH79wKrEyfWKkVuyY6zf1OHvkT1SjZud173Utz7WLS35t00MG7g5O8b6l6rzM2799UPZMYZMfk12jAPv/Wp2jBeaqvNdMGhAR/eod1/rlvz3fWvboOwYAJva8r+r1530d9kxnlq3a3aMLcOOzI4B8PSa/KUj9hr+UnaMgVMOz44B0LYu/z07bPGiKrQE+nMqJ+kM4GqgGfhmugeudP+HKO6JawOeA94VEX9I+7YCy1LVP0bEWbnt6fM/CUn3AOXflP8QEcsq1TczMzOz7tsZPdWSmoEvUywyuBJYIGlWRDxYUm0RMCkiNkp6H/A54Ly0rzVNi1w1fT6pjohjdnYbzMzMzKyqjgYeTWuhIOm7FEN4/5JUR0TpIoB3AxfWskEeWW5mZmZmvbaTlikfCzxZ8nxlKuvIuykmmmg3OC3Qd7eks3t35dvr80m1pK0lS4l/X9LQCuW3SRpZcsyhku6S9LCkRyT9P6kY7ZqWTX8uHfuApFvaY5qZmZn1N7VKqktXpk7b9JLTVlxbpFL7JF0ITAL+q6R434iYRLFC9hclvSr3dejzSTVpzExEjAc2A++tUL4GuARA0hBgFvCZiDiIYgny44F/Kol5czr20BTzPMzMzMysakpXpk7bjJLdK4F9Sp6/Eni6PIakNwCXA2dFxKaS2E+nfx+jmJXudbnt7Q9JdalfAa+uUD6fv/7J4ALgNxExByAiNgKXAh8rPygtOrPL/8/enYfJUZXtH//e2QOBBAiyQwiyIwRIQAQxbMorooAoqxBEIy6g+APBDZfXDVGRTTAqhlVWkaAo8AJRNoEJCUlAdgJEkJ3AhOzz/P6oGql0ema65/Qs3XN/rquuVJ9T9dTpnu7OM2dOnUP7c2mbmZmZNaweWlHxfmBTSRtLGkS2fsiU4gGStgd+TZZQv1QoX03S4Hx/JLArhbHYndVnkuo8Af4f3pk+pbW8P9m82K0/iK2BacVjIuJJYJikVfOiQ/LFbf4NrA7c0IVNNzMzM7OCfK2SLwE3Af8CroqIhyR9X1Lr9HhnAMOAq/Nhu6253pZAU77Q4O1koxOSk+qGn/2Dd1Z3hKyn+ncl5aPIkuhb8nLRxpicQvmVEfGlfJz1ecDJwE9KD87H/kwEOOhz57PzPhNLDzEzMzOraz21+EtE3AjcWFJ2WmF/7zbOuxt4T63b0xd6qlvHTo+JiOMjYnGxHNgIGEQ+php4iGww+39JGg00R8RbxfKICLJe6t3LXbg4FsgJtZmZmTWiHpr9o9fpC0l1uyJiHnACcJKkgcBlwG75wPbWGxfPJpswvJzdgCe7o61mZmZm1jv1+aQaICKmAw8Ch0bEArLJw78l6VGyMdj3A+cWTjkkH5szk+xu0f/t7jabmZmZ9Qbuqc40/JjqiBhWSXlE7F/YnwWMb+O8ycDkmjXQzMzMzOpewyfVZmZmZtZ1Kpj+rk9wUt1N5s9flhxj2bK2JiWp3LgtlibHWNpSmw/PaistSY6xcGn/5BivNg9MjjFi5fTXFUA1eGmHDUp/XQf0a0lvSI3864lByTEWLUt/n9TKRv/vfckxNr3v/OQYd+30+eQYA5tmdXxQBZbU4OfTrwafneEDm9ODAK8OGJocY9AV53Z8UAfWP/z05BibNE9PjgGwdMQuyTGaF6d/V+/4jwuTYwAMXDw/OUZTL/peStVSh0M1uoLHVJuZmZmZJXJPtZmZmZl1Wj3eVNgV3FNtZmZmZpbIPdVmZmZm1mm+UTHTUD3Vkpbl80fPlnSDpBF5+bqSrsn3V5J0maRZ+XF3ShomaZSk2RVeZ7ykefm1WreyS2GamZmZWeNrtJ7q1qXHkXQR2dLjP4yI54GD82O+DLwYEe/Jj9sc6Mx0CXdExEdq0GYzMzOzuuUx1ZmG6qkucQ+wHkBJL/Q6wL9bD4qIRyNiUfFESaMlTZc0rttaa2ZmZlaHItQlW71pyKRaUn9gL2BKmeoLgVMk3SPpB5I2LTl3c+Ba4JiIuL+dy7y/ZPjHJmXaMVFSk6Smabf/NuEZmZmZmVlv1mjDP4ZKmgGMAqYBt5QeEBEzJI0GPgjsDdwvaRdgAbAmcD3w8Yh4qINrdTj8IyImAZMAvnPxkvSVW8zMzMx6GQ//yDRaT3XrmOqNgEFkY6pXEBHNEfHHiPgCcCnw4bxqHvAcsGt3NNbMzMzMGkOjJdUARMQ84ATgJEnLrWsqaVdJq+X7g4CtgMePCxAAACAASURBVGfy6sXAAcBRkg7vxiabmZmZ1SWPqc40ZFINEBHTgQeBQ0uqNgH+LmkWMB1oIhtD3XrefOAjwImSPtbOJUrHVB/czrFmZmZmDamli7Z601BjqiNiWMnj/QsPt8nLLgYuLnP6nMIxbwBtzvwREVOB4WmtNTMzM7NG0VBJdW82YGD6nzEGDkiPETW4XXLEkAXpQYDmxUOSY6y3yrzkGOuukv66itrchyqlx6nFn8wG9luaHANq05YBAwcnx9holZeSYyxZtlZyDIB/n3lXcozX+y1LjjGwaVZyDIAlY9+THGP0RzdMjvH0X59LjjFixtXJMQDWHjY0OcayRYuTY6zF88kx5q66dXIMgOE0J8dYY3D699Idr9ZmptxhNWjLBt/brwYtAa5dYU6GblePQzW6gpPqdkj6EHB6SfHTEXFgT7THzKw3qUVCbWbWKJxUtyMibgJu6ul2mJmZmfVWnlIv46TazMzMzDrNwz8ydT/7h6TmkscTJJ2b7x8n6ah2zh0v6X1d3UYzMzMza2wN3VMdERd0cMh4oBm4u9KYkgZERG3u4jIzMzOrcx7+kan7nur2SPqupJPy/RMkPSxppqQrJI0CjiObj3qGpPdL2kjSrfkxt0raMD93sqRfSLodOEPS45LWzOv6SXpC0sgeeppmZmZm1sMaoad6qKQZhcerA1PKHHcqsHFELJI0IiLekHQB0BwRPwOQdANwcURcJOnTwNlkKywCbAbsHRHLJL0BHAH8EtgbeDAiXumap2dmZmbWe7XUZlbZutcIPdULImJM6wac1sZxM4HLJB0JtDV8Yxfg8nz/EmC3Qt3VEdE6OeyFQOtY7U8Dvy8XTNJESU2Smppu/U2FT8fMzMzM6k0jJNWV2g84D9gRmCapkl764u9e8/9bGPEc8KKkPYGdgb+WPTliUkSMjYixY/f6bOdbbmZmZtZLBeqSrd70iaRaUj9gg4i4HfgaMAIYBrwFrFI49G7g0Hz/CODOdsL+FrgUuKrQg21mZmbWp0SoS7Z60yeSaqA/cKmkWcB04MyIeAO4ATiw9UZF4ATgGEkzgU8BX24n5hSyxLzs0A8zMzMz6zvq/kbFiBhW8ngyMDnf/26hqjg+uvXYx4BtS4r3LHPchDKX3o7sBsVHqmmvmZmZWSMJ36gINEBS3RMknQp8nmyIiJmZmZn1cU6qOyEifgL8pJpzlixuSb7uiFX7J8cYNmhRcozVB85LjlEra+rF5Bi1uBlC1ObX9H41GJ7/ktZJjjFAtVnfqKUGI8xq8dkZvvTV5BiDB6yZHANg0dL012TwgPSfz5Jl6d8ng6fNZL3vfSQ5zlNTnk2OsfXRWyTHGP76nOQYAG+PXDU5xsqjN0yO0TLvueQYS1YbnBwDYIFWTo5Ri8/xSoNq8zmuxWewFu97gC1rEiVNSx3eVNgVnFSbmVmn1CKhNrP6V483FXaFvnKjopmZmZlZl3FPtZmZmZl1mm9UzPTZnmpJy/Kp9GZLulrSSlWe39xVbTMzMzOz+tJnk2reWd58G2AxcFyxUpm+/PqYmZmZdcgrKmacNGbuAN4taZSkf0n6FfAAsIGkwyTNynu0Ty+eJOnnkh6QdKuk2txSbGZmZlZHWqJrtnrT55NqSQOA/wFm5UWbAxdHxPbAEuB0sgVhxgDjJB2QH7cy8EBE7AD8HfhOtzbczMzMzHqNvpxUD5U0A2gCngV+l5c/ExH/zPfHAVMj4uWIWApcBuye17UAV+b7l1JmxUZJEyU1SWp6YOpvu+p5mJmZmfWYCHXJVm/68uwfCyJiTLFAEsD8YlEV8Vb4Q0VETAImAZx20eI6/EOGmZmZmVWiL/dUV+Je4AOSRkrqDxxGNtQDstfu4Hz/cODOHmifmZmZWY+K6Jqt3vTlnuoORcQLkr4O3E7Wa31jRFyfV88HtpY0DZgHHNJDzTQzMzOzHtZnk+qIGFambA6wTUnZ5cDl7Zz/7a5on5mZmVk9aKnD6e+6Qp9Nqs3MzMwsXT0O1egKTqq7yZAh/ZNjLFiY/q6dt2hIcowlLWskxwB4e8nA5BgDhq6THGNJS/rPZmC/ZckxAPqpJT1IDb7clrSk/2xqpRafnZf6pb9P3l6c3o5aWbAk/au7Xw06lp477S8s3WXb5DhbH71FcoyHLnokOcZWX98yOQbAK4tXS46xymNzkmMs+0D6qMQ3Iv25APSrQdZVi89x86Lek/bU4n1vvUvveXeZmVldqUVCbWb1rx6nv+sKnv3DzMzMzCyRe6rNzMzMrNPqcUnxruCk2szMzMw6zTcqZhpu+IekZZJmSJot6QZJI/LydSVd0855oyTNrvAa4yXNy68zQ9L/1ar9ZmZmZlZ/Gi6pJl9+PCK2AV4DvggQEc9HxMHtn1qVO/LrjImIvWsY18zMzKxuBOqSrd40YlJddA+wHizfEy1pa0n35b3MMyVtWjxJ0mhJ0yWN64E2m5mZmVmdadikWlJ/YC9gSpnq44CzImIMMBaYWzhvc+Ba4JiIuL+dS7y/MPzjm220YaKkJklN9/3fbzr9XMzMzMx6q5bomq3eNOKNikMlzQBGAdOAW8occw/wTUnrA3+MiMclAawJXA98PCIe6uA6d0TER9o7ICImAZMAfnTlsjp8e5iZmZm1zzcqZhqxp3pB3gO9ETCIfEx1UURcDnwUWADcJGnPvGoe8Bywaze11czMzMwaQCMm1QBExDzgBOAkScutuSxpNPBURJxNNjykdVmwxcABwFGSDu/O9pqZmZnVo4iu2epNwybVABExHXgQOLSk6hBgdj5MZAvg4sI584GPACdK+lh3tdXMzMzM6lfDjamOiGElj/cvPNwmL/sx8OOSU18r1L8BtDnzR0RMBaamt9bMzMysvrVE/U1/1xUaLqnure657bHkGJ//3LuTY+y69LbkGEv+fF1yDICBH0r/Q8BSrZwc46mvfCM5xuhf/ig5BsCAxfPTY7z1anIMvfFacgwABqR/xdxz254dH9SBYx9I//msOvG7yTEA5rUMT46xYOng5BjDBzYnx2Dm7YxoeSW9La/PSY6x1de3TI7x8Bb7JccA2GNq+vut+ZivJMdoqcHfz0ees8JtSZ2Ls0f6rUrz7m1KjtF89AXJMQD6qSU5xsjPfqYGLbHexEl1OyR9CDi9pPjpiDiwJ9pjZtab1CKhNrP6V4/jn7uCk+p2RMRNwE093Q4zMzOz3spJdaahb1Q0MzMzM+sOfaKnOl/x8HBgGdACfC4i7u3ZVpmZmZnVv3pc/bArNHxSLWkXsinydoiIRZJGki0K09l4AyJiac0aaGZmZmZ1r+GTamAd4JWIWAQQEa8ASBoHnAWsDCwC9gKWAOcDY4GlwFcj4nZJE4D9gCH58XtKOhn4JDAYuC4ivtOdT8rMzMysNwhPqQf0jTHVNwMbSHpM0q8kfUDSIOBK4MsRsR2wN9mS5V8EiIj3AIcBF0kaksfZBTg6IvaU9EFgU2AnYAywo6Tdu/dpmZmZmfW8nlpRUdK+kh6V9ISkU8vUD5Z0ZV5/r6RRhbqv5+WP5rO9JWv4pDoimoEdgYnAy2TJ9OeAFyLi/vyYN/MhHbsBl+RljwDPAJvloW6JiNbJez+Yb9OBB8hWZdy09NqSJkpqktT0zL+u6qJnaGZmZta3SOoPnAf8D7AVcJikrUoOOxZ4PSLeDZxJPk1yftyhwNbAvsCv8nhJ+sLwDyJiGdkKiFMlzSLrkS73O1B7f78orsoh4McR8esOrjsJmASw/+f+5WH8ZmZm1nB66EbFnYAnIuIpAElXAB8DHi4c8zHgu/n+NcC5kpSXX5EPDX5a0hN5vHtSGtTwPdWSNpdU7EUeA/wLWDcfV42kVSQNAP4BHJGXbQZsCDxaJuxNwKclDcuPXU/Su7rwaZiZmZnZO9YDnis8npuXlT0mH5EwD1ijwnOr1hd6qocB50gaQXbz4RNkQ0F+n5cPJRtPvTfwK+CCvDd7KTAhnzFkuYARcbOkLYF78rpm4Ejgpe55SmZmZma9Q1ct/iJpIlnO1mpSPgoAyo8uKG1JW8dUcm7VGj6pjohpwPvKVL0CvLdM+YQyMSYDk0vKziKbPcTMzMysz+qqpLo4jLaMucAGhcfrA8+3cczcfETCcOC1Cs+tWsMP/zAzMzOzhnM/sKmkjfNZ3Q4FppQcMwU4Ot8/GLgtIiIvPzSfHWRjsskm7kttUMP3VPcWm4/ZKDnGU/9J/3GNX/mN5BjzPnl8cgyA1V+YnRxD9/8jOcaG5/4iOcbAv1+XHANg2dsLkmPMPfCryTEGb/B2cgyAlvSbqdn83+snx1hlq/2SYzR/74TkGABzv3x9coxFS9P7Q14dMDQ5BqzJ2sOak6O8PXLV5BivLF4tOcYeU3+UHAPg9vHfSI6x+sz7k2NsMvlLyTH4/NfSYwAvDVw5OcbINdZKjvHCm7V434NqMC3zmiO3TQ9CmanHekBP3KgYEUslfYnsPrf+wIUR8ZCk7wNNETEF+B1wSX4j4mtkiTf5cVeR3dS4FPhiPqlFEifVZmbWKbVIqM3MOisibgRuLCk7rbC/EPhEG+f+EPhhLdvjpNrMzMzMOq2rxlTXG4+pNjMzMzNL5J5qMzMzM+u0lpaebkHvkNxTLanDQXWS5kgamXqtakiaIGndDo6Zmq/5/qCk+yWNKdTdmM9t3da53f6czMzMzHqbiK7Z6k2vH/6RzyvYGROAdpPq3BERsR3Zwi9ntBZGxIcjIn2qDDMzMzNreDVLqiWNz3t+r5H0iKTLtPxShMdLekDSLElb5OesLOnCvJd4uqSP5eUTJF0t6Qbg5rzs5Py4mZK+l5eNkvQvSb+R9JCkmyUNlXQwMBa4TNKMfNXEjtxDYYnK1p7ovI1/yXuzZ0s6pOR5D5X0N0mfTXn9zMzMzOqRe6ozte6p3h74CrAVMBrYtVD3SkTsAJwPnJSXfZNsIu5xwB7AGZJaJ7PcBTg6IvaU9EGyqRh3AsYAO0raPT9uU+C8iNgaeAP4eERcAzSR9UKPiYhKJv/dF/hTG+XPR8R2EbEN8LdC3TDgBuDyiPhN6YmSJkpqktQ0884LK2iCmZmZmdWjWt+oeF9EzAWQNAMYBdyZ1/0x/3cacFC+/0Hgo5Jak+whwIb5/i0R8VrhuA8C0/PHw8iS6WeBpyNiRiH2qCrbfFmeyPcHdihTPwv4maTTgT9HxB2FuuuBn0bEZeUCF5fXPOn8t+vwdy4zMzOz9vXE4i+9Ua17qhcV9pexfNK+qEy5yHqWx+TbhhHxr7xufuFcAT8uHPfuiPhdBdesxBHAxsDlwHmllRHxGLAjWXL9Y0mnFarvAv6nZJiLmZmZWZ8REV2y1ZuevlHxJrKx1gKQtH07x31a0rD8uPUkvauD2G8Bq1TSiIhYAnwLeK+kLYt1+Qwib0fEpcDPWL43+zTgVbKbHM3MzMysj+rppPp/gYHATEmz88criIibyXqS75E0C7iGjhPmycAFld6omI+7/jnvjPdu9R7gvnw4yzeBH5TUfwUYIumnHV3DzMzMrNH4RsVM8pjqiBiW/zsVmFoo/1Jhf1RhvwkYn+8vAD5XJuZksqS4WHYWcFaZJmxTOOZnhf1rgWs7aPv4ksc/L9Pmm/Kt9NxRhYfHtHcdMzMzM2tsXlGxmwwYkP5HgVdfW5oco2mj/ZNjDFy2LDkGwFMjN06OMXSvfZNjvLl4SHKMVffaPDkGQD+lL0s1KJYkx1jWr39yDIAg/XaDWnx2Hlt3r+QYc47/RHIMgH2aTuv4oA68+YH0tgy64tzkGADLFi1OjrHy6A07PqgDqzw2JzlG8zFfSY4BsPrM+5NjvLbtuOQYmzxY9h76qgxZ+HpyDIDXBq+dHKMWn+Pt+z2THANg5SXzkmOsets1NWgJsEnpH9C7n1dUzPSJpFrSdWQ3IxadEhEr9ECbmVllapFQm1n9q8ehGl2hTyTVEXFgT7fBzMzMzBpXn0iqzczMzKxreJ7qTE/P/mFmZmZmVvcqSqolrS3pCklPSnpY0o2SNpO0taTbJD0m6XFJ3y7MOT1BUoukbQtxZksaJenefKq7ZyW9nO/PyOvmSJolaaakv0vaqHD++pKuz6/1pKSzJA3K68ZL+nOFz2eqpEclPSjpfkljCnVzJI3M978p6aG8LTMk7Vw4f2y+Pypvz4cqubaZmZlZI/GUepkOk+o8Sb4OmBoRm0TEVsA3gLWAKcBPImIzYDvgfcAXCqfPJZvbeTkRsXNEjCFbPOXKwkqJc/JD9oiIbcmm6PtWoR1/BP4UEZsCm5EtV/7Dqp915oiI2I5s4ZYzyjzvXYCPADvkbdkbeK7kmPXJptv7f77p0czMzKzvqqSneg9gSURc0FoQETPIktq78oVZiIi3gS8BpxbO/TOwtaTOzjd2D7Bevr8nsDAifp9fbxlwItlKiyt1Mn7pNYrWAV6JiEX59V6JiOcL9WsDNwPfiogpCdc3MzMzq1vREl2y1ZtKkuptgGllyrcuLY+IJ4FhklbNi1qAn5L1bHfGvsCf2rnem8CzwLs7Gb/0GkU3AxvkQ1t+JekDJfUXA+dGxNVtBZY0UVKTpKYZ//hdQhPNzMzMeqeW6Jqt3qTcqCigradcLL8ceK+kalb6uF3SS2RDLi7v4HrttaM9l0maC5wCnFNaGRHNwI7AROBl4EpJEwqH/B/wqfZ6ySNiUkSMjYixY3Y/thNNNDMzM7N6UElS/RBZclmufGyxQNJooDki3moti4ilwM/JktdK7QFslF/j++1cb1VgA+DJKmK3OoJsQZjLgfPKHRARyyJiakR8h2xoy8cL1T8F7gWuluSpCc3MzKxP8o2KmUqS6tuAwZI+21ogaRzwOLCbpL3zsqHA2WTJZqnJZL3Oa1basIhYAHwFOErS6sCtwEqSjsqv158sWZ+cj+euWkQsIbsR8r2StizWSdpc0qaFojFA6fqmJwJvAr9rnfXEzMzMzPqeDpPqiAjgQGCffBq7h4DvAs8DHwO+JelRYBZwP3BumRiLyRLud1XTuIh4AfgD8MVCOz4h6XHgMWAhy4/X3kvS3MK2SwXXWECWnJ9UUjUMuCifQnAmsBXZ8y6eG8DRZDc1lvtlwszMzKyhtbREl2z1pqJhC/msF59so3p8G+dMJuuhbn18Nlli3eYxedmoksfHF/afA/Zv43pTgaFttLH02PElj39e5vqvkE0R2O75+S8MH6zkumZmZmaNph6HanQFjwXuJqutNig5Ri0GmIwYND85xpKozdtm5QELk2PE8Qcnx1j9nD8mx+h3/EHJMWolzrkmOYZUm2/IIP1NW4vPzvB+85Jj7LTqC8kxAB7Z4/8lx/j3m8OTY6x/+OnJMQDW4vmOD+pAy7znOj6oA8s+cEh6O2qUGWwy+UvpMR68LDnG/dsdkRxjvYfvTI4BMJT07/tafI6bXh6dHANg8ID098oeY9I/O9a7NHRSLek6spsRi07xQi1mZulqkVCbWf1zT3WmoZPqiDiwp9tgZmZmZo2voZNqMzMzM+tatRo6Ve+cVJuZmZlZp0VLT7egd0hZUbFmJB0oKSRtUeV54yX9Od//qKRT8/0DJG3VwbmTJT0taYakByXtVaj7bXvnS5oqaWxb9WZmZmbWt/SKpBo4DLgTOLSzASJiSkT8JH94ANm80h05OSLGkC0yc0Eh1mci4uHOtsXMzMysr4iILtnqTY8n1ZKGAbsCx5In1cUe6PzxuZIm5Pv7SnpE0p3AQYVjJuTHvQ/4KHBG3gu9SQXNuAdYrxBrqqSxkvrnPdqzJc2SdGJJ2/tJukjSDzr9ApiZmZlZ3evxpJqsV/lvEfEY8JqkHdo6UNIQ4DdkC8C8H1i79JiIuBuYQt4LHRFPVtCGfYE/lSkfA6wXEdtExHuA3xfqBgCXAY9FxLfaaO9ESU2Smu69ZVIFzTAzMzOrLy0tXbPVm96QVB8GXJHvX5E/bssWwNMR8Xi+RPilidc+Q9JTeZwflal/Chgt6RxJ+wJvFup+DcyOiB+2FTwiJkXE2IgYu/M+ExObamZmZma9VY8m1ZLWAPYEfitpDnAycAiwjOXbNqSwX8tBNicD7wa+BVxUWhkRrwPbAVOBLwK/LVTfDeyR956bmZmZ9UkeU53p6Z7qg4GLI2KjiBgVERsAT+d1W0kaLGk40DozxyPAxoVx0m31ar8FrFJJAyKiBTgL6CfpQ8U6SSOBfhFxLfBtoDg05XfAjcDVkjw1oZmZmfVJLdE1W73p6aT6MOC6krJrgcOBq4CZZOOWpwNExEJgIvCX/EbFZ9qIewVwsqTpldyomA8l+QHwtZKq9YCpkmYAk4Gvl5z3C+AB4BJJPf1ampmZmVkP6dEe1ogYX6bs7MLD0iSXiPgb2djq0vLJZIkvEXEXHUypFxETSh5fS5bQl7ZrhRsni/UR8Z32rmNmZmbWyKIeu5W7gIctdJO/XXV/cowTTkpfb2a9RU8kxxg67f+SYwAs3GHP5BgvnXd5cowNp57d8UEdeLYG7QAYzMLkGP3i9eQYQxe9lRwDoKVf/+QYf7tqbnKM4+ak/3xeOPDk5BgAm7w5IznGkmE7prejeXpyDIC5q26dHGPJaoOTY7wRqyXHGHnOF5NjAPD5FfqDqjZkYfrneL2H70yO8e+tdkuOATDuwcuSYwy+8ZLkGOvv97/JMQCk9CTy1QHvrkFLKhzrat2i4ZNqSeeRzYNddFZE/L7c8WZmVplaJNRmVv/q8J7CLtHwSXVE1KjrwczMzMxKtXj4B9DzNyqamZmZmdW9Pp1US1qWL2U+W9INkkbk5etKuqad80ZJmt19LTUzMzPrnTxPdaZPJ9XAgnwp822A18gWeCEino+Ig3u2aWZmZmZWL/p6Ul10D9m81Mv1REvaWtJ9eY/2TEmbFk+SNDqfD3tcD7TZzMzMrEdFS9ds9abhb1SshKT+ZKs2/q5M9XFks4VcJmkQ0B9YKz9vc7KFZo6JiPR5sszMzMzqTEsdDtXoCn29p3povlriq8DqwC1ljrkH+IakU4CNImJBXr4mcD1wZFsJtaSJkpokNT3/1J+6oPlmZmZm1hv09aR6QUSMATYCBpGPqS6KiMuBjwILgJskta5YMg94jhXnwC6eOykixkbE2HVHH1DzxpuZmZn1NN+omOnrSTUAETEPOAE4SdLAYp2k0cBT+fLpU4Bt86rFwAHAUZIO7872mpmZmVnv4jHVuYiYLulB4FDgjkLVIcCRkpYA/wG+D6yanzNf0keAWyTNj4jru7vdZmZmZj3Ji79k+nRSHRHDSh7vX3i4TV72Y+DHJae+Vqh/A/DMH2ZmZmZ9WJ9Oqs3MzMwsTR0Of+4STqq7ybg9t+34oA688mb/5BizVto+OcZ6u62XHAPg+YVrJsdYI95MjvHK7oclx1gatfkoLWPl5BgLjj0oOcaLd7+WHANAA5UcY9wvpifHGLzpo8kxFrcMSo4BMHPQzskxnn9tpeQYS0fskhyDxTB8UHNymAVKf9/3q8H/6iP3aPO+86q8NDD9+bw2eO3kGENZmBxj3IOXJccAuH+7I5Jj7PW3bybHePTFVZNjAAwZlP5+G75W+mentwgP/wB8o6KZmXVSLRJqM7NG4Z5qMzMzM+s0L/6ScU+1mZmZmVmihk2qJYWkSwqPB0h6WdKfq4wzvtpzzMzMzPqKaIku2epNIw//mA9sI2lovrT4PsC/qwkgqZFfHzMzM7Nk9ZgAd4WG7anO/RXYL98/DPhDa4WknSTdLWl6/u/mefkESVdLugG4uRhM0rj8+NGSPiBpRr5Nl7RKdz0pMzMzM+tdGj2pvgI4VNIQsuXF7y3UPQLsHhHbA6cBPyrU7QIcHRF7thZIeh9wAfCxiHgKOAn4YkSMAd4PLOjSZ2JmZmbWC7VE12z1pqGT6oiYCYwi66W+saR6OHC1pNnAmcDWhbpbIqI4Ue+WwCRg/4h4Ni+7C/iFpBOAERGxtPT6kiZKapLU9OAdv6vJczIzMzOz3qehk+rcFOBnFIZ+5P4XuD0itgH2B4YU6uaXHPsCsBD478opEfET4DPAUOCfkrYovXBETIqIsRExdrv3H5v8RMzMzMx6G9+omOkLN+JdCMyLiFmSxhfKh/POjYsTOojxBnAscLOk+RExVdImETELmCVpF2ALsiElZmZmZn1GeJ5qoA/0VEfE3Ig4q0zVT4EfS7oL6HD974h4kaxH+zxJOwNfkTRb0oNk46n/Wst2m5mZmVn9aNie6ogYVqZsKjA1378H2KxQ/e28fDIwuY1znuWdsdfFmx7NzMzM+qSWOhyq0RUavqfazMzMzPoWSatLukXS4/m/q5U5ZoykeyQ9JGmmpEMKdZMlPV2YPnlMR9ds2J7q3uaJh6tad6asvXfZMDnGBiu9kBxjnblNyTEA+q+3Y3KMgS2LkmOsOeuW5Bi854PpMYCBy9Kfzyo//UZyjG2aX0+OARD9OhxZ1aHfXpf+2bn1+B8mx9hl2sbJMQCeWbJLcoy1VlmYHKN58cAaxFiNjVZ5OTnO8KWvJsd4qd86yTHm3Vub77aRa6yVHOOxdfdKjjG837zkGPMHj2D1685JjrPX376ZHOPWfdM/x+tPO6TjgyrQXy3JMWrxvs+sV6M4nddLx1SfCtwaET+RdGr++JSSY94GjoqIxyWtC0yTdFNEvJHXnxwR11R6QSfVZmbWKbVIqK13q0VCbY2vl87U8TFgfL5/EdlQ3uWS6oh4rLD/vKSXgDXJJqiomod/mJmZmVmjWSsiXgDI/31XewdL2gkYBDxZKP5hPizkTEmDO7qge6rNzMzMrNO6qqda0kRgYqFoUkRMKtT/H7B2mVOrGm8kaR3gErLVtFvH9nwd+A9Zoj2JrJf7++3FcVJtZmZmZr1OnkBPaqd+77bqJL0oaZ2IeCFPml9q47hVgb8A34qIfxZit96EtkjS74GTOmpvp4Z/SApJlxQeD5D0sqQ/F8oOyLvMH5E0g0L0XgAAIABJREFUS9IBhbrJkv7d2pUuaaSkOfn+KEkLCndbzpB0lKTLJX2+EGPnPH7ZXwwkzZF0R0nZjHxZ8mqe66hqzzEzMzPrK1oiumRLNAU4Ot8/Gri+9ABJg4DrgIsj4uqSunXyfwUcAHSYC3a2p3o+sI2koRGxANiHd1YnRNJ2ZEuD7xMRT0vaGLhF0lMRMTM/bBnwaeD8MvGfjIjlpi6RdBNwj6RrgFeBc4EvRMTSdtq5iqQNIuI5SVtW+yQlpU9dYGZmZmbd7SfAVZKOBZ4FPgEgaSxwXER8BvgksDuwhqQJ+XkTImIGcJmkNQEBM4DjOrpgyo2KfwX2y/cPA/5QqDsJ+FFEPA2Q//tj4OTCMb8ETmyrp7lUvqLhz8hWQjwOmBkRd3Zw2lVA6/w5y7Ux74G+Q9ID+fa+vHy8pNslXQ7MKgaTNFrSdEnjJG0t6b6893umpE0reR5mZmZmjSRaoku2pDZFvBoRe0XEpvm/r+XlTXlCTURcGhEDI2JMYZuR1+0ZEe+JiG0i4siIaO7omilJ9RXAoZKGANuy/AqDWwPTSo5v4p3VCCH7reFO4FNlYm9SMvzj/Xn5BcBWZMn51ypo4zXAQfn+/sANhbqXyHrSdyBLvM8u1O0EfDMitmotkLQ5cC1wTETcT5bYn5X3qI8F5pZeXNJESU2Smp6efUUFzTUzMzOrLxHRJVu96fSNihExU9Iosh7gG0uqBZS+GuXKfkQ25uUvJeUrDP/Ir9ki6dfA2IioZNb014DXJR0K/Itsku9WA4Fz8xVylrH8kuX3tfay59YkG4vz8Yh4KC+7B/impPWBP0bE42Xa+98B9ged8ET9vTvMzMzMrCKp81RPIRuS8YeS8ofIem+LdgAeLhZExBNk41Q+WcU1W/KtUlcC55Vp44nAi8B2eVsHFermlxw7D3gO2LW1ICIuBz4KLABukrRnFW0yMzMzawgtLdElW71JnVLvQmBeRMySNL5Q/jPgakm3RcScvEf7G8DBZWL8kBV7qmvpOmAd4CZg3UL5cGBu3vt9NNDeTYmLye78vElSc0RcLmk08FREnJ3vbwvc1jVPwczMzMx6s6SkOiLmAmeVKZ8h6RTgBkkDgSXA11oHf5cc+5CkB8h6slttIql47IURcTadEBFvAacDZLOi/NevgGslfQK4nRV7p0vjzJf0EbJZTOaTje0+UtISssnB250Q3MzMzKwR9dJlyrtdp5LqiBhWpmwq2brqrY//CPyxjfMnlDw+qLA/BxjazrUnA5MraOOoMmVzgG3y/cfJepdbfT0vn8ryz6N4zhvAuLzqerIZTczMzMz6rHq8qbAryC9E9/jptem/xq09MnUIPAwZVM1w9PKGDV6WHANg/uL0acBr8fZdZUhtns9bC9Ofz/J/TOmc5gXp75NatANq8/N5+bX09+wOmy5JjvHSm4M6PqgC/dJ/PKy2/zbJMXb4x4XpDQHumD+u44M6sNKg9pYbqEzzovQFgtdeZUFyDIAX3myzX6hi26/5THKM6S9vlBwDYP3hHc4k1qFHX1w1vR2rL0qOsWjHbTs+qAIDVk1/v8Wt02vQEth3zKAafWN33uGnzu2SZPLyn6zf48+tGnW/TLmke4HBJcWfiohZ5Y436wq1SKjN6k0tEmrr3WqRUFvji5b0zo9GUPdJdUTs3NNtMDMzM7O+re6TajMzMzPrOfU4/V1X6LNJdT413go3XJqZmZlZ5Xx/XqYGt8yYmZmZmfVtTqoLJG0k6VZJM/N/N8zLPyFptqQHJf0jL9ta0n2SZuTHb9qzrTczMzPrftESXbLVGyfVyzsXuDgitgUuA1oXnDkN+FBEbEe2NDnAccBZETGGbJnzud3dWDMzMzPrHZxUL28X4PJ8/xJgt3z/LmCypM/yznLm9wDfyFeO3CgiVpjgVNJESU2Smu69ZVIXN93MzMys+7mnOuOkun0BEBHHAd8CNgBmSFojIi4n67VeANwkac8VTo6YFBFjI2LszvtM7M52m5mZmVk36rOzf7ThbuBQsl7qI4A7ASRtEhH3AvdK2h/YQNJw4KmIOFvSaLIlz2/roXabmZmZ9YiW8OIv0LeT6pUkFcdB/wI4AbhQ0snAy8Axed0Z+Y2IAm4FHgROBY6UtAT4D/D9bmu5mZmZWS9Rj0M1ukKfTaojoq2hL+WGcRxU5rgf55uZmZmZ9XF9Nqk2MzMzs3Tuqc44qa4jy2owZGn+wn6sPCQtUPOi/gwbvCy5Lb1lAaa3FqY/n2GDl9G8qH/HB3aDoYN7yQvbizzw+EDGbbYoKcY6wxfynzeHJLdlQP/0n8/SN5cmx7hvzFHset/5STH2HDiV+/rt1vGBHRg8IP35DB24lAVL0v5La148kFUHp71PAKTkEKy8ZF5yjN1GzOT+5vckxXh5/sq8a1hzcluGDEp/37/SPIi1VlmYFGOlB2awePzY5LbU4jM4bGB6jMygGsWxVE6q+5jUhBqoSULdm9Ti+fSWhNrKS02ogZok1L1JakIN1CShrpXUhBqoSULdm6Qm1EBNEupaSU2ogZok1LYiL1OecVJtZmZmZp3W0uLZP8DzVJuZmZmZJXNPtZmZmZl1mm9UzNS0p1pS2cFX+XLdj+TbfZJ2K9R9RNJ0SQ9KeljS5/LyzSVNlTRD0r8ktbnOt6SVJF0maZak2ZLulDQsr1tb0hWSnszj3yhps7xua0m3SXpM0uOSvi1lt5hImiDp5fz6j0g6sXC970r6d17Xuo2ozatoZmZmZvWmy3uqJX0E+BywW0S8ImkH4E+SdgJeBSYBO0XEXEmDgVH5qWcDZ0bE9Xmc9u64+DLwYkS8Jz92c2BJniBfB1wUEYfmdWOAtSQ9B0wBPh8RN0taCbgW+AJwXh73yoj4kqQ1gEclXRMRz+V1Z0bEz1JfHzMzM7N6Fl5REeieMdWnACdHxCsAEfEAcBHwRWAVssT+1bxuUUQ8mp+3DvDfFQ8jYlY711gH+Hfh2EcjYhGwB7AkIi4o1M2IiDuAw4G7IuLmvPxt4EtkKyUuJyJeBZ7Ir2NmZmZmuWiJLtnqTXck1VsD00rKmoCtI+I1st7iZyT9QdIRklrbdCZwm6S/Sjqxg+EVFwKnSLpH0g/yJcUBtilz7TbbFRFPAsMkrVosl7QhMASYWSg+sTD04/ZyF8iHvTRJarr3ljZHr5iZmZlZneup2T8EBEBEfAbYC7gPOIksQSYifg9sCVwNjAf+mQ8PWUFEzABGA2cAqwP3S9qy0jaUC5n/e4ikh4CngLMiojhJ5pkRMSbf9mijXZMiYmxEjN15n4kdNMfMzMys/rinOtMdSfXDwI4lZTvk5UA2tCMizgT2AT5eKH8+Ii6MiI8BS8l6nsuKiOaI+GNEfAG4FPgw8FCZa7d6CFhuFnhJo4HmiHgrL7oyIrYG3g/8XNLaHT5bMzMzM+tzuiOp/ilwen6zX+uNghOAX0kaJml84dgxwDP5cftKGpjvrw2sQWHcdJGkXSWtlu8PArbK49wGDJb02cKx4yR9ALgM2E3S3nn5ULKbI39aGj8i7gEuIbsh0szMzMxyLdHSJVu9qfXsHytJmlt4/IuI+IWk9YC7JQXwFnBkRLwgaRXga5J+DSwA5pMl3AAfBM6S1Drk4uSI+E8b190EOD+f7aMf8Bfg2ogISQcCv5R0KrAQmAN8JSIWSPoYcI6k84D+ZInzuW1c43TgAUk/yh+fKOnIQv0BETGng9fHzMzMzBpQTZPqiCjb8x0R5wPnlyl/i2yYRrlzvgp8tcLrXgxc3Ebd88An26ibRTZeu1zdZGBySZzW4R/fzTczMzOzPq0exz93Ba+oaGZmZmadFi31N1SjK9RVUi3pQ2TDMIqejogDe6I91WhuXpocY+iQgckxtli77KKXVVlj0BvJMQBeWzI8OcZ6/csOs69KoOQYWqU2v6X3i2XJMV5S+nTqQ/otSo4B0FL+j1dVefjxNZJjbD7o8eQYS4ZtkRwDYNHS9Ndk2IzpyTGalvVPjrHB9/ZLjgHw1JRnk2NsfXT6z2fkZz+THANgzZHbJsdY9bZrkmPsMeb55BivDnh3cgyA4Wul/98zfOmryTFm3pr+2QEYNjD9//TmMdvXoCXAkkc7Psa6RV0l1RFxE3BTT7fDzMzMzDIe/pHpqXmqzczMzMwaRl31VJuZmZlZ7xJ1OP1dV0hOqiU1R8SwwuMJwNiI+JKk44C389k5yp07HlgcEXentsPMzMzMul+Lh38AXdxTHREXdHDIeKAZqDipljQgItLvEOgkSf0janA3mZmZmZk1jC4dUy3pu5JOyvdPkPSwpJmSrpA0CjiObBGVGZLeL2kjSbfmx9wqacP83MmSfiHpduAMSY9LWjOv6yfpCUkj22jDJyTNlvSgpH/kZf0l/UzSrPxax+fle0manpdfKGlwXj5H0mmS7gQ+IWkTSX+TNE3SHZJqMy2AmZmZWZ2JlpYu2epNLXqqh0qaUXi8OjClzHGnAhtHxCJJIyLiDUkXAM0R8TMASTcAF0fERZI+TbZs+AH5+ZsBe0fEMklvAEcAvwT2Bh6MiFfaaN9pwIci4t+SRuRlE4GNge0jYqmk1SUNIVvsZa+IeEzSxcDn82sALIyI3fJ23gocFxGPS9oZ+BWwZ+mFJU3Mr8V+E85jh/G1ma7JzMzMzHqXWvRUL4iIMa0bWRJbzkzgsnxp77aGb+wCXJ7vXwLsVqi7ujDs4kLgqHz/08Dv22nfXcBkSZ8lW4ocskT8gtZhJBHxGrA52ZzXj+XHXATsXohzJYCkYcD7gKvzXyZ+DZSdGDgiJkXE2IgY64TazMzMGlG0RJds9aY7Z//YjyxJ/SjwbUlbV3BO8RWd/9/CiOckvShpT2Bnsl7r8gEijst7k/cDZkgaA6gkNnlZe1qv3w94I/8FwszMzKxP8+wfmW6Zp1pSP2CDiLgd+BowAhgGvAWsUjj0buDQfP8I4M52wv4WuBS4qr0bByVtEhH3RsRpwCvABsDNwHGSBuTHrA48AoyS1Lp81KeAv5fGi4g3gaclfSI/V5K2a+/5m5mZmVlj667FX/oDl0qaBUwHzoyIN4AbgANbb1QETgCOkTSTLKn9cjsxp5Al5u0N/YDsxsZZkmYD/wAeJEvInwVmSnoQODwiFgLHkA3rmAW0AG3NXnIEcGx+7kPAxzpog5mZmVlD8vCPTPLwj+Ic1fnjyWQ3/BER3y1UFcdHtx77GLBtSfEKN/xFxIQyl96O7AbFRzpo30FlipcCX8234rG3AtuXiTGq5PHTwL7tXdfMzMzM+o66XFFR0qlkM3O0OZbazMzMzLpePU5/1yUioiE24JvAjJLtmz3driqfw0TH6J1t8fPxa1JvbektMXpTW3pLjN7UFj+fxn9NvHXfpvyHZr2ApKaIGOsYva8tfj5dE6M3tcXPp2ti9Ka29JYYvaktfj5dE6O3tcW6R3fdqGhmZmZm1rCcVJuZmZmZJXJS3btMcowuidNbYtQqTiPFqFWc3hKjVnEaKUat4jRSjFrF6S0xahWnkWLUKk6t2mLdwGOqzczMzMwSuafazMzMzCyRk2qzOiRp3Z5ug5mZmb3DSbVZffpnTzfAzMzM3uGkuheQtJGkvfP9oZJW6USMNSWt2QVtG5d4/q6SzkuMMUTSJ1JipJI0UpJ6sg0lqm5L/rNYOd8/UtIvJG1U+6a124Yh5d6nkt4laUiVsdaS9DtJf80fbyXp2ArP7XXzvvaSn8+ehf2NS+oOqjLW6jVozxqSzpH0gKRpks6StEZq3E62ZTdJx+T7a5a+PhXGWOH9KeknFZ67Tzt1p1fZju+XPO4v6bJqYuTn7VimbP8qY6wsqV++v5mkj0oa2Im2bCJpcL4/XtIJkkZ04/mrtlO3YaVxrL45qe5hkj4LXAP8Oi9aH/hThedK0nclvQI8Ajwm6WVJpyW2aStJ35f0OHB+J84fI+mnkuYAP8jbVm2M/pL+R9LFwDPAIRWeN0TS0fkXsySdIunP+X/GIyuM8V5JUyX9UdL2kmYDs4EXJe1bxXMYKek7+ZfzMEnnS5ot6XpJ7640Ths6c4fx+cDbkrYDvkb2ul6c2A6qfL+dDby/TPk+wJlVXnoycBPQOhTmMeArFZ77G0mP5+/zraq87nIk7ZG/Vx7Kt2skje9EqE7/fGrxvs/9rLB/bUndt6qIA3CvpKslfVjq9C+kVwAvAR8HDgZeBq6s9GRJNxf2v97JNiDpO8ApQGuMgcClnQh1sKQjCnF/BVTaGXKepP1K2tVP0mRguyrbsWHr65EnktcBj1cZA7LP0XsK7TmM6t8n/wCGSFoPuBU4huyzXa1rgWX5d+vvgI2By7vx/KmtO5JuLamr6P/0wvmbSbo1/78HSdtKqvZ1tZ7Q00s69vWNbDn1QcD0QtmsCs89EbgF2LhQNpos0TixynZsBJwKPAhMA14BRlVx/mbAacC/gDuB44FnOvF67A5cADxH9iX3H2ClKs6/CriM7Evs78B5wL5kyf2fK4zRBHwQ+ATwOvDevHyL4s+pgjg3Az8CzgEeBk7OY3wWmFrB+eeQJaGl2znAm514bR/I/z0NOLZYlvgefraKYx9up+6hKq97f/5v8bMzo4rzNwe+k/9sZpAlTRtV2Yb9gKfJEoHtgDHAp4GngA9318+nFu/7Mq/l9LbqKowlsl+W/gA8mX8WNqsyxrQyZU2dfD6dfq/n7w+VxJvZiThDyb6zDyP7hemXVZw7iqyD4qD88RDgz/nPfWAnfjaXk/2ScDNV/n9RiDMaeADYMv9euwMYXmWM1vf98cDXOvNeK4lzMnB8tXFqcH4tPzt/B3YqiTm7Mz8jb927DcB62qKIWNzakSNpAJX3Qh4F7BMRr7QWRMRTko4k+6KsqOdP0t3AcLJeoYMj4nFJT0fEnMqfBo+QfaHuHxFP5HFPrOJ8JM0FniXrsTs5It7K2/F2FWG2ioht8tdxbkR8IC//m6QHK4wxICJuztv0/Yj4J0BEPFJlh9taEfGNvJfumYg4Iy9/RNIXKzi/qZN1bXkr7506EthdUn+yHrcOSXqzrSqyRKFS7b2A1f7lbL6yoQBZliC9F5hX6ckR8SjwPeB7ee/wocBtkv4TEbtWGOZk4ICIKL63ZkhqIvvl58ZK20PCz4favO9h+e+e0u+hqv46EhFBlkDeImkPsp7dL+TtOTUi7qkgzO2SDiX7pQGy3uq/VNOMatrcjsUREZJa32srV3Oylh8K8xmyX37uAr4vafWIeK2jGBExR9kwwZskvQv4FHBvRHy1inbsUHh4FtlfSO8C/i5ph4h4oNJYeZueyn8+fyLrCPlgRCyoJkbWLO0CHAG0Do/pTG6yJO8pPxpoHYJSzTCS1PNr9tkh60i6r+T/m6VVxrAe4KS65/1d0jeAocrGzH0BuKHCcwcWE+pWEfGyqhuT9jLZsJO1yP4U+TjVfwl8nCwpuV3S38gS9Gr/5HstcADZUI9lkq7vRDsWA0TEUknPl9QtqzBGS2G/9D+IatqzLG9LKBui09Y1yoqIi8qVKxt7XNW4xdwhwOFkvaD/UTbO74wOzmn1BjAuIl4s057nqmjDS5J2ioj7SmKMI3sfVuOrwBRgE0l3kb13D64yBsrGc76L7P2/cpXtWLskoQYgImZKWqvKpqT8fGrxvgcYLWkK2We3dZ/8cVVjiPNfeI4kS/5eJOuJnELWm391e/EkvUX2WRPZz7l1qEU/oJnsLwwpzweAiPhohXGukvRrYISyIXufBn5T4bmQ/fWv9fm0/rtfvgVZj2+7Cgnx18h6uW8BLm0trzAh/nnJ49eBrfLyAPZc4YzybZnF8t+FqwP9yYb8EBHbVhIn92WyHvPrIuIhSaOB26s4v9UxwHHADyPiaWVj3qsZopN6/rskfZXsZ9u6T/642vudXpG0Ce90GBwMvFBlDOsBXvylh+X/oR9LNtxAZEM3fhsV/GAkPRARO1Rb18bxw8kS48OAdwMjgA+VJj8VxFmZLDE+jOwL+iKyL8ub2z3xnfMF7JGf/2FgVbLX58aIaK7g/Jd4J6E/JN8nf/zJiOgw0ZG0DJjPO72wrT3lAoZERKW9u2+QjRcU2TjifxTi7BYRq1USJ4/Vn+w9chjwIeCOiKg4gczPvyki9q70nJLzfwBMKfd+kHR6RJxSYZydyHodJ5MlGgBjyf7qcmhE3FtluwaQDeMQ8GhELKni3PeTvZ4HkI2ZvwK4NiIq7u2WNC0iVrhZq6O6No5fGVgYEcskbUY2VOivlTynWrzv8zgfaK8+Iv5eSZw81mPAJcDvI2JuSd0pEVHVzXWdUePnsw+F7+mIuCWxeVWR1F6iGRFRUUJco7a0ewNtRDxTRaxRpX8VlTQuIu6vsk07RsS0krL9I6LSTqrieasBG0TEzCrOafcXvYj4XhWxRpOtpPg+sl98ngaOqOZ1tZ7hpLoH5YnORRFxZCfPb03+VqiiiuSvTNx3kf3HfBjZF8sGnYyzOtm45ENav/AlrRYRr1d4/kCycaGHkf1ZscMbriQd3V59W72/ndHRc6nFf+iSdifrvdwPuA/YFRhd5ZCY1lhTgE9VkzR2hfz99UVgm7zoIeDciHipyjhHlSuPiA5v7st7158lSz6vKtcDX2EbWn9xWqGK6n9xmkb2y9dqZFMmNgFvR8QR7Z5I977v8+tdGxEfb6e+P3BGNUMT2on1UbJ7LSC7F+H/t3fm4ZIUVfp+v+62oV1AGdkUkU1AQVkUFVBE0HFUVNARaUFQcB0BkWHcEHFXBBdEVHDYVJYBEQEZcGGVfWkbUBRBFgVERccfCCLb9/vjRHHzVte9FVmZ91bd7nifJ59bmVURGXErK/NExDnf+WHTOnucY8L+NB2QdtX1RuCs5Nr2UWBj4FO2f9607prteB9wFHAPMeO+MeGSkzX5UalnTcLd6J+K4NznAN+2/bcadVwFvNb27Wn/JcT94NmTl1ykngXALravTfvzgb1svyCz/HnAa4kV/IXEitX5LV3Dj7Pd61nd67OzCDfME9NAe5bte5q2oTBNeAQcu5fkjZiZnjvsdkzSvqdXXh/SQn0DBQsB8yqvT26hHUPrS496evYHuA24mFg+f0I6dnOD85xIGJJHUAl8nOprqM3/Sfd3WNm+RQQHfi+z/qe31M6XTLYNcj0xPmArO/CyUs/jgcdN8ffTN/AKOLuF83yeUITYNW0/AT4/3f0h3FZqBeBNUM816e+LiBiU1xF+0TllNyHcjTr7OwOnpt/xcjXbcXX6+4rUtw0GuZ8RxuccYnXzt0Qcz//WrGMT4ApgJWJ1ciExmVO3LY2CJjvXAOHz/onq91WjjqcSK29z0/4KRIDuHTXruaDptVa24WzFp3r43AJclGYRHx3J2v5Sv4LqowPrjOCXfnj8clNu8NZkDCSt5fHBL339DzMYWl96MFF/2vAxr3IG9YK8sqjrapRJ3+/Y9h5d7ViWcDfI4RBNEnTqTF9bZ7oP9JvZHfvYIgFbs3PqT4XfQ/imdrSu/w4cYPvruXXUIOc6XJjuaycx/t72/RrneRWwoe1HACQdA/ycUCpqk379uR+4VtJPGN+XPWuep+Pf/mrgG7ZPlfTxzLKHAZ18BlsQA449CB/1w6kXT9C5+F9FuOdcrcl+EBPziMOP//WEkskhkmrNutu+QtKeRHD9/UTwfd34Ctw8aHKOpJWB7YF9655f0l6p3I3AUpIOBr5E+L9nu4ElfiJpH0I+snq9NX6mF6aWYlQPnzvSNguom/SlGvzSTVbwyxBow99oVHyW2mpHz3psvy/dqDs+5gcCy0jankwf8676jpE0D1jVoXzRClNgUMNg/9v7gGdkfnZT4sF7PHAZ7Q2QJiLnt7gXAwZsJVeCzYAtbd+Ujq0BHKxQl/j0gO1uwnLAXxgf/GagjlENEd/RMSaWbaFdg9DWgPT2FPD4MuAAhUZ0rurN7IpR9SbgcNsnAydLWlizHVcpNLxXBz6sSDjWN3i6Bx3FjJ2pqZgh6XTG/84fS6j3HJGCHbMGti0GTX6SWDm+KBn6a1BPu/udwDq2/6oIMr4R2MJJPaomu6a/VZWoUX2mFyoUn+oRId3UXNdQyqx7Pdu/bKGexjOSpY7B6xnEx7yr/GuI5B5zba8uaUPgk7kPrx71PRn4i6fgJpLzP+l6KM8iVAxOtN13FjP5yb6c+F8+hzCYjm/jdzLB+bKvlUHuBZKuBzawfX/X8XnEUv/atRrc/3w/t71Rm3VOcJ75xIzsucTAZwvgw7ZPmLRg/fP07Y+kuYQeP9QMiq3U8VjiN3ytQ7p0ZeDZzvBlViQC2TDNDP8aeKftCzrv2V5/8hrG1TWLmOG+yfbfFEotT3WNwLxUz7MIxYxLbB+vUMx4k+2+WSLbCiJtM2iyCd2/8brfSWHxoMxUDxlJ6xNL1sul/buAnVt+uH+HCERpShuzeaWOzHokHW37rZ399BA/HTg9GUt1+TiRUOC8VN9CZaZaVmhAf56YMfwUcU09GZglaWfbZw3QnklPmfGZava/hwgt8Nsm+nAV2w8DZxE6zksRxvV5Cl3yQ2q3tgUUmem+TdwLJOnP1LgXdBvU6dg/JNWegVR/JYW+ai+SViH83TcnBj8XAu/L/Y6SO8KFwAsJv1sBH7R9Z3ZHxupq1J8UhHcM4a4n4GmSdukYtRnnX8b23UTClvPSseWAf5KvOX88IcF6FyH1+bNUz1pk6rNLWtf2rwmDGkJmMPP0i2L7OmDPyv7NxH0ip+z5bQSB2r41DRKuaWLENr1egVUkfbWyv0J1v46rUJpAeQ+VAF3gsEEGcoVppm0n7bLV24hAtJdW9rcELm75HLWzU6VySwNvrOy/NbPci4C3pdfLw7iMj30DaoDn9jj2msrrf50pfWnSH1oKhKzUd1n39UBmIA4tZZmcyu94gDYsBbye8Pm9AtiPmK2binPlBPYNfC8ggvm27nF8K+DcAdq7gJhB7ezPJzOzU8AAAAAgAElEQVSgrlLmJ4T275y0vRX4Sc06FsmoOOD/v1F/CFe7dSr7a9dpGymrJSGNdlP629luqlHPC4HtqASiprZsnFn+8PT33B7bOTXacWL6ey1wTWW7NveeUqmrrSDQYwnXtkHLN7peiaQxE2412/LfxCBuq7QdRUjtNv4tlG1qt6E3YEnfSFHY/Y41PEe2cUb4or2SmDH7I5lqCpXy+xOzqb9J+08hfNRqtbfpA31U+tKkP0SWyo2IVYZFtgHacQQhz3cN4Xt8CPDNzLILK69/1fXeQCmFB/2OCRmwu3ts95CZvj09sK4i0nivX7f9PeprPEhoci8A1iN8OI8mgtd2T328EVhvgP60kX56EeWSXsf61HEokXSo6ffTVBliEUOx17Gp3IgVjAm3aW7Lyunv03ttNetqRZUIOCfdA84mDPXTCG39abteK+UaKfA0uReUbbhbcf8YPjdJ2o8x1YKdiNmLaUW99ZBXd3095O0IQ3ABgO07ko9oHf4d+J6kHYmZ4p2JWdIsRqwvMHh/nkpkOpsoELVusoc9iOj0fxJLyT8iXDlyaCvLZIeBv2Pbg3wH3byFiKpfG9izsgSuOIWXqVnft5I7wDiNXFJ2VOfp/w58L3AENq5PXPfrEf24AHiXe7iFZNTXRvrpuyTtRFxrEAOnv9Ss46XAuyXdwlhCJrtexr42+nOlpCMY+252ZCx50cBIWgfYx/Y7Mj7eCUyHRe8JpkEQmyKxzQdsvzzn87b/kP6O81dO7hw7AHX8mNsKAs1OrjIBja9XtafA87CkNW3/NtWzBvUyoxaGxbCt+iV9IxI9fJUw3BYAXwGe1PI5Lu3zfmt6yMDl6W9Hc/dxDDCjQxg71xGG37wa5UauL4P2hwHddjLqXabzv6lR5mHGZoMfYvzs8IPT9T+ZoJ4VgFU7W8v/q6zfIu3M7Pa6FzyxYftnE5nYcj/fvZx/J3B9Z7/muVclZgv/DPyJMGhrfT80nAltqz+Eq9DehHLJKcD7gaVqlH8OIRn3C2J1ZEVCMvM24P1tXrN92rEV8Bsi1ft3ieDeKwmD/fU16lmGMB6/xliWyT0IY/rU6epPy/+bRtcr8FHgf4nkXJ1jaxAD64/WbMvWxOz9ecD5hC//S+vUUbbhbEX9YwaTZHsmxPbvMus5mNBDvhY4jkgocK3t2jMfSVvzGYSywucIaaDjnBH81UMaaQUiAOefAM6YnRqVvqTyjfrTtsKCpE2AIxmTbvx/wK7uCuBqeI5+WSYbf8eVul5LzOQ/hXgIPp1wTVlvgKZPdI46qh1rMzYTuq3rz+z2qvMg2/tkfG4ZQn7rqcQ1/9O0/1/EEvbrMs/39Mned73005vbvqjfsQnKLk2oSqxF/JaPsP1Q7rkr9bTSH1VSyKf92YRRnbX6Jeky4BvAJYT6xweI+9N+HmAloavu7NluhYb0+1M7Oq5x+9k+uOY5TyViKy4hDMAnAXOJwL5a8n6SnkHcX59FxL4AUPeenYKpDyEGtnOJAeW9rr/qVK1zL9tfyfxsqwo8KYB6HWLA8mvb/6xTvjAcilE9ZBTJBN7olNZV0pOAE2y/IqNsx0CpLgWaCKhbwXadxBFiTA/5VcRMxG4MoIeclhI7sxc/sv2TzHJtPQCH3pdUtlF/JP2r7R8nA2Mt4rv97aAPYUnXAO+13VENeBHw9TqGbMY5JjVCWzbariZm3n5qeyNJLwXm235ndoP7n2PSgU2bg4QJ6v+d7UkHz+lzrRg5Csm3B51UBpLB9ipCWaWWvnSvayF3kCLpf4AHiRn/V6bzv6/O+bvqa5ROW9KlwMs69w9Jjwd+bHuzzPILbW9Y2f89sFrHSM+s4zmE4s1TiMHbIcDXgRcAX7T95Yw6umXffmt7zdw2VMpd65RGPA0w7iJmdWun05Z0IRG/8mVC6/pthG2yf816riRcT04ishruDDzD9kfqtqlSZ9bvL332etvrTPDer22vW+O87wWO7bIL5ntqEjkVWqT4VA+fJ1dv7Lb/T9IKOQU7N7UOklYjpKFeRqRGzcYxujoHOEfj9ZC/Tkin9aVLHinb+Ky04dZUT88HYI16ht6X1I6m/TlX0heIGfJbCS3mVSQdBezr+vJK93QM6tS+CyXVfgj2YVJ9rra+48SDtv8iaZakWbbPlXTAQK2epMl93t+m5fN1k6t3tkbFyPlvBjdyziIGoDcopNouIVQVtpG0ie0P921wZIXcDFhe0t6Vt5YhP0Pksyr9OYKIjWjCycDzUp+OIJb5jyMGDDksXR2Q2/57GoDksrSkjRj7Pv8OPCdNAGB7QUYd32L8bPcCog871hhoP1GR/bCDqvs1Bk6P3ntsPyzp5kEM6sQ822dLUro/fFzSzwhDuxa2b5Q0Ow1WjpJ08YBt6lBHb/A2SVvbPntcBdJWwB9qnvcdtg/t7CS74B3EM6wwwhSjevg8ImnVjqtGmsmrtXyQls/2Jc1YAHsOYHA9isfrIW/R7/OVcg9Luk/SsrazdFMnoOkDsNqmYfcFBu/PFwhXjdU7D6y0zH9Q2rJm7iR1ZqYuV2RzO564xt5E0sxtkdxrt43v+G9pxvAC4FhJfyL8vaeNNgYJCr3inm+R/1Bvy8h5ku1OFrldiIQ4eygSn1xF+NH2Yy6hfjCH8Vli7yY/lXa1Pw+pgZZyomk67XslbdwxfiU9j0UDdifjD0TK6g53VvZzg46Xsn10en29wj3tQ3Vmuwn/3NdMsG/ys11uIOnu9FrAvLQ/SKDv/Qqd6Rsk7Q7cTqz41OW+dJ0uTJMRfyAFDDagzrN4T+DUNPPeCSrdhAiUz3K/qjArDTIMj07yzK1ZR2EIFKN6+OwLXCipkz1qCyLdaV8U0f77EtH+XwB2q3mD7dQzG9ie8Mc8y/YvJG0DfASYRyhg5HI/cK3CreXezkHXEL6nwQNwBPsCg/dnG2Dtzo01nftuRYT5r8k0qomBVpXqDNCw/L+aGjkQD6r7CR/RHYkU1p9suZ251lyTQULnAdzrXA9knn+DilEDgxs51ethK+BAooIHlJlExpEJ73xF8qLOoGMW8HhHApQc2jTaoEE67cRewEmS7iD+R08hBqVZ2H5pzuckvXwSF7PGs92235bZjl1sHzNJPdmuhRnsRaQo35NQI9qKGNDV5S3ESsjuxD3hacAb+hVKq3W97oMinhlZuF0Fnh8BJ0r6Zmrbu4lVpMKIU3yqRwBFuucXEj/CS2zflVnuYSIo6gx6yO3kGn+SjiZuQJcTs923ApsSsyA/yKmjUlfPm+FkN+gedVxGKB/sS2j93qzMlK+j1pdUz0D9kfQbTxDcMtl7w0SZwZUNv+OvEQGjTZd2O/W9iPC9PErS8oTxd3N6bznbf82oY4HtjSV9APhHZ5CQ87+o0c71PEVp1Cvn+C4xi3o78CGSFKWkJwLn296gRl3HEcbAw8TAYVngS7YPbL/lfdsyUDptRXDv723fqXAlexeRMOg64GM510bNdk7ocy7p3EmK2nZdic2B2lHoTRpQr+hFg3NfDNzhJI+XWdcsYnLtZYRd8GMi+UuR1RtxilE9ZCRtTkTn36vQyNwYONgZAVsTGX0dco0/Sb8AnmP7EUVQ3F3AWh4gHXCqby4hlwZwfV1XlEEfgKnsSPUl1THoA/0HwPdtf7vr+E7A9rZfW7MdTyRm6lajskpVd+a9JSO0yXf8PiIgaWXgfwgXhVqKA5W69ieCmtaxvbakpwAn2d68Zj0DDxJqnGMyg6uqlnENcKQHU8uYR6yArJzquDod3wxY0/Z3JivfVddC2xsqtMifS8R7XOUWA2OnGkkLiADFvyrcx04gpOM2BJ5pO9edJfd8jQdifWa7p60dGec4bbL3c+9vigDsyeqZlutN0g+Bj9i+puv484D9bb+md8m+9S4HrNJdb2E0KUb1kEk3hA0Y88E8ktALfUnNeh5PzFbc2/fDi5btjggfeJZC4U96DKGrKWLWeBfbFwxS3wDnX5z68jTge4TvZtVHbx6wne3ba9Z3MXApIVH26FJ+zVWEVozQNlDEH+yQtqUJX/ETbP+mRh0LSQl+OkaEpGvqPoibDBJqnGNCQ0ctq2W0gaRfEsbnccDXbJ8v6eo6s90ttOFE29trUZWWrCQy1fZKOhT4s+2Pp/1xih4ttbfxDPGo1JFxjj8TK63HA5fR5f7kcCPKqWch8d0eR8TPjPN1z5mgaoPJBtGqqKVk1nUe8Fpi8mMhoZ19vu29JytXGD7Fp3r4PGTbkl5HpGY9ot8MdBW1k8Fp3cpoX8CaaX+Q7GVfJLKVXZ/aszZx03xuv4JNH4Cj1Jf0+ab9OTW5FGxNaLgKONNd0eU1WLqFm3KjLJMtfcekc98KHAAcoPA1PZLwF6/j7/lA+v11AoIGCmyyfR3hE9rZvxlozaDuVDvJe62oZUzy/UQD6v1+DiMGpFcDF6RBUK5PdVt0BhaDqrTMljQnzfpvzfh4l1F9fjaO6mypjn6sROQAmE/4IZ9BrDrVcnFKqyHrpnqOI1xzjiMkD6czcHnpSd7L9s1OLOuIn3k7cJTt/fvNyBdGg1G9KSxJ3CPpw0RK4i0UgXZZATSSPkpIV21p+6Z0bA3g4LQM/+nMNjxzgHZPxGM6RiiA7d8kX8Qcmj4AYXT6As370wlAOhsY1JCu8h2FLNMPSTrKqf46fqFNjdA2vmPSuTtyiTsQBs/51E9VfKJCEeWJ6X+zKyFdltuG1gYJDWlLLaO178f2V4kMkR1uVWiJTxtunk77eCLo8i5iBrSj8b4WoUdeC0lLuSuJR9exW+rW2YO+y8+SVu+4bE1wrG+CnqY4/IPPAs5SJDqZD5wn6ZPOTLBVqevXxIB6f0lvIlZ9DyAF2k4TV0h6h+1x9w9Ju1E/pf0cSSsTQff7ttXAwtRT3D+GjKSViFH6FbZ/psiSuKW7/GgnKNtqBqce9W8OvNn2e2uUOZK4qXd8L3cE5jgz6nyCOmcDO9g+tkEdI9GXVG9WfyTdxngZrnHYnvC9Cep7L/AZ4G+MPXjtGpnL1DDL5CT1Zn/HioQ884FXEzOyJwA/GMT1qVLfoAl+Vrb9B02Q1KbNpWdJl9p+4QTvPcyYQk1HteA+GFgto7v+Ot/PTra/q/Ea1Y9S97ptgsZnmjyN0JzfHdiHzEyTikx9KxMzn/emY2sTsQQ5+tLVugZOiNPkHJntuMp21ipcWyRj+tXE73k14js6cgDXtqcSg6TtiCRIJwKnuGayryZIWpFIYf8AY0b08wgpvO1cI65H0huB/YALbf9Hmiw70HZfNZPCcCkz1UMm/dC+VNn/HRV9W0mX2N50kvKLSPXY/ocy5a+6kbQhYeRvD9xMvm5ph/cQD7E94VFJoSxXlH4PQCIJRTbD7Es6f9P+zCb0fttait2bCNrMUpfphe2DkhF6N5FC92M1jdA2vuOPEMu7+0w2y67+KdPbSPDTdCa0WuZs21tPdGwigzq914rEWUvfT2f1ItstaAr5DmOZJt9OpG2fC7zOmcGtti/tcSzbbx8enTx5KiENWJXFW4aQk2uEpBfYvizt3jLJ59Yl5N6W1fgkMMswuftC60g6BlgfOBP4hO1fDFjP+cS1diLwVqBzT5irzMDpNrD9R2CztBrT8a0+w/Y5A9R1EpEZsrN/ExV5QEkftv25hk0uTAFlpnrE0eTBSWcDn+32sVVkcNrP+dqoaxMGwHzgL4Siwj62J00pPUFdjwPuT0t7HeNiKdv3ZZRtnGp5VPqSPt+oP1Mwg3UaMduY1f4e5atG6KBtaCWddua5cmbsTgPe4gET/LQ0E7o0YVidC2zJeIPrTNttujT1a8u0fT/TgVpMp92wHbsQBt/zgCsrb90DHO2aKeB71J+bzv51wLZEEFxVfeMeIsi3FZnKHNLET2d1pZfrVNbqiqRbKuV71ZO9EtcERYbNB50UoiStQ+jU32L7lJbPVSQPR5QyUz36TDbqaSuD068JX8HX2L4RQNL7B2suZxPamp1lt3mExuZmGWXbSLU8Kn2B5v1pO1joYSLb2LmM96nOktRzO1km20qnnUPO/69pgp/GM6GE9vFeREKRqyrtvhs4dKJCU0Tj70fSVyd7v8b/tg3aTKc9MA6FnWMkvcH2yVNwiqx7he1TiWfGprYvmYJ2ZGN7Vkv1rJbzOU29zvtZwG5EZsi1iHvCscA2kp5vOycbaS7TEUhaGIBiVM9g3F4GpzcQs7vnSjqL8FEd9Ee7dNWPzfbf0wg+hzYegKPSF2jen637f6QWP0hbE5oaodNp5OQsw52RtkFpbITaPpgILt7DDX3TW6CN76calPUJxmfwnG7azszYlB9KejOLasU3zQSateQs6QO2vwC8WZFhcnwl0zvgmW6+Q+SBmCqeZPuG9HoXQslkD0Wug6sIla62KC4GI0oxqkefSQ3CZDwf2eQEaWnqlOTusC2R4nVFSd8ggj1+XKO6eyVt7BTAoxC+/0efMh0aPwBHqC+N+9O2L6BrZoKcgKZG6EgZObaPUbMEP20OEh6R9ETbf4PwCQfmu548ZlPa+A0+ep1J2qul624g2vI1b5FTCdWQq6isFuUg6XQmTqf9L5nV/Cr9vXLSTy2eTPXsbvW72YqkPGL7gUFjnCahzFSPKMWneojk+KhKWn+iAA5J9zDxTbaRgaLI4vRGIoFFdvpbRVrfE4A7UtuekuqoKynUGotTX5og6WZ6aw/X8jlsaIROG5PFI1Q+syUNEvyoRdUN9UgmktOHUab4fo5HDbJsSpo0IZgzk6UsqUz1tSjpu8CdwO3Ah4DVbd+nyGR7vmskPeoXYCnpI7Y/27jRhdYpRvWQaRIoJekxbRg0Gp/i+FrgCNcUzU8G6O9t36nQD34X8HpCiP9jbc+6TtKOxaYvbSOpOpu1NDHQWM72x2rUsSVDzDLZ1ZaDiMQIPf0kcyL/JV1FSC2OS/DjaZYWS+e+hpDI7GiAzwausb3edLelLYpRPR5JhwOH2L62QR1LE/c3A7+t4+o3yWw3kJ8afCYyDUb1PELnfWVCFvDqdHwzYE3b35msfFddNxBqO0cRwcrFUJshFKN6yEg6EXghoRpQy0e1rZuEWkhxLGkB8DLbf5W0BTHDuweRpviZtv+9aTsz27HY9GU6kHSh7RfV+PwoGaFvB95GuLEdldpRa3CqHinJex2bDiQdSPjafpMwfN5NDO7+c7rb0oSuFbTHEjP3MDw/5pFB0nWEQXwz4f6RnSRI0hzgs4Q2/K3ALGAV4trfN2eCpTLb/Xoio+F30/58QqXiI7U6NAJImmW7r3uFJtF5n04knew+etOSRATJ7wo8n1CxOto1pRwL008xqoeMJkhJnuOH2NbSsMbLTs0BLq9rrEu6urO8JelQ4M+2P572F1nWnioWp760jaTq/2EWIe/1nprLkiNjhFbOvw5hXM8nMsF9y/a5mWWnJMHPIEiaRayKbE0YWz8G/ttJ0rEw81GDJEGSvkzoMb+/47evkHQ8CPhHnckDSRfY3qLfsZmApIXEfWyoaia51H1uK3Svv0vov18NfGim9HVJpAQqDpmGgVLLa4KsZanu3MxlbaQ4ni1pTnK12Bp4Z+W96bzOFqe+tM0XGZtBfIhw4XhjzTqulHQE443QYfrLzwbWTdtdxENnb0nvsr1DRhWNEvy0SZpt+0baCoshtm+V9CLgGbaPkrQ8keAph22AtauuALbvlvQeQkq0zorc8pLWcCQVQdLqwPI1yo8S7wIOkXQ18AFPkvBpRMhJI/8vwE7AW4A/EiulpxGrpScBq09lAwuDM5MNhMWCXj6qknJ9VNvKuNeGIsPxwPmS7iIUMn4GoNDrHFTTeBAWp760zSsJycHVGPvt7wDUkfMaGSNU0peIJBadJEiXp7cOkHR9ZjVzgIM7A9BkpC/VemMnQdKJtreXdC29A0mHtgpQaBdJ+xMrROsQbhuPIWYhN88o7l6+tQ7VmbpLzu8HzpN0U9pfjTBOZxy2L5P0AsJd6kpJZwKPVN6fiTKBlxATF9vavq1y/EpJ3xxSmwoZFPePIdPER3XUgoAkvZAI0vix7XvTsbWBxzvJ0s0UFqe+dFDodv8NWEAkggHA9hdr1NEoy2SbSNqVyAK3yLmVmaBG0qWE//zf0/7jie88N8FPYyStbPsPTVwDCjOD5KqwEbCg4wKQ6z4l6QfA921/u+v4TsD2dYMMJS1FrPAA/Np2LYm/USLN7B4IPAs4jPFG9dAkHXvRz/0j3VMPtD3hKnRhdCkz1cPnMR2DGsD2bxSKEzmMlFal7Ut7HJuRgRWLU18qrGL73xrW0TTLZJscTSSxWMP2JyWtCqxk+/IaAYtNE/w0JhnUswmlmoFTwBdmBA/YdmdmOQ1Sc3kv8P00mKxm0J0HbFenEZJ27jq0gSS6DfaZgKR3E5lMDwR26zWbPwzSc3x94Hbbf6q89cHJyqWVh+w4l8JoUYzq4dPER3WRjHvpJr0dkTTi1e00sbCYcLGkZ7uBnBcjYIRWOJSYkdqKcGG5BziZMDRyaZrgpxXcTgr4wuhzoqTDgCdKegeh7vCtnIK2bwdeIGkrxjLonmn77AHaUf2NLE08SxYAM86oBl4MbNpluE47yS3jEEem42UJF46HgeUk7WP7eADnJSBbqJDbPYnxqmDfn4KmF1qkGNXDp5eP6qE5BZ00eFOg46uIdOX/RhgWxe+q0M2LgLcqksDUkvOqMBJGaOIFtjeW9HMA2/+Xfgt12As4SdK4BD8ttzOXpingCyOO7YMkvRy4m/Cr/pjtn9Ss4xzgnM6+IrnIe21/pkYde1T3kxGYraM8YpzZMaglbW77os4bkna3/bVpaseLbb87vX4b8Bvb20paCTiTiNXJZTngL8SEQQcDxagecYpRPXzenYKkHlXqkPQ+4OB+BdPNeT7wCuBc4qb4/GHIgRVmBK9soY5RMkIfTG4TnaX05an4Uk6GxhL8XCFpXcYS/JxFaAgPg14p4EdiKbvQHI3PoFvLkE7lnwbsR/zmfgAcB3wK2Dm9bsJ9jClQzTT2Zkxv+xCgGme0KzBdRvUDldcvJ2aZcSQRq1VReYbPXGYNuwEFeulUvzWz7I+ANYEX2d7J9ulkGhWFJQ/bt/bacspK2kTSSravIIKb/oeQ5RumEfpV4BRgBUmfAS4kkmPkcBhjD8FNgY8QK0T/BxzecjtzeaLtY6ob8KQhtaXQMim49740KzwI3wbuIAzH9YBLCQP72a6f4Op0Sael7QzgesJQn4logte99qeSv0naRtJGhJrLWfBovoR5dSqStIqkUyT9SdIfJZ0saZUpaHOhZcpM9ZCQNJ9w11g9+U51eAKx7JPDcwlJtJ8maaQTCJm9QqFtDiMCFGHMCO1kmTwcmPYsk7aPTeo5nWQp29r+VWbx2R5LYf4m4HDbJwMnJ4WGYbALi65QvbXHscLMpYmLz3JOSaiAH0n6I7DJgKodB1VeP0T8fuYPUM8o4Ale99qfSt5FDPRXAvayfWc6vjWLrkD14yhi9aGTR2CndOzlLbSzMIUUo3p4XAz8AXgykZSjwz3ANTkV2P458HPgg5I2J26Kc5NO5ym2hzXjVlj8GEUjFOAGwj91DoCkVW3/LqPcyCT4mWSAvQz5A+zCzKCXi082kp7E2OzrncBjOwoild9nX2yfL2lD4rrbnlhtOnnQdg2ZdSVdQ/xf1kyvSftrTFcjkjrUIupKtn9ErCrXYXnbR1X2j5a0V5P2FaaHYlQPibTsfqukHYE7bN8PIGkesAqRDKZOfRcBF0nak5hR3IHhLWMXFj9GxgjtIGkPYH8i49jDpMBLICfwcpQS/DQeYBdmBo4MuvOAVatSqpksSyhDVV0aOpr5JsOATFr7OxATMH8h3Lhk+6U12zJKPHPYDQBIai7n2b5B4UR9JJFs6xZglzQJlstdSX+8E9zY+b4KI05J/jJkJF0JbGb7gbQ/F7jIdl9ZMEmvAJ5g+3tdx3cE/lQ3qrxQmAhJ+xIKM3cBqwIbJ73dtYBjbOdkhGu7TTcSCiADPWw0Ygl+0ozjP2w/ktqxLqFs8OB0t6UwNUh6DeF6Mdf26mm2+JM5iVskPb1pIiBJjxADyN1s35iO3WR72mZ0F1ck/QLYyPaDkt4M/Cfwr0Syn/1tv7hGXasSAZabEgOmi4E9M1fhCkOkzFQPnzkdgxrA9gM1ZME+Abymx/GziQCuYlQXWsH2ZySdzZgR2hmNzyJ8q4fB72kwqzyCCX4uAF6clvjPBq4kXG12HGKbCu3yceD5wHkAthdKWj2z7CmMV7YYhDcQM9XnKjKsnsCIJRGrS5IIrc4OqrJv22tOU1MeqgyAtwG+nQb8P5X0hZp1Pa17oJVcPItRPeIUo3r4/FnSa22fBiDpdcRsYA6Ptf3n7oNJwqdOpq5CoS8jaITeBJyX1AseDdZKEpUzEdm+T9JuRBKJL3Q0uAuLDQ/Z/n9dEmu5y8WNjV/bpwCnpOfDtsD7gRUlfYOIw8lJTDJqPK9rfxbhJ74PEXM0XTwiaWVCQWhroKobXkv9g0WlASc6VhgxilE9fN4NHCvpUOLmehuhO5rD0hU/10dRpEet+yMuFGYav0vb3LTNdCRpU2Jmerd0rNyjFy9+kVwDZkt6BpH06+LMsk+V9NWJ3qyTJCi5Ox1LPHuWI1QmPgTMOKO64/4laRbwFiJl+ULg1bavm8amfIxYXZoNnGb7l6ldLyEmAPqSfv+bActL2rvy1jIUZa8ZQfGpHhEkPZ74Pu6pUebzwIrA7hWf0McRsj532f7glDS2UBghJD2BWOb9e98PjzDp4fufREzFAZLWIKS5SkbFxQRJjwX2JXxtRahCfKoTqN6n7K2E4daTpGu+xJEmkXYlZt0vBD5n+7dDasscIs7p/yrHHkc82/ven9I9YEtisq2aFfke4HTbN7Tb4kLbFKN6yEhakUhY8RTbr5T0LGBT20dklJ0DfBp4O3ArcZN+GnAEsF8JcCoszkhan1wwU6gAAAdDSURBVMgiulw6dBewc2eGqFBYnJC0wHZZ/u9C0m2E1vZX6OFzbHvaUntLWgF4L5Gcx8B1wNdt/7FmPY8GpaYZ+Mfbvrvt9hbapxjVQyZpSh8F7Gt7g2Qo/9z2s2vUMQ9YK+3eaPsfU9DUQmGkkHQx8bs5N+1vCXzW9mZDbVhNJH3F9l6STqeHf22OMkRhZpBUXfYBVqPi2mN7q4yyl9p+4dS1bmYi6Wgm9ku37V2nqR2bEwlbjmZM+nBjIqnTjkn2Nreu44jZ6odTXcsCX7J9YMvNLrRMMaqHjKQrbG8i6ee2N0rHFtreMLN8r5Hxobb/NGWNLhRGAElX296g37FRR9JzbV+Vln4Xwfb5092mwtQg6WpiWf8qwmACwPZVGWVXnez9Irc2XCRdCrynW486ySYeZvsFNepaaHvDJI/7XOCDwFW2czT4C0OkBMEMn3sl/QtppJ20c7NkwrpGxt9mbGR8uaRaI+NCYQZyk6T9CBcQiFS+Nw+xPQPRMahSlrvl0+tFVH0KiwUP2f7GgGXPIJ4TVRUQA8sDK7AEB7IlV7D/Yvzk0kG2r53GZizTK8FLkk18Qs26HpN8xbcFvpa0r8sM6AygGNXDZ2/gNCK96kXEDfLfM8t+Edi264d8qqRTgMOA7JFxoTAD2ZXQav8+YWhcALxtqC0agJR9bX9gd6IfsyQ9RMjqfXKojSu0QlLYADhd0n8QmtNVGci+Kca7XQIlrUbMYL6MiMtZIkkytAcBnyOeiSJmd78vaR/bp05fU/SkapBiOrgcIfNXh8OITIxXAxdIejpQfKpnAMX9Y0hI2gT4fdKUngO8ixDmvw74WM5NVtJ1tp9V971CoTA6SHo/ka3ynbZvTsfWAL4BnGX7y8NsX6E5lQQlvbSmXSejYZLi25eYNPkikdF0iQ1KTy41r7N9S9fx1YBTp8sdTNI7gXcQPvOdjKzPBQ4AjrL9zYnKZta/iHxuYfQoRvWQkLQAeJntv0ragshstQewIfBM231nqyX9ikhx3mtkfLHtdaeg6YXCUJF02mTvz7TAvpTg5eW27+o6vjyRvXKj4bSsMEokF4d9CReHLwDH23548lKLP6M0uSRpG+ADjHdDOdD26Znld7L93S6N6keZwYmtlhiK+8fwmF2ZjX4TcLjtk4GTJS3MrOPLwI8l9RoZf6XV1hYKo8OmRIry44HLmOFploHHdBvUEH7Vya+ysBghaTMWVf/4dkbRq4nr/gwi1fnzq5kZl2A98wclrdodqJlcJqZ1Ztf2D4Efdh+XtJftnGdyJxNyXR/swohQjOrhMbuynLM18M7Ke1nfi+3DJd0BfIrxI+NP546MC4UZyErAy4H5wJsJI+P4GaxP/cCA7xVmGJK+A6xJZPzrzDKbCDTvx7RIw81A9gd+KumzhKqKgU2IDJGjkgBtbzImumwflv5+YspbVJgSivvHkJC0L+FHeRewKrCxbUtai/CR27xh/bkj40JhxiJpKcK4PhD4pO1Dhtyk2kh6GLi311vA0rbLbPViQnLZe5YbPnhTBl53Muku6UjagMhGuh7xu/klof5x9VAblpD0e9tPy/jchGnoYYlejZgxFKN6iCT5vJUJv8lOmvG1iexJCyYt3L/u39meVNe0UJipJGP61YRBvRqhoHOk7duH2a5CYTIknQTsafsPA5Z/D/BhxtwE/g4cYPvrLTWxMAXkPo8l7VLZ/QQxC/8oS2oq+plEMaoXU3JHxoXCTEPSMcD6wJnACbZ/MeQmFQpZSDqXCEa/nPGSen2DayV9FNgM2N32TenYGsDBwGW2Pz0ljR5xRiVwWdI99M7sKGCe7VruttWEcIWZQzGqF1PKTHVhcUXSI4y5S1RvYCKWxJeZ/lYVCv1pkjVT0vXABrbv7zo+D7ja9trttHJmIenPTBK4PFMzkkpaYHvjYbejUI8SqDiD6TcynubmFArTgu26iRQKhZGgqYHXbVCnY/9IA80llcUtcLkwgylG9QzGdpHdKRQKhRGnzwRI7urKbZK2tn12V91bAwP5aC8OJK3us4CzKoHL50macYHLXdfJYyV1siiWVbgZQnH/KBQKhUJhxJG0HnAqcCHjpeM2JzIKLrEzsyVwuTAqFKO6UCgUCoURJ8mtrgSszXjpuBuA223/dojNGxolcLkwShSjulAoFAqFEUfSD4GP2L6m6/jzgP1tv2Y4LRsuJXC5MEoUn+pCoVAoFEaf1boNagDbV0pabfqbMxqUwOXCKFEuxkKhUCgURp+lJ3mvqD0VCiNAMaoLhUKhUBh9rpD0ju6DknYjAhcLhcKQKT7VhUKhUCiMOJJWBE4BHmDMiH4eMBfYzvadw2pboVAIilFdKBQKhcIMQdJLCbULgF/aPmeY7SkUCmMUo7pQKBQKhUKhUGhI8akuFAqFQqFQKBQaUozqQqFQKBQKhUKhIcWoLhQKhUKhUCgUGlKM6kKhUCgUCoVCoSHFqC4UCoVCoVAoFBry/wFngabRmCkORQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Exploring dataset - (1) Correlation within variables\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(df.drop(['Detection_Risk'], axis=1).corr(), cmap = 'coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TOTAL</th>\n",
       "      <td>0.888086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PARA_B</th>\n",
       "      <td>0.887780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Risk_B</th>\n",
       "      <td>0.887556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inherent_Risk</th>\n",
       "      <td>0.750873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>History_score</th>\n",
       "      <td>0.431217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prob</th>\n",
       "      <td>0.431217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONTROL_RISK</th>\n",
       "      <td>0.357872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Risk_D</th>\n",
       "      <td>0.334091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <td>0.332883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>History</th>\n",
       "      <td>0.329682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Risk_F</th>\n",
       "      <td>0.327669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MONEY_Marks</th>\n",
       "      <td>0.291531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score_MV</th>\n",
       "      <td>0.291531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marks</th>\n",
       "      <td>0.259593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score_B.1</th>\n",
       "      <td>0.259593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Risk_C</th>\n",
       "      <td>0.249884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Risk_A</th>\n",
       "      <td>0.221400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numbers</th>\n",
       "      <td>0.221326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PARA_A</th>\n",
       "      <td>0.219582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Risk</th>\n",
       "      <td>0.216845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score_B</th>\n",
       "      <td>0.207708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RiSk_E</th>\n",
       "      <td>0.202779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score_A</th>\n",
       "      <td>0.201556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>District_Loss</th>\n",
       "      <td>0.199220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOSS_SCORE</th>\n",
       "      <td>0.073724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROB</th>\n",
       "      <td>0.073724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss</th>\n",
       "      <td>0.049199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOCATION_ID</th>\n",
       "      <td>-0.085276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Money_Value</th>\n",
       "      <td>-0.092576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sector_score</th>\n",
       "      <td>-0.092576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Correlation\n",
       "TOTAL             0.888086\n",
       "PARA_B            0.887780\n",
       "Risk_B            0.887556\n",
       "Inherent_Risk     0.750873\n",
       "History_score     0.431217\n",
       "Prob              0.431217\n",
       "CONTROL_RISK      0.357872\n",
       "Risk_D            0.334091\n",
       "Score             0.332883\n",
       "History           0.329682\n",
       "Risk_F            0.327669\n",
       "MONEY_Marks       0.291531\n",
       "Score_MV          0.291531\n",
       "Marks             0.259593\n",
       "Score_B.1         0.259593\n",
       "Risk_C            0.249884\n",
       "Risk_A            0.221400\n",
       "numbers           0.221326\n",
       "PARA_A            0.219582\n",
       "Risk              0.216845\n",
       "Score_B           0.207708\n",
       "RiSk_E            0.202779\n",
       "Score_A           0.201556\n",
       "District_Loss     0.199220\n",
       "LOSS_SCORE        0.073724\n",
       "PROB              0.073724\n",
       "Loss              0.049199\n",
       "LOCATION_ID      -0.085276\n",
       "Money_Value      -0.092576\n",
       "Sector_score     -0.092576"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correlation with target variables\n",
    "cor = pd.DataFrame(df.drop(\"Audit_Risk\", axis=1).apply(lambda x: x.corr(df.Audit_Risk)).sort_values(ascending = False)).rename(columns = {0:'Correlation'})\n",
    "cor.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler # Used MinMaxScaler\n",
    "reg_data = df.drop(['Audit_Risk','Risk'], axis=1)\n",
    "reg_target = df['Audit_Risk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting training and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_org, X_test_org, y_train, y_test = train_test_split(reg_data, reg_target, random_state=0)\n",
    "\n",
    "# Scaling data\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train_org)\n",
    "X_test = scaler.transform(X_test_org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Task "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Two models with bagging and pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing models\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.ensemble import BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1) Linear Regression\n",
      "\n",
      "Bagging\n",
      "Train Score: 0.825529\n",
      "Test Score: 0.525339\n",
      "\n",
      "Pasting\n",
      "Train Score: 0.854711\n",
      "Test Score: 0.518959\n"
     ]
    }
   ],
   "source": [
    "#Linear Regression\n",
    "print('(1) Linear Regression')\n",
    "print()\n",
    "\n",
    "lreg = LinearRegression()\n",
    "\n",
    "lreg_bag = BaggingRegressor(lreg, bootstrap=True, n_jobs=-1, random_state=0)\n",
    "lreg_bag.fit(X_train, y_train)\n",
    "print(\"Bagging\")\n",
    "print(\"Train Score: {:4f}\".format(lreg_bag.score(X_train, y_train)))\n",
    "print(\"Test Score: {:4f}\".format(lreg_bag.score(X_test, y_test)))\n",
    "print()\n",
    "\n",
    "lreg_pas = BaggingRegressor(lreg, bootstrap=False, n_jobs=-1, random_state=0)\n",
    "lreg_pas.fit(X_train, y_train)\n",
    "print(\"Pasting\")\n",
    "print(\"Train Score: {:4f}\".format(lreg_pas.score(X_train, y_train)))\n",
    "print(\"Test Score: {:4f}\".format(lreg_pas.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) Lasso Regression\n",
      "\n",
      "Bagging\n",
      "Train Score: 0.335160\n",
      "Test Score: 0.079369\n",
      "\n",
      "Pasting\n",
      "Train Score: 0.331951\n",
      "Test Score: 0.065304\n"
     ]
    }
   ],
   "source": [
    "#LASSO Regression\n",
    "print('(2) Lasso Regression')\n",
    "print()\n",
    "\n",
    "lasso = Lasso(alpha=1.0) #the best parameter alpha=1.0\n",
    "lasso_bag = BaggingRegressor(lasso, bootstrap=True, n_jobs=-1, random_state=0)\n",
    "lasso_bag.fit(X_train, y_train)\n",
    "print(\"Bagging\")\n",
    "print(\"Train Score: {:4f}\".format(lasso_bag.score(X_train, y_train)))\n",
    "print(\"Test Score: {:4f}\".format(lasso_bag.score(X_test, y_test)))\n",
    "print()\n",
    "\n",
    "print(\"Pasting\")\n",
    "lasso_pas = BaggingRegressor(lasso, bootstrap=False, n_jobs=-1, random_state=0)\n",
    "lasso_pas.fit(X_train, y_train)\n",
    "print(\"Train Score: {:4f}\".format(lasso_pas.score(X_train, y_train)))\n",
    "print(\"Test Score: {:4f}\".format(lasso_pas.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3) KNN Regression\n",
      "\n",
      "Bagging\n",
      "Train Score: 0.335160\n",
      "Test Score: 0.079369\n",
      "\n",
      "Pasting\n",
      "Train Score: 0.756169\n",
      "Test Score: 0.178808\n"
     ]
    }
   ],
   "source": [
    "#KNN Regression\n",
    "print('(3) KNN Regression')\n",
    "print()\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "knn_reg = KNeighborsRegressor(3)  #the best parameter n=3\n",
    "knn_reg.fit(X_train, y_train)\n",
    "knn_bag = BaggingRegressor(knn_reg, bootstrap=True, n_jobs=-1, random_state=0)\n",
    "lasso_bag.fit(X_train, y_train)\n",
    "print(\"Bagging\")\n",
    "print(\"Train Score: {:4f}\".format(lasso_bag.score(X_train, y_train)))\n",
    "print(\"Test Score: {:4f}\".format(lasso_bag.score(X_test, y_test)))\n",
    "print()\n",
    "\n",
    "print(\"Pasting\")\n",
    "lasso_pas = BaggingRegressor(knn_reg, bootstrap=False, n_jobs=-1, random_state=0)\n",
    "lasso_pas.fit(X_train, y_train)\n",
    "print(\"Train Score: {:4f}\".format(lasso_pas.score(X_train, y_train)))\n",
    "print(\"Test Score: {:4f}\".format(lasso_pas.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Two models with Adaboost boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1) Linear Regression\n",
      "\n",
      "Best Parameter: {'learning_rate': 0.1, 'n_estimators': 10}\n",
      "Train Score: 0.861234\n",
      "Test Score: 0.575278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "#Linear Regression\n",
    "print('(1) Linear Regression')\n",
    "print()\n",
    "\n",
    "param_grid = { 'n_estimators': [10, 50, 100],\n",
    "              'learning_rate' : [0.1,0.5,1] }\n",
    "ada_grid = GridSearchCV(AdaBoostRegressor(LinearRegression()), \n",
    "                        param_grid,n_jobs=-1)\n",
    "ada_grid.fit(X_train, y_train)\n",
    "print('Best Parameter: {}'.format(ada_grid.best_params_))\n",
    "\n",
    "ada_reg = AdaBoostRegressor(LinearRegression(), learning_rate=0.1, n_estimators=10)\n",
    "ada_reg.fit(X_train, y_train)\n",
    "print(\"Train Score: {:4f}\".format(ada_reg.score(X_train, y_train)))\n",
    "print(\"Test Score: {:4f}\".format(ada_reg.score(X_test, y_test)))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) LASSO Regression\n",
      "\n",
      "Best Parameter: {'learning_rate': 1, 'n_estimators': 10}\n",
      "Train Score: 0.658038\n",
      "Test Score: 0.240431\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "#Linear Regression\n",
    "print('(2) LASSO Regression')\n",
    "print()\n",
    "\n",
    "param_grid = { 'n_estimators': [10, 50, 100],\n",
    "              'learning_rate' : [0.1,0.5,1] }\n",
    "ada_grid = GridSearchCV(AdaBoostRegressor(Lasso(alpha=1.0)), \n",
    "                        param_grid,n_jobs=-1)\n",
    "ada_grid.fit(X_train, y_train)\n",
    "print('Best Parameter: {}'.format(ada_grid.best_params_))\n",
    "\n",
    "ada_reg = AdaBoostRegressor(Lasso(alpha=1.0), learning_rate=0.1, n_estimators=50)\n",
    "ada_reg.fit(X_train, y_train)\n",
    "print(\"Train Score: {:4f}\".format(ada_reg.score(X_train, y_train)))\n",
    "print(\"Test Score: {:4f}\".format(ada_reg.score(X_test, y_test)))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) One model with Gradient boosting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1) Gradient Boosted Regression Trees\n",
      "\n",
      "Best Parameter: {'learning_rate': 0.5, 'max_depth': 10, 'n_estimators': 8, 'subsample': 0.5}\n",
      "Train Score: 0.999957\n",
      "Test Score: 0.289579\n",
      "Mean Squared Error: 3530.585249\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "#Linear Regression\n",
    "print('(1) Gradient Boosted Regression Trees')\n",
    "print()\n",
    "\n",
    "param_grid = {\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1, 0.5],\n",
    "    \"max_depth\":[3,5,8, 10],\n",
    "    \"subsample\":[0.5, 0.75, 1.0],\n",
    "    \"n_estimators\":[3, 5, 8, 10]\n",
    "    }\n",
    "\n",
    "gbr_grid = GridSearchCV(GradientBoostingRegressor(),  \n",
    "                        param_grid,n_jobs=-1)\n",
    "gbr_grid.fit(X_train, y_train)\n",
    "print('Best Parameter: {}'.format(gbr_grid.best_params_))\n",
    "\n",
    "\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.5, max_depth=8, n_estimators=10, subsample=0.75, random_state=0)\n",
    "gbr.fit(X_train, y_train)\n",
    "y_pred = gbr.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Train Score: {:4f}\".format(gbr.score(X_train, y_train)))\n",
    "print(\"Test Score: {:4f}\".format(gbr.score(X_test, y_test)))\n",
    "print(\"Mean Squared Error: {:4f}\".format(mse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting training and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_org, X_test_org, y_train, y_test = train_test_split(reg_data, reg_target, random_state=0)\n",
    "\n",
    "# Scaling data\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train_org)\n",
    "X_test = scaler.transform(X_test_org)\n",
    "\n",
    "# Dimension Reduction\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components= 0.95)\n",
    "X_reduced_train = pca.fit_transform(X_train)\n",
    "X_reduced_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dimensions: 8\n",
      "Explained Variance Ratio: 0.04320262807034925\n"
     ]
    }
   ],
   "source": [
    "print('Number of dimensions:', pca.n_components_) \n",
    "print('Explained Variance Ratio:',1- pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv=5\n",
      "Best parameters: {'fit_intercept': True, 'normalize': False}\n",
      "Best cross-validation score: 0.30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josep\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#(1) Linear Regression\n",
    "\n",
    "lreg = LinearRegression()\n",
    "param_grid = {'fit_intercept':[True,False], 'normalize':[True,False]}\n",
    "\n",
    "#cv =5\n",
    "grid = GridSearchCV(lreg, param_grid, cv=5, return_train_score=True, n_jobs = -1)\n",
    "grid.fit(X_reduced_train, y_train)\n",
    "print('cv=5')\n",
    "print(\"Best parameters: {}\".format(grid.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - Train Score: 0.23\n",
      "Linear Regression - Test Score: 0.23 \n"
     ]
    }
   ],
   "source": [
    "lreg_accuracy_train = grid.best_estimator_.score(X_reduced_test, y_test)\n",
    "lreg_accuracy_test = grid.best_estimator_.score(X_reduced_test, y_test)\n",
    "\n",
    "print('Linear Regression - Train Score: %.2f'%lreg_accuracy_train)\n",
    "print('Linear Regression - Test Score: %.2f '%lreg_accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_table = [['Linear Regression', '',\n",
    "                 grid.best_estimator_.score(X_reduced_train, y_train), \n",
    "                 grid.best_estimator_.score(X_reduced_test, y_test)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josep\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv=5\n",
      "Best parameters: {'alpha': 100}\n",
      "Best cross-validation score: 0.42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#(2) Ridge Regression\n",
    "from sklearn.linear_model import Ridge\n",
    "param_grid = {'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "# create and fit a ridge regression model, testing each alpha\n",
    "# cv = 5\n",
    "model = Ridge(random_state=0)\n",
    "grid = GridSearchCV(model, param_grid, cv = 5)\n",
    "grid.fit(X_reduced_train, y_train)\n",
    "# summarize the results of the grid search\n",
    "print('cv=5')\n",
    "print(\"Best parameters: {}\".format(grid.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression - Train Score: 0.39\n",
      "Ridge Regression - Test Score: 0.14 \n"
     ]
    }
   ],
   "source": [
    "ridge_accuracy_train = grid.best_estimator_.score(X_reduced_train, y_train)\n",
    "ridge_accuracy_test = grid.best_estimator_.score(X_reduced_test, y_test)\n",
    "\n",
    "print('Ridge Regression - Train Score: %.2f'%ridge_accuracy_train)\n",
    "print('Ridge Regression - Test Score: %.2f '%ridge_accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_table = report_table + [['Ridge', 'alpha = 100', \n",
    "                                grid.best_estimator_.score(X_reduced_train, y_train), \n",
    "                                grid.best_estimator_.score(X_reduced_test, y_test)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josep\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv=5\n",
      "Best parameters: {'alpha': 1}\n",
      "Best cross-validation score: 0.39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#(3) LASSO\n",
    "from sklearn.linear_model import Lasso\n",
    "param_grid = {\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "# create and fit a ridge regression model, testing each alpha\n",
    "# cv = 5\n",
    "model = Lasso(random_state=0)\n",
    "grid = GridSearchCV(model, param_grid, cv = 5)\n",
    "grid.fit(X_reduced_train, y_train)\n",
    "# summarize the results of the grid search\n",
    "print('cv=5')\n",
    "print(\"Best parameters: {}\".format(grid.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression - Train Score: 0.36\n",
      "Lasso Regression - Test Score: 0.14 \n"
     ]
    }
   ],
   "source": [
    "lasso_accuracy_train = grid.best_estimator_.score(X_reduced_train, y_train)\n",
    "lasso_accuracy_test = grid.best_estimator_.score(X_reduced_test, y_test)\n",
    "\n",
    "print('Lasso Regression - Train Score: %.2f'%lasso_accuracy_train)\n",
    "print('Lasso Regression - Test Score: %.2f '%lasso_accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_table = report_table + [['Lasso', 'alpha = 1.0', \n",
    "                                grid.best_estimator_.score(X_reduced_train, y_train), \n",
    "                                grid.best_estimator_.score(X_reduced_test, y_test)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv=5\n",
      "Best parameters: {'n_neighbors': 3}\n",
      "Best cross-validation score: 0.46\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josep\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#(4) KNN\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor()\n",
    "param_grid = {'n_neighbors':np.arange(1,11,1)}\n",
    "\n",
    "#cv =5\n",
    "grid = GridSearchCV(knn, param_grid, cv=5, return_train_score=True, n_jobs = -1)\n",
    "grid.fit(X_reduced_train, y_train)\n",
    "print('cv=5')\n",
    "print(\"Best parameters: {}\".format(grid.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Regression - Train Score: 0.76\n",
      "KNN Regression - Test Score: 0.13 \n"
     ]
    }
   ],
   "source": [
    "knnreg_accuracy_train = grid.best_estimator_.score(X_reduced_train, y_train)\n",
    "knnreg_accuracy_test = grid.best_estimator_.score(X_reduced_test, y_test)\n",
    "\n",
    "print('KNN Regression - Train Score: %.2f'%knnreg_accuracy_train)\n",
    "print('KNN Regression - Test Score: %.2f '%knnreg_accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_table =report_table +  [['KNN', 'n = 3', \n",
    "                                grid.best_estimator_.score(X_reduced_train, y_train), \n",
    "                                grid.best_estimator_.score(X_reduced_test, y_test)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'linearregression__fit_intercept': True, 'linearregression__normalize': True, 'polynomialfeatures__degree': 1}\n",
      "Best cross-validation score: 0.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josep\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#(5) Polynomial Regression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "def PolynomialRegression(degree=2, **kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree), LinearRegression(**kwargs))\n",
    "\n",
    "param_grid = {'polynomialfeatures__degree': np.arange(4), \n",
    "        'linearregression__fit_intercept': [True, False], \n",
    "        'linearregression__normalize': [True, False]}\n",
    "\n",
    "grid = GridSearchCV(PolynomialRegression(), param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "grid.fit(X_reduced_train, y_train)\n",
    "print(\"Best parameters: {}\".format(grid.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Regression - Train Score: 0.50\n",
      "Polynomial Regression - Test Score: 0.23 \n"
     ]
    }
   ],
   "source": [
    "poly_accuracy_train = grid.best_estimator_.score(X_reduced_train, y_train)\n",
    "poly_accuracy_test = grid.best_estimator_.score(X_reduced_test, y_test)\n",
    "\n",
    "print('Polynomial Regression - Train Score: %.2f'%poly_accuracy_train)\n",
    "print('Polynomial Regression - Test Score: %.2f '%poly_accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_table =report_table +  [['Polynomial', 'degree=1', \n",
    "                                grid.best_estimator_.score(X_reduced_train, y_train), \n",
    "                                grid.best_estimator_.score(X_reduced_test, y_test)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv=5\n",
      "Best parameters: {'C': 1, 'epsilon': 10}\n",
      "Best cross-validation score: 0.43\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josep\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#(6) Linear SVR\n",
    "from sklearn.svm import LinearSVR\n",
    "model = LinearSVR()\n",
    "parameters = {'C':[0.001, 0.01, 0.1, 1, 10], 'epsilon':[0.001,0.01,0.1,1,10]}\n",
    "\n",
    "#cv = 5\n",
    "grid = GridSearchCV(model, parameters, cv=5, return_train_score=True, n_jobs = -1)\n",
    "grid.fit(X_reduced_train, y_train)\n",
    "print('cv=5')\n",
    "print(\"Best parameters: {}\".format(grid.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVR - Train Score: 0.39\n",
      "Linear SVR - Test Score: 0.15 \n"
     ]
    }
   ],
   "source": [
    "lsvr_accuracy_train = grid.best_estimator_.score(X_reduced_train, y_train)\n",
    "lsvr_accuracy_test = grid.best_estimator_.score(X_reduced_test, y_test)\n",
    "\n",
    "print('Linear SVR - Train Score: %.2f'%lsvr_accuracy_train)\n",
    "print('Linear SVR - Test Score: %.2f '%lsvr_accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_table =report_table +  [['SVR', 'C=1, epsilon=10', \n",
    "                                grid.best_estimator_.score(X_reduced_train, y_train), \n",
    "                                grid.best_estimator_.score(X_reduced_test, y_test)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv=5\n",
      "Best parameters: {'C': 10, 'epsilon': 1, 'gamma': 0.1}\n",
      "Best cross-validation score: 0.49\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josep\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#(7) RBF kernel SVR\n",
    "from sklearn.svm import SVR\n",
    "model = SVR(kernel='rbf')\n",
    "parameters = {'C':[0.001, 0.01, 0.1, 1,10],'gamma':[0.0001,0.001, 0.01, 0.1, 1],'epsilon':[0.01, 0.1, 1]}\n",
    "\n",
    "#cv =5\n",
    "grid = GridSearchCV(model, parameters, cv=5, return_train_score=True, n_jobs = -1)\n",
    "grid.fit(X_reduced_train, y_train)\n",
    "print('cv=5')\n",
    "print(\"Best parameters: {}\".format(grid.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF SVR - Train Score: 0.41\n",
      "RBF SVR - Test Score: 0.07 \n"
     ]
    }
   ],
   "source": [
    "rbf_svr_accuracy_train = grid.best_estimator_.score(X_reduced_train, y_train)\n",
    "rbf_svr_accuracy_test = grid.best_estimator_.score(X_reduced_test, y_test)\n",
    "\n",
    "print('RBF SVR - Train Score: %.2f'%rbf_svr_accuracy_train)\n",
    "print('RBF SVR - Test Score: %.2f '%rbf_svr_accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_table = report_table + [['RBF Kernel SVR', 'C=10, epsilon=1, gamma=0.1', \n",
    "                                grid.best_estimator_.score(X_reduced_train, y_train), \n",
    "                                grid.best_estimator_.score(X_reduced_test, y_test)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Parameter</th>\n",
       "      <th>Train Score</th>\n",
       "      <th>Test Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td></td>\n",
       "      <td>0.501870</td>\n",
       "      <td>0.227250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>C=1, epsilon=10</td>\n",
       "      <td>0.389456</td>\n",
       "      <td>0.151080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>alpha = 1.0</td>\n",
       "      <td>0.362740</td>\n",
       "      <td>0.140918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>alpha = 100</td>\n",
       "      <td>0.392291</td>\n",
       "      <td>0.135664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>n = 3</td>\n",
       "      <td>0.755355</td>\n",
       "      <td>0.131152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RBF Kernel SVR</th>\n",
       "      <td>C=10, epsilon=1, gamma=0.1</td>\n",
       "      <td>0.412363</td>\n",
       "      <td>0.070397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Model Parameter  Train Score  Test Score\n",
       "Model Name                                                            \n",
       "Linear Regression                                 0.501870    0.227250\n",
       "SVR                           C=1, epsilon=10     0.389456    0.151080\n",
       "Lasso                             alpha = 1.0     0.362740    0.140918\n",
       "Ridge                             alpha = 100     0.392291    0.135664\n",
       "KNN                                     n = 3     0.755355    0.131152\n",
       "RBF Kernel SVR     C=10, epsilon=1, gamma=0.1     0.412363    0.070397"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = pd.DataFrame(report_table,columns = ['Model Name', 'Model Parameter', 'Train Score', 'Test Score'])\n",
    "report.index = report['Model Name']\n",
    "report.drop(['Model Name'],axis=1,inplace=True)\n",
    "report= report.drop(['Polynomial'])# as polynomial regression with the degree of 1 is exatly same to linear Regression\n",
    "report.sort_values(by='Test Score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x258126e9be0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(y =report.index, x = 'Test Score',data = report.sort_values(by='Test Score', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result from Project 1\n",
    "<img src=\"Result Table.png\">\n",
    "<img src=\"Result 1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA result is not bettern than the one from Project 1 on Regression Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) Deep Learning Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading packages\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    # Defining model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=30, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compiling model\n",
    "    model.compile(loss='mse', optimizer='sgd', metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasRegressor(build_fn= create_model, verbose=0)\n",
    "param_grid = {'batch_size':[5,10,25,50], 'epochs':[10, 50,100]}\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting model\n",
    "grid_search_result = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'batch_size': 5, 'epochs': 100}\n",
      "Best cross-validation score: -0.04\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid_search_result.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search_result.best_score_))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_train_pred = grid_search_result.predict(X_train)\n",
    "grid_test_pred = grid_search_result.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Learning - Train Score: -0.03\n",
      "Deep Learning - Test Score: -0.03 \n"
     ]
    }
   ],
   "source": [
    "dl_train_score = grid_search_result.best_estimator_.score(X_train, y_train)\n",
    "dl_test_score = grid_search_result.best_estimator_.score(X_test, y_test)\n",
    "\n",
    "print('Deep Learning - Train Score: %.2f'%dl_train_score)\n",
    "print('Deep Learning - Test Score: %.2f '%dl_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score 0.86\n",
      "Test Score 0.87\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, recall_score, precision_score\n",
    "\n",
    "print('Train Score {:.2f}'.format(r2_score(y_train, grid_train_pred)))\n",
    "print('Test Score {:.2f}'.format(r2_score(y_test, grid_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataset for classification task\n",
    "clf_data = df.drop(['Audit_Risk','Risk'], axis=1)\n",
    "clf_target = df['Risk']\n",
    "\n",
    "# Splitting training and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_org, X_test_org, y_train, y_test = train_test_split(clf_data, clf_target, random_state=0)\n",
    "\n",
    "# Scaling data\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train_org)\n",
    "X_test = scaler.transform(X_test_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Two voting classifiers - one with hard voting and one with soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting\n",
      "LogisticRegression Test Accuracy Score 0.9691\n",
      "KNeighborsClassifier Test Accuracy Score 0.9536\n",
      "SVC Test Accuracy Score 0.9639\n",
      "VotingClassifier Test Accuracy Score 0.9691\n",
      "\n",
      "LogisticRegression Test Accuracy Score 0.9691\n",
      "KNeighborsClassifier Test Accuracy Score 0.9536\n",
      "SVC Test Accuracy Score 0.9639\n",
      "VotingClassifier Test Accuracy Score 0.9742\n"
     ]
    }
   ],
   "source": [
    "log_clf = LogisticRegression()\n",
    "log_clf.fit(X_train, y_train)\n",
    "knn_clf = KNeighborsClassifier(7)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "svm_clf = SVC(C = 10, probability = True)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "voting_hard_clf = VotingClassifier(estimators=[('lr', log_clf), ('knn', knn_clf), ('svc', svm_clf)], voting='hard')\n",
    "voting_hard_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Hard Voting\")\n",
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (log_clf, knn_clf, svm_clf, voting_hard_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, 'Test Accuracy Score {:.4f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print()\n",
    "\n",
    "(\"Soft Voting\")\n",
    "voting_soft_clf = VotingClassifier(estimators=[('lr', log_clf), ('knn', knn_clf), ('svc', svm_clf)], voting='soft')\n",
    "voting_soft_clf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (log_clf, knn_clf, svm_clf, voting_soft_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, 'Test Accuracy Score {:.4f}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Two models with bagging and any two models with pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing models\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1) Logistic Regression\n",
      "\n",
      "Bagging\n",
      "- Accuracy Score\n",
      "Train Accuracy Score: 0.987910\n",
      "Test Accuracy Score: 0.974227\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       121\n",
      "           1       1.00      0.93      0.96        73\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       194\n",
      "   macro avg       0.98      0.97      0.97       194\n",
      "weighted avg       0.98      0.97      0.97       194\n",
      "\n",
      "- ROC AUC Score\n",
      "Test AUC Score: 0.965753\n",
      "\n",
      "\n",
      "Pasting\n",
      "Train Accuracy Score: 0.991364\n",
      "Test Accuracy Score: 0.979381\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       121\n",
      "           1       1.00      0.95      0.97        73\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       194\n",
      "   macro avg       0.98      0.97      0.98       194\n",
      "weighted avg       0.98      0.98      0.98       194\n",
      "\n",
      "\n",
      "- ROC AUC Score\n",
      "Test AUC Score: 0.972603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "print('(1) Logistic Regression')\n",
    "print()\n",
    "\n",
    "log = LogisticRegression(C=10, penalty='l1')\n",
    "\n",
    "log_bag = BaggingClassifier(log, bootstrap=True, n_jobs=-1, random_state=0)\n",
    "log_bag.fit(X_train, y_train)\n",
    "y_pred_bag = log_bag.predict(X_test)\n",
    "\n",
    "print(\"Bagging\")\n",
    "print(\"- Accuracy Score\")\n",
    "print(\"Train Accuracy Score: {:4f}\".format(log_bag.score(X_train, y_train)))\n",
    "print(\"Test Accuracy Score: {:4f}\".format(log_bag.score(X_test, y_test)))\n",
    "print()\n",
    "\n",
    "#Classficiation Report\n",
    "print(classification_report(y_test, y_pred_bag))\n",
    "\n",
    "#ROC AUC Score\n",
    "print(\"- ROC AUC Score\")\n",
    "print(\"Test AUC Score: {:4f}\".format(roc_auc_score(y_test, y_pred_bag)))\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "log_pas = BaggingClassifier(log, bootstrap=False, n_jobs=-1, random_state=0)\n",
    "log_pas.fit(X_train, y_train)\n",
    "y_pred_pas = log_pas.predict(X_test)\n",
    "print(\"Pasting\")\n",
    "print(\"Train Accuracy Score: {:4f}\".format(log_pas.score(X_train, y_train)))\n",
    "print(\"Test Accuracy Score: {:4f}\".format(log_pas.score(X_test, y_test)))\n",
    "      \n",
    "#Classficiation Report\n",
    "print(classification_report(y_test, y_pred_pas))\n",
    "print()\n",
    "\n",
    "#ROC AUC Score\n",
    "print('- ROC AUC Score')\n",
    "print(\"Test AUC Score: {:4f}\".format(roc_auc_score(y_test, y_pred_pas)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1) Linear SVC\n",
      "\n",
      "Bagging\n",
      "- Accuracy Score\n",
      "Train Accuracy Score: 0.994819\n",
      "Test Accuracy Score: 0.989691\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       121\n",
      "           1       1.00      0.97      0.99        73\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       194\n",
      "   macro avg       0.99      0.99      0.99       194\n",
      "weighted avg       0.99      0.99      0.99       194\n",
      "\n",
      "- ROC AUC Score\n",
      "Test AUC Score: 0.986301\n",
      "\n",
      "\n",
      "Pasting\n",
      "Train Accuracy Score: 0.994819\n",
      "Test Accuracy Score: 0.989691\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       121\n",
      "           1       1.00      0.95      0.97        73\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       194\n",
      "   macro avg       0.98      0.97      0.98       194\n",
      "weighted avg       0.98      0.98      0.98       194\n",
      "\n",
      "\n",
      "- ROC AUC Score\n",
      "Test AUC Score: 0.972603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Linear SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "print('(1) Linear SVC')\n",
    "print()\n",
    "\n",
    "lsvc = LinearSVC(C= 10, penalty = 'l1', dual=False, loss='squared_hinge')\n",
    "\n",
    "lsvc_bag = BaggingClassifier(lsvc, bootstrap=True, n_jobs=-1, random_state=0)\n",
    "lsvc_bag.fit(X_train, y_train)\n",
    "y_pred_bag = lsvc_bag.predict(X_test)\n",
    "\n",
    "print(\"Bagging\")\n",
    "print(\"- Accuracy Score\")\n",
    "print(\"Train Accuracy Score: {:4f}\".format(lsvc_bag.score(X_train, y_train)))\n",
    "print(\"Test Accuracy Score: {:4f}\".format(lsvc_bag.score(X_test, y_test)))\n",
    "print()\n",
    "\n",
    "#Classficiation Report\n",
    "print(classification_report(y_test, y_pred_bag))\n",
    "\n",
    "#ROC AUC Score\n",
    "print(\"- ROC AUC Score\")\n",
    "print(\"Test AUC Score: {:4f}\".format(roc_auc_score(y_test, y_pred_bag)))\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "lsvc_pas = BaggingClassifier(lsvc, bootstrap=False, n_jobs=-1, random_state=0)\n",
    "lsvc_pas.fit(X_train, y_train)\n",
    "y_pred_pas = log_pas.predict(X_test)\n",
    "print(\"Pasting\")\n",
    "print(\"Train Accuracy Score: {:4f}\".format(lsvc_pas.score(X_train, y_train)))\n",
    "print(\"Test Accuracy Score: {:4f}\".format(lsvc_pas.score(X_test, y_test)))\n",
    "      \n",
    "#Classficiation Report\n",
    "print(classification_report(y_test, y_pred_pas))\n",
    "print()\n",
    "\n",
    "#ROC AUC Score\n",
    "print('- ROC AUC Score')\n",
    "print(\"Test AUC Score: {:4f}\".format(roc_auc_score(y_test, y_pred_pas)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  (3) Two models with adaboost boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1) Logistic Regression\n",
      "\n",
      "Best Parameter: {'learning_rate': 0.05, 'n_estimators': 50}\n",
      "\n",
      "- Accuracy Score\n",
      "Train Accuracy Score: 0.918826\n",
      "Test Accuracy Score: 0.917526\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94       121\n",
      "           1       1.00      0.78      0.88        73\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       194\n",
      "   macro avg       0.94      0.89      0.91       194\n",
      "weighted avg       0.93      0.92      0.92       194\n",
      "\n",
      "- ROC AUC Score\n",
      "Test AUC Score: 0.890411\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#Logistic Regression\n",
    "print('(1) Logistic Regression')\n",
    "print()\n",
    "\n",
    "param_grid = { 'n_estimators': [3, 5, 10, 50, 75, 100],\n",
    "              'learning_rate' : [0.01, 0.05, 0.1, 0.5,1] }\n",
    "ada_grid = GridSearchCV(AdaBoostClassifier(LogisticRegression(C=10, penalty='l1')), \n",
    "                        param_grid,n_jobs=-1)\n",
    "ada_grid.fit(X_train, y_train)\n",
    "print('Best Parameter: {}'.format(ada_grid.best_params_))\n",
    "print()\n",
    "\n",
    "ada_clf = AdaBoostClassifier(LogisticRegression(), learning_rate=0.05, n_estimators=50)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "y_pred_ada = ada_clf.predict(X_test)\n",
    "\n",
    "print(\"- Accuracy Score\")\n",
    "print(\"Train Accuracy Score: {:4f}\".format(ada_clf.score(X_train, y_train)))\n",
    "print(\"Test Accuracy Score: {:4f}\".format(ada_clf.score(X_test, y_test)))\n",
    "print()\n",
    "\n",
    "#Classficiation Report\n",
    "print(classification_report(y_test, y_pred_ada))\n",
    "\n",
    "#ROC AUC Score\n",
    "print(\"- ROC AUC Score\")\n",
    "print(\"Test AUC Score: {:4f}\".format(roc_auc_score(y_test, y_pred_ada)))\n",
    "print()\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) Linear SVC\n",
      "\n",
      "Best Parameter: {'learning_rate': 0.01, 'n_estimators': 3}\n",
      "\n",
      "- Accuracy Score\n",
      "Train Accuracy Score: 0.994819\n",
      "Test Accuracy Score: 0.989691\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       121\n",
      "           1       1.00      0.97      0.99        73\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       194\n",
      "   macro avg       0.99      0.99      0.99       194\n",
      "weighted avg       0.99      0.99      0.99       194\n",
      "\n",
      "- ROC AUC Score\n",
      "Test AUC Score: 0.986301\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "#Linear SVC\n",
    "print('(2) Linear SVC')\n",
    "print()\n",
    "\n",
    "param_grid = { 'n_estimators': [3, 5, 10, 50, 75, 100],\n",
    "              'learning_rate' : [0.01, 0.05, 0.1, 0.5,1] }\n",
    "ada_grid = GridSearchCV(AdaBoostClassifier(LinearSVC(C= 10, penalty = 'l1', dual=False, loss='squared_hinge'),\n",
    "                                           algorithm='SAMME'), param_grid,n_jobs=-1)\n",
    "ada_grid.fit(X_train, y_train)\n",
    "print('Best Parameter: {}'.format(ada_grid.best_params_))\n",
    "print()\n",
    "\n",
    "ada_clf = AdaBoostClassifier(LinearSVC(C= 10, penalty = 'l1', dual=False, loss='squared_hinge'), \n",
    "                             algorithm='SAMME', learning_rate=0.01, n_estimators=3)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "y_pred_ada = ada_clf.predict(X_test)\n",
    "\n",
    "print(\"- Accuracy Score\")\n",
    "print(\"Train Accuracy Score: {:4f}\".format(ada_clf.score(X_train, y_train)))\n",
    "print(\"Test Accuracy Score: {:4f}\".format(ada_clf.score(X_test, y_test)))\n",
    "print()\n",
    "\n",
    "#Classficiation Report\n",
    "print(classification_report(y_test, y_pred_ada))\n",
    "\n",
    "#ROC AUC Score\n",
    "print(\"- ROC AUC Score\")\n",
    "print(\"Test AUC Score: {:4f}\".format(roc_auc_score(y_test, y_pred_ada)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) One model with gradient boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1) Gradient Boosted Classification Trees\n",
      "\n",
      "Best Parameter: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 5, 'subsample': 0.75}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "print('(1) Gradient Boosted Classification Trees')\n",
    "print()\n",
    "\n",
    "param_grid = {\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1, 0.5],\n",
    "    \"max_depth\":[3,5,8, 10],\n",
    "    \"subsample\":[0.5, 0.75, 1.0],\n",
    "    \"n_estimators\":[3, 5, 8, 10]\n",
    "    }\n",
    "\n",
    "gbr_grid = GridSearchCV(GradientBoostingClassifier(random_state=1),  \n",
    "                        param_grid,n_jobs=-1)\n",
    "gbr_grid.fit(X_train, y_train)\n",
    "print('Best Parameter: {}'.format(gbr_grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Accuracy Score\n",
      "Train Accuracy Score: 1.000000\n",
      "Test Accuracy Score: 1.000000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       121\n",
      "           1       1.00      1.00      1.00        73\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       194\n",
      "   macro avg       1.00      1.00      1.00       194\n",
      "weighted avg       1.00      1.00      1.00       194\n",
      "\n",
      "- ROC AUC Score\n",
      "Test AUC Score: 1.000000\n"
     ]
    }
   ],
   "source": [
    "gbr_clf = GradientBoostingClassifier(learning_rate=0.1, max_depth=5, n_estimators=58, subsample =0.75, random_state=0)\n",
    "gbr_clf.fit(X_train, y_train)\n",
    "y_pred_gbr = gbr_clf.predict(X_test)\n",
    "\n",
    "print(\"- Accuracy Score\")\n",
    "print(\"Train Accuracy Score: {:4f}\".format(gbr_clf.score(X_train, y_train)))\n",
    "print(\"Test Accuracy Score: {:4f}\".format(gbr_clf.score(X_test, y_test)))\n",
    "print()\n",
    "\n",
    "#Classficiation Report\n",
    "print(classification_report(y_test, y_pred_gbr))\n",
    "\n",
    "#ROC AUC Score\n",
    "print(\"- ROC AUC Score\")\n",
    "print(\"Test AUC Score: {:4f}\".format(roc_auc_score(y_test, y_pred_gbr)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dimensions: 8\n",
      "Explained Variance Ratio: 0.04320262807034925\n"
     ]
    }
   ],
   "source": [
    "# Dimension Reduction\n",
    "pca = PCA(0.95)\n",
    "X_reduced_train = pca.fit_transform(X_train)\n",
    "X_reduced_test = pca.transform(X_test)\n",
    "\n",
    "print('Number of dimensions:', pca.n_components_) \n",
    "print('Explained Variance Ratio:',1- pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv=5\n",
      "Best parameters: {'n_neighbors': 7}\n",
      "Best cross-validation score: 0.9890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#(1) KNN \n",
    "knn = KNeighborsClassifier()\n",
    "parameters = {'n_neighbors':np.arange(1,11,1)}\n",
    "\n",
    "#cv =5\n",
    "grid = GridSearchCV(knn, parameters, scoring='roc_auc',cv=5, n_jobs = -1)\n",
    "grid.fit(X_reduced_train, y_train)\n",
    "print('cv=5')\n",
    "print(\"Best parameters: {}\".format(grid.best_params_))\n",
    "print(\"Best cross-validation score: {:.4f}\".format(grid.best_score_))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier - Train Accuracy: 0.9637\n",
      "KNN Classifier - Test Accuracy: 0.9433 \n"
     ]
    }
   ],
   "source": [
    "knnclf_accuracy_train = grid.best_estimator_.score(X_reduced_train, y_train)\n",
    "knnclf_accuracy_test = grid.best_estimator_.score(X_reduced_test, y_test)\n",
    "\n",
    "print('KNN Classifier - Train Accuracy: %.4f'%knnclf_accuracy_train)\n",
    "print('KNN Classifier - Test Accuracy: %.4f '%knnclf_accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier - Train ROC AUC Score: 0.9576\n",
      "KNN Classifier - Test ROC AUC Score: 0.9247 \n"
     ]
    }
   ],
   "source": [
    "knnclf_auc_train = roc_auc_score(y_train, grid.predict(X_reduced_train))\n",
    "knnclf_auc_test = roc_auc_score(y_test, grid.predict(X_reduced_test))\n",
    "\n",
    "print('KNN Classifier - Train ROC AUC Score: %.4f'%knnclf_auc_train)\n",
    "print('KNN Classifier - Test ROC AUC Score: %.4f '%knnclf_auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96       121\n",
      "           1       1.00      0.85      0.92        73\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       194\n",
      "   macro avg       0.96      0.92      0.94       194\n",
      "weighted avg       0.95      0.94      0.94       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = grid.predict(X_reduced_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_table = [['KNN', 'n=7',knnclf_accuracy_train, knnclf_accuracy_test, knnclf_auc_train,knnclf_auc_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv=5\n",
      "Best parameters: {'C': 100, 'penalty': 'l2'}\n",
      "Best cross-validation score: 0.9935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#(2) Logistic Regression\n",
    "model = LogisticRegression(random_state=0)\n",
    "parameters = {'C':[0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'penalty': ['l1', 'l2']}\n",
    "\n",
    "#cv =5\n",
    "grid = GridSearchCV(model, parameters, scoring='roc_auc', cv=5, n_jobs = -1)\n",
    "grid.fit(X_reduced_train, y_train)\n",
    "print('cv=5')\n",
    "print(\"Best parameters: {}\".format(grid.best_params_))\n",
    "print(\"Best cross-validation score: {:.4f}\".format(grid.best_score_))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifier - Train Accuracy: 0.9672\n",
      "Logistic Regression Classifier - Test Accuracy: 0.9794 \n"
     ]
    }
   ],
   "source": [
    "logistic_accuracy_train = grid.best_estimator_.score(X_reduced_train, y_train)\n",
    "logistic_accuracy_test = grid.best_estimator_.score(X_reduced_test, y_test)\n",
    "\n",
    "print('Logistic Regression Classifier - Train Accuracy: %.4f'%logistic_accuracy_train)\n",
    "print('Logistic Regression Classifier - Test Accuracy: %.4f '%logistic_accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logstic Regression - Train ROC AUC Score: 0.9641\n",
      "Logistic Regression - Test ROC AUC Score: 0.9726 \n"
     ]
    }
   ],
   "source": [
    "logistic_auc_train = roc_auc_score(y_train, grid.predict(X_reduced_train))\n",
    "logistic_auc_test = roc_auc_score(y_test, grid.predict(X_reduced_test))\n",
    "\n",
    "print('Logstic Regression - Train ROC AUC Score: %.4f'%logistic_auc_train)\n",
    "print('Logistic Regression - Test ROC AUC Score: %.4f '%logistic_auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       121\n",
      "           1       1.00      0.95      0.97        73\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       194\n",
      "   macro avg       0.98      0.97      0.98       194\n",
      "weighted avg       0.98      0.98      0.98       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = grid.predict(X_reduced_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_table = report_table + [['Logistic Regression', 'C=100, penalty=l2', \n",
    "                                logistic_accuracy_train, logistic_accuracy_test, logistic_auc_train,logistic_auc_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv=5\n",
      "Best parameters: {'C': 100, 'loss': 'squared_hinge', 'penalty': 'l2'}\n",
      "Best cross-validation score: 0.9946\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#(3) Linear SVC\n",
    "model = LinearSVC(random_state=0)\n",
    "parameters = [{'C':[0.001, 0.01, 0.1, 1, 10, 100], 'penalty':['l2'],'loss':['hinge','squared_hinge']},\n",
    "              {'C':[0.001, 0.01, 0.1, 1, 10, 100], 'penalty':['l1'], 'dual':[False], 'loss':['squared_hinge']}]\n",
    "\n",
    "#cv =5\n",
    "grid = GridSearchCV(model, parameters, scoring= 'roc_auc', cv=5, n_jobs = -1)\n",
    "grid.fit(X_reduced_train, y_train)\n",
    "print('cv=5')\n",
    "print(\"Best parameters: {}\".format(grid.best_params_))\n",
    "print(\"Best cross-validation score: {:.4f}\".format(grid.best_score_))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC - Train Accuracy: 0.9672\n",
      "Linear SVC - Test Accuracy: 0.9742 \n"
     ]
    }
   ],
   "source": [
    "lsvc_accuracy_train = grid.best_estimator_.score(X_reduced_train, y_train)\n",
    "lsvc_accuracy_test = grid.best_estimator_.score(X_reduced_test, y_test) \n",
    "\n",
    "print('Linear SVC - Train Accuracy: %.4f'%lsvc_accuracy_train)\n",
    "print('Linear SVC - Test Accuracy: %.4f '%lsvc_accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC - Train ROC AUC Score: 0.9641\n",
      "Linear SVC - Test ROC AUC Score: 0.9685 \n"
     ]
    }
   ],
   "source": [
    "lsvc_auc_train = roc_auc_score(y_train, grid.predict(X_reduced_train))\n",
    "lsvc_auc_test = roc_auc_score(y_test, grid.predict(X_reduced_test))\n",
    "\n",
    "print('Linear SVC - Train ROC AUC Score: %.4f'%lsvc_auc_train)\n",
    "print('Linear SVC - Test ROC AUC Score: %.4f '%lsvc_auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       121\n",
      "           1       0.99      0.95      0.97        73\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       194\n",
      "   macro avg       0.98      0.97      0.97       194\n",
      "weighted avg       0.97      0.97      0.97       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = grid.predict(X_reduced_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_table  = report_table +[['Linear SVC', 'C=100, penalty=l2', \n",
    "                                lsvc_accuracy_train, lsvc_accuracy_test,lsvc_auc_train,lsvc_auc_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv=5\n",
      "Best parameters: {'C': 0.001, 'gamma': 1}\n",
      "Best cross-validation score: 0.9948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#(4) RBF Kernel SVC\n",
    "model = SVC(kernel='rbf', random_state=0)\n",
    "parameters = [{'C':[0.001, 0.01, 0.1, 1, 10, 100], 'gamma':[0.001,0.01,0.1,1,10,100]}]\n",
    "\n",
    "#cv =5\n",
    "grid = GridSearchCV(model, parameters, scoring = 'roc_auc',cv=5, n_jobs = -1)\n",
    "grid.fit(X_reduced_train, y_train)\n",
    "print('cv=5')\n",
    "print(\"Best parameters: {}\".format(grid.best_params_))\n",
    "print(\"Best cross-validation score: {:.4f}\".format(grid.best_score_))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF SVC - Train Accuracy: 0.5993\n",
      "RBF SVC - Test Accuracy: 0.6237 \n"
     ]
    }
   ],
   "source": [
    "rbf_svc_accuracy_train = grid.best_estimator_.score(X_reduced_train, y_train)\n",
    "rbf_svc_accuracy_test = grid.best_estimator_.score(X_reduced_test, y_test)\n",
    "\n",
    "print('RBF SVC - Train Accuracy: %.4f'%rbf_svc_accuracy_train)\n",
    "print('RBF SVC - Test Accuracy: %.4f '%rbf_svc_accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF Kernel SVC - Train ROC AUC Score: 0.5000\n",
      "RBF Kernel SVC - Test ROC AUC Score: 0.5000 \n"
     ]
    }
   ],
   "source": [
    "rbf_svc_auc_train = roc_auc_score(y_train, grid.predict(X_reduced_train))\n",
    "rbf_svc_auc_test = roc_auc_score(y_test, grid.predict(X_reduced_test))\n",
    "\n",
    "print('RBF Kernel SVC - Train ROC AUC Score: %.4f'%rbf_svc_auc_train)\n",
    "print('RBF Kernel SVC - Test ROC AUC Score: %.4f '%rbf_svc_auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.77       121\n",
      "           1       0.00      0.00      0.00        73\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       194\n",
      "   macro avg       0.31      0.50      0.38       194\n",
      "weighted avg       0.39      0.62      0.48       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = grid.predict(X_reduced_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_table = report_table +[['rbf Kernelized Support Vector Machine', 'C=0.001,gamma=1', \n",
    "                               rbf_svc_accuracy_train, rbf_svc_accuracy_test,rbf_svc_auc_train, rbf_svc_auc_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv=5\n",
      "Best parameters: {'max_depth': 4, 'max_features': 3}\n",
      "Best cross-validation score: 0.9735\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josep\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#(5) Decission Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(random_state=0)\n",
    "parameters = [{'max_depth':[1,2,3,4,5,6,7,8,9,10], 'max_features':[1,2,3,4,5,6,7,8]}]\n",
    "\n",
    "#cv =5\n",
    "grid = GridSearchCV(model, parameters, scoring='roc_auc', cv=5, n_jobs = -1)\n",
    "grid.fit(X_reduced_train, y_train)\n",
    "print('cv=5')\n",
    "print(\"Best parameters: {}\".format(grid.best_params_))\n",
    "print(\"Best cross-validation score: {:.4f}\".format(grid.best_score_))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classofier - Train Accuracy: 0.9706\n",
      "Decision Tree Classifier - Test Accuracy: 0.9639 \n"
     ]
    }
   ],
   "source": [
    "dtree_accuracy_train = grid.best_estimator_.score(X_reduced_train, y_train)\n",
    "dtree_accuracy_test = grid.best_estimator_.score(X_reduced_test, y_test)\n",
    "\n",
    "print('Decision Tree Classofier - Train Accuracy: %.4f'%dtree_accuracy_train)\n",
    "print('Decision Tree Classifier - Test Accuracy: %.4f '%dtree_accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier - Train ROC AUC Score: 0.9662\n",
      "Decision Tree Classifier - Test ROC AUC Score: 0.9521 \n"
     ]
    }
   ],
   "source": [
    "dtree_auc_train = roc_auc_score(y_train, grid.predict(X_reduced_train))\n",
    "dtree_auc_test = roc_auc_score(y_test, grid.predict(X_reduced_test))\n",
    "\n",
    "print('Decision Tree Classifier - Train ROC AUC Score: %.4f'%dtree_auc_train)\n",
    "print('Decision Tree Classifier - Test ROC AUC Score: %.4f '%dtree_auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       121\n",
      "           1       1.00      0.90      0.95        73\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       194\n",
      "   macro avg       0.97      0.95      0.96       194\n",
      "weighted avg       0.97      0.96      0.96       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = grid.predict(X_reduced_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_table = report_table +[['Decision Tree Classification', 'max_depth=4, max_features=3',\n",
    "                               dtree_accuracy_train, dtree_accuracy_test, dtree_auc_train, dtree_auc_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_table = pd.DataFrame(report_table, columns = ['Model Name', 'Model Parameter', 'Train Accuracy', 'Test Accuracy', 'Train AUC Score', 'Test AUC Score'])\n",
    "report_table.index = report_table['Model Name']\n",
    "report_table.drop(['Model Name'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Parameter</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Train AUC Score</th>\n",
       "      <th>Test AUC Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>C=100, penalty=l2</td>\n",
       "      <td>0.967185</td>\n",
       "      <td>0.979381</td>\n",
       "      <td>0.964051</td>\n",
       "      <td>0.972603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVC</th>\n",
       "      <td>C=100, penalty=l2</td>\n",
       "      <td>0.967185</td>\n",
       "      <td>0.974227</td>\n",
       "      <td>0.964051</td>\n",
       "      <td>0.968471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classification</th>\n",
       "      <td>max_depth=4, max_features=3</td>\n",
       "      <td>0.970639</td>\n",
       "      <td>0.963918</td>\n",
       "      <td>0.966219</td>\n",
       "      <td>0.952055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>n=7</td>\n",
       "      <td>0.963731</td>\n",
       "      <td>0.943299</td>\n",
       "      <td>0.957598</td>\n",
       "      <td>0.924658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rbf Kernelized Support Vector Machine</th>\n",
       "      <td>C=0.001,gamma=1</td>\n",
       "      <td>0.599309</td>\n",
       "      <td>0.623711</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Model Parameter  \\\n",
       "Model Name                                                           \n",
       "Logistic Regression                              C=100, penalty=l2   \n",
       "Linear SVC                                       C=100, penalty=l2   \n",
       "Decision Tree Classification           max_depth=4, max_features=3   \n",
       "KNN                                                            n=7   \n",
       "rbf Kernelized Support Vector Machine              C=0.001,gamma=1   \n",
       "\n",
       "                                       Train Accuracy  Test Accuracy  \\\n",
       "Model Name                                                             \n",
       "Logistic Regression                          0.967185       0.979381   \n",
       "Linear SVC                                   0.967185       0.974227   \n",
       "Decision Tree Classification                 0.970639       0.963918   \n",
       "KNN                                          0.963731       0.943299   \n",
       "rbf Kernelized Support Vector Machine        0.599309       0.623711   \n",
       "\n",
       "                                       Train AUC Score  Test AUC Score  \n",
       "Model Name                                                              \n",
       "Logistic Regression                           0.964051        0.972603  \n",
       "Linear SVC                                    0.964051        0.968471  \n",
       "Decision Tree Classification                  0.966219        0.952055  \n",
       "KNN                                           0.957598        0.924658  \n",
       "rbf Kernelized Support Vector Machine         0.500000        0.500000  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_table.sort_values(by=['Test Accuracy','Test AUC Score'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x25811534080>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(y =report_table.index, x = 'Test AUC Score', data= report_table.sort_values(by='Test AUC Score', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result from Project 1\n",
    "<img src=\"Result1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA result is not better than the one from Project 1 on Classification Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6) Deep Learning Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def create_model():\n",
    "    # Defining model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=30,activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compiling model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn= create_model, verbose=0)\n",
    "param_grid = {'batch_size':[5,10,25,50], 'epochs':[10, 50,100]}\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting model\n",
    "grid_search_result = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'batch_size': 5, 'epochs': 100}\n",
      "Best cross-validation score: 0.99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid_search_result.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search_result.best_score_))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Learning - Train Accuracy: 0.9948\n",
      "Deep Learning - Test Accuracy: 0.9897 \n"
     ]
    }
   ],
   "source": [
    "dl_accuracy_train = grid_search_result.best_estimator_.score(X_train, y_train)\n",
    "dl_accuracy_test = grid_search_result.best_estimator_.score(X_test, y_test)\n",
    "\n",
    "print('Deep Learning - Train Accuracy: %.4f'%dl_accuracy_train)\n",
    "print('Deep Learning - Test Accuracy: %.4f '%dl_accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dl_train_score = grid_search_result.best_estimator_.score(X_train, y_train)\n",
    "dl_test_score = grid_search_result.best_estimator_.score(X_test, y_test)\n",
    "\n",
    "print('Deep Learning - Train Score: %.2f'%dl_train_score)\n",
    "print('Deep Learning - Test Score: %.2f '%dl_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Learning - ROC AUC Score 0.9950\n",
      "Deep Learning - ROC AUC Score 0.9890\n"
     ]
    }
   ],
   "source": [
    "grid_train_pred = grid_search_result.predict(X_train)\n",
    "grid_test_pred = grid_search_result.predict(X_test)\n",
    "\n",
    "print('Deep Learning - ROC AUC Score {:.4f}'.format(roc_auc_score(y_train, grid_train_pred)))\n",
    "print('Deep Learning - ROC AUC Score {:.4f}'.format(roc_auc_score(y_test, grid_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
